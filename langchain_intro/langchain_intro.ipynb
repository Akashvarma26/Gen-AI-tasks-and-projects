{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ingestion using Document Loaders in LangChain_Community\n",
    "Documentation for all Data Loaders:    https://python.langchain.com/v0.2/docs/integrations/document_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.document_loaders.text.TextLoader at 0x23d07bfde50>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text Loaders to read contents in txt file\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "text_load=TextLoader('speech.txt',encoding = 'UTF-8')\n",
    "text_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'speech.txt'}, page_content='Scuderia Ferrari (Italian: [skudeˈriːa ferˈraːri]) currently racing under Scuderia Ferrari HP is the racing division of luxury Italian auto manufacturer Ferrari and the racing team that competes in Formula One racing. The team is also known by the nickname \"The Prancing Horse\" (Italian: il Cavallino Rampante or simply il Cavallino), in reference to their logo. It is the oldest surviving and most successful Formula One team, having competed in every world championship since 1950.')]\n"
     ]
    }
   ],
   "source": [
    "text_docs=text_load.load()\n",
    "print(text_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'Minor Project Report.pdf', 'page': 0}, page_content='Multi-Class Ship Classification of Commercial and\\nNaval Vessels using Convolutional Neural Network\\nA PROJECT REPORT\\nSubmitted by\\nAKASH VARMA DATLA [RA2111047010131]\\nAMAN PARASHER [RA2111047010157]\\nUnder the Guidance of\\nDr. U.Sakthi\\nAssistant Professor,\\nDepartment of Computational Intelligence\\nin partial fulfilment of the requirements for the degree of\\nBACHELOR OF TECHNOLOGY\\nin\\nARTIFICIAL INTELLIGENCE\\nDEPARTMENT OF COMPUTATIONAL INTELLIGENCE\\nCOLLEGE OF ENGINEERING AND TECHNOLOGY\\nSRM INSTITUTE OF SCIENCE AND TECHNOLOGY\\nKATTANKULATHUR- 603 203\\nOCTOBER 2024\\n'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 1}, page_content='1\\nDepartment of Computational Intelligence\\nSRM Institute of Science & Technology\\nOwn Work* Declaration Form\\nThis sheet must be filled in (each box ticked to show that the condition has been met). It must\\nbe signed and dated along with your student registration number and included with all\\nassignments you submit – work will not be marked unless this is done.\\nTo be completed by the student for all assessments\\nDegree/ Course: B. Tech / Artificial Intelligence\\nStudent Name: Akash Varma Datla, Aman Parasher\\nRegistration Number: RA2111047010131, RA2111047010157\\nTitle of Work: Multi-Class Ship Classification of Commercial and Naval Vessels using\\nConvolutional Neural Network\\nI / We hereby certify that this assessment compiles with the University’s Rules and\\nRegulations relating to Academic misconduct and plagiarism**, as listed in the University\\nWebsite, Regulations, and the Education Committee guidelines.\\nI / We confirm that all the work contained in this assessment is my / our own except where\\nindicated, and that I / We have met the following conditions:\\n● Clearly referenced / listed all sources as appropriate\\n● Referenced and put in inverted commas all quoted text (from books, web, etc)\\n● Given the sources of all pictures, data etc. that are not my own\\n● Not made any use of the report(s) or essay(s) of any other student(s) either past or\\npresent\\n● Acknowledged in appropriate places any help that I have received from others (e.g.\\nfellow students, technicians, statisticians, external sources)\\n● Compiled with any other plagiarism criteria specified in the Course handbook /\\nUniversity website\\nI understand that any false claim for this work will be penalized in accordance with the\\nUniversity policies and regulations.\\nDECLARATION:\\nI am aware of and understand the University’s policy on Academic misconduct and\\nplagiarism and I certify that this assessment is my / our own work, except were indicated by\\nreferring, and that I have followed the good academic practices noted above.\\nIf you are working in a group, please write your registration numbers and sign with the date\\nfor every student in your group.\\n'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 2}, page_content='2\\nSRM INSTITUTE OF SCIENCE AND TECHNOLOGY\\nKATTANKULATHUR – 603 203\\nBONAFIDE CERTIFICATE\\nCertified that 18CSP107L - Minor Project report titled “Multi-Class Ship\\nClassification of Commercial and Naval Vessels using Convolutional Neural\\nNetwork” is the bonafide work of AKASH VARMA DATLA\\n[RA2111047010131] and AMAN PARASHER [RA2111047010157] who\\ncarried out the project work under my supervision. Certified further, that to the best of\\nmy knowledge the work reported herein does not form any other project report or\\ndissertation on the basis of which a degree or award was conferred on an earlier\\noccasion on this or any other candidate.\\nSIGNATURE SIGNATURE\\nDr. U.Sakthi Dr. R. ANNIE UTHRA\\nSUPERVISOR\\nASSISTANT PROFESSOR PROFESSOR & HEAD\\nDEPARTMENT OF\\nCOMPUTATIONAL\\nINTELLIGENCE\\nDEPARTMENT OF\\nCOMPUTATIONAL\\nINTELLIGENCE'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 3}, page_content='3\\nACKNOWLEDGEMENTS\\nWe express our humble gratitude to Dr. C. Muthamizhchelvan, Vice-Chancellor, SRM Institute of\\nScience and Technology, for the facilities extended for the project work and his continued support.\\nWe extend our sincere thanks to Dr. T. V. Gopal, Dean-CET, SRM Institute of Science and\\nTechnology, for his invaluable support.\\nWe wish to thank Dr. Revathi Venkataraman, Professor and Chairperson, School of Computing,\\nSRM Institute of Science and Technology, for her support throughout the project work.\\nWe encompass our sincere thanks to Dr. M. Pushpalatha, Professor and Associate Chairperson,\\nSchool of Computing and Dr. C.Lakshmi, Professor and Associate Chairperson, School of\\nComputing, SRM Institute of Science and Technology, for their invaluable support. We are\\nincredibly grateful to our Head of the Department, Dr. R. Annie Uthra, Professor, Department of\\nComputational Intelligence, SRM Institute of Science and Technology, for her suggestions and\\nencouragement at all the stages of the project work.\\nWe want to convey our thanks to our Project Coordinator, Dr.M.Abirami, Panel Head, Dr.Saad\\nYunus Sait and Panel Members, Dr. M Vimaladevi, Dr.R.Babu, Mrs. Shaik Rasheeda Begum,\\nDepartment of Computational Intelligence, SRM Institute of Science and Technology, for their\\ninputs during the project reviews and support.\\nWe register our immeasurable thanks to our Faculty Advisor, Dr. B. Pitchaimanickam, Department\\nof Computational Intelligence, SRM Institute of Science and Technology, for leading and helping us\\nto complete our course.\\nOur inexpressible respect and thanks to our guide, Dr. U.Sakthi , Department of Computational\\nIntelligence, SRM Institute of Science and Technology, for providing us with an opportunity to\\npursue our project under her mentorship. She provided us with the freedom and support to explore\\nthe research topics of our interest. Her passion for solving problems and making a difference in the\\nworld has always been inspiring.\\nWe sincerely thank all the staff and students of Computational Intelligence, School of Computing,\\nS.R.M Institute of Science and Technology, for their help during our project. Finally, we would like\\nto thank our parents, family members, and friends for their unconditional love, constant support and\\nencouragement'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 4}, page_content='4\\nABSTRACT\\nThis work seeks to classify various ship categories on the high-resolution optical remote sensing\\ndataset known as FGSC-23 using deep learning models. The dataset contains 23 types of ships, but for\\nthis study, six categories are selected: Medical Ship, Hovercraft, Submarine, Fishing Boat, Passenger\\nShip and Liquified Gas Ship. The adopted ship categories were thereafter used to train four deep\\nlearning models which included VGG16, EfficientNet, ResNet50v2, and MobileNetv2. The accuracy,\\nprecision, and AUC parameters were used to evaluate the models where the best one, ResNet50v2, was\\nset up as accurate. Using these models, it should be possible to achieve a practical deployment aiming\\nat fine-grained classification of ships that will contribute to enhancing maritime surveillance\\ntechniques. ResNet50v2 model had the highest precision of 0.9058 and on the other hand MobileNetv2\\nhad the highest AUC of 0.9932. The analysis of the identified models is performed further in this work\\nto illustrate their advantages and shortcomings in adherence to fine-grained ship classification tasks.\\nBased on this research, the practical implications transcend theoretical comparisons of performance\\nmetrics, as useful information is provided to improve security applications in the maritime domain,\\nsurveillance, and monitoring systems.\\nCategorization and identification of ships is a very important process in global maritime business\\nbecause it is used in decision-making processes in fields like security and surveillance, fishing control,\\nsearch and rescue and conservation of the environment. The models highlighted are namely\\nResNet50v2 as well as MobileNetv2, proved to be robust in real-time applications such scenarios\\nbecause of their ability to accurately and proficiently distinguish the differences between the ship types.\\nIn addition, this study suggests the luminal possibility of doing further improvement on these models\\nusing data enhancement strategies like transfer learning, data augmentation, and hyperparameter\\noptimization which would enable it to perform impressively on any other maritime datasets. Therefore,\\nthe outcomes are beneficial for furthering work in automated ship detection and classification and are\\nimportant toward enhancing the overall effectiveness and safety of navies across the globe.'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 5}, page_content='5\\nTABLE OF CONTENTS\\nABSTRACT 4\\nTABLE OF CONTENTS 5\\nLIST OF FIGURES\\nLIST OF TABLE\\n6\\n7\\nABBREVIATIONS 8\\nCHAPTER NO. TITLE PAGE NO.\\n1 INTRODUCTION 9\\n1.1 General (Introduction to Project) 9\\n1.2 Motivation 10\\n2 LITERATURE SURVEY 11\\n2.1 Deep Learning Techniques for Ship Classification: A\\nComprehensive Review\\n11\\n2.2 Enhancing Ship Classification with Pretrained Models\\nand Data Augmentation\\n11\\n2.3 Limitations Identified from Literature Survey\\n(Research Gaps)\\n12\\n2.4 Research Objectives 12\\n3 PROPOSED METHODOLOGY 14\\n3.1 Preprocessing and Data Augmentation 14\\n3.1 Model Architectures 15\\n3.1 Transfer Learning and Training 16\\n3.1 Evaluation Metrics 16\\n4 RESULTS AND DISCUSSIONS 18\\n5 CONCLUSION AND FUTURE ENHANCEMENTS 21\\n5.1 Conclusion 21\\n5.2 Future Enhancements 21\\n6 REFERENCES 23\\n7 APPENDIX 25\\n7.1 A. CONFERENCE PUBLICATION 25\\n7.2 B. PUBLICATION DETAIL 26\\n7.3 C. PLAGIARISM REPORT 27'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 6}, page_content='6\\nLIST OF FIGURES\\nFIGURE NO. TITLE PAGE NO.\\n3.1.1 Process Flow Diagram of Ship Classification 14\\n3.2.1 Architecture Diagram of Ship Classification 15\\n4.1 Accuracy Comparisons of Different Models 19\\n4.2 Precision Comparisons of Different Models 19\\n4.3 AUC Comparisons of Different Models 20'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 7}, page_content='7\\nLIST OF TABLE\\nFIGURE NO. TITLE PAGE NO.\\n4.1 Performance Analysis 18'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 8}, page_content='8\\nABBREVIATIONS\\nAI Artificial Intelligence\\nFGSC Fine-Grained Ship Classification\\nVGG Visual Geometry Group\\nResNet Residual Neural Network\\nAUC Area Under the Curve\\nCNN Convolutional Neural Network\\nViT Vision Transformers\\nSE Squeeze and Excitation\\nADAM Adaptive Moment Estimation'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 9}, page_content='9\\n1 INTRODUCTION\\n1.1 GENERAL INTRODUCTION\\nShip grouping is an important procedure in maritime vigilance systems to sort different kinds of\\nships with high accuracy. Classification of ships is also important for several reasons such as\\nsecurity, environmental conservation as well as traffic control on water channels. FGSC-23 is a\\nfine-grained dataset in the ship classification field, which includes 23 different ship types and a\\ntotal of 4052 samples are divided into categories they belong to, which aspect ratio they have and\\nin which direction are dispersed. The dataset has numerous image scenes and fine categorization,\\nwhich constitutes a complex issue for machine learning since the variations of ship kinds are very\\nclose. By focusing on classifying six specific categories of ships from the FGSC-23 dataset:\\nSubmarine, Medical Ship, Hovercraft, Fishing Boat, Passenger Ship, Liquified gas ship. Each of\\nthese categories was chosen because they were appropriate for both civilian and defense markets.\\nAlthough the FGSC-23 dataset is commonly used in ship classification research, by focusing on\\nthe fine-grained nature of the task in dealing with ships whose intra class variations deviate little\\nfrom each other. The selected models effectively solve this increased complexity of the problem.\\nIt is imperative that differences between classes are well distinguished and hence the objective of\\nthe current research is to use enhanced deep learning classification for ship classification. CNN\\narchitecture is the most important choice for the tradeoff between performance and computational\\nefficiency.\\nTo achieve this, four different convolutional neural network (CNN) architectures are used, models\\nincluding VGG16, EfficientNet, ResNet50v2, and MobileNetv2. VGG16 featured for its simple and\\nclassical deep convolutional structure, which is a starting point in the construction of feature extraction.\\nVGG16 is a classic use of small 3x3 convolutional filters that can capture very fine patterns. Since it\\nhas many parameters, it is a good comparative model, though. MobileNetV2: In terms of\\ncomputational cost, one is selected for its efficiency. In MobileNetV2, depth wise separable\\nconvolutions are used, drastically reducing the number of parameters and operations while keeping on\\npar accuracy. This is particularly useful in mobile and embedded systems where resources are limited.\\nResNet50V2: Residual connections are selected for their deep architecture which alleviates vanishing\\ngradient issues. This speeds up the training, especially in deep networks. As ResNet50V2 whose depth\\nis suitable to capture complex features in larger datasets. EfficientNet: Had scalability in mind. Deep,\\nwide, and low resolution together enable a model that is efficient while achieving high accuracy with\\nless parameters.'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 10}, page_content='10\\n1.2 MOTIVATION\\nAccurate ship classification is crucial for maritime operations such as security, traffic control, and\\nenvironmental protection. The FGSC-23 dataset presents a significant challenge due to the fine-grained\\nnature of the task, where visual differences between ship types are subtle. Traditional methods struggle\\nwith such close intra-class variations, emphasizing the need for more advanced deep learning models.\\nWith maritime activities becoming increasingly diverse and complex, there is a growing need for\\nefficient systems that can operate in real-time while maintaining high accuracy. The classification of\\nships is not only essential for managing civilian maritime traffic but also for defense-related\\napplications, where timely and precise identification of vessels is critical. As the volume of maritime\\ndata grows, so does the demand for models that can scale effectively without compromising\\nperformance.\\nThis research focuses on enhancing ship classification accuracy and efficiency by using CNN\\narchitectures like VGG16, MobileNetV2, ResNet50V2, and EfficientNet. Each model offers unique\\nstrengths in feature extraction and computational efficiency, addressing both the complexity of the\\nFGSC-23 dataset and the practical need for real-time, resource-efficient applications in maritime\\nsystems. By targeting six specific ship categories relevant to both civilian and defense sectors, this\\nstudy aims to bridge the gap between high-performance models and practical deployment in maritime\\nsurveillance and monitoring.\\nUltimately, the motivation behind this study is to provide a solution that balances cutting-edge deep\\nlearning techniques with the real-world constraints of computational resources. Through this, we aim\\nto contribute to the development of more reliable and scalable ship classification systems, which can\\nimprove the safety and efficiency of maritime operations on a global scale.'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 11}, page_content=\"11\\n2 LITERATURE SURVEY\\n2.1 SUBTITLE 1: DEEP LEARNING TECHNIQUES FOR SHIP CLASSIFICATION: A\\nCOMPREHENSIVE REVIEW\\nThis paper reviews various deep learning techniques utilized for ship classification, focusing on recent\\nadvancements and methodologies. The study highlights the growing importance of accurate ship\\nclassification in maritime safety, environmental monitoring, and fleet management. With the\\nincreasing volume of maritime data, deep learning models, such as Convolutional Neural Networks\\n(CNNs) and their variants, have demonstrated remarkable effectiveness in classifying ships from\\nimages. The research emphasizes that models like VGG16, MobileNetV2, and EfficientNet show\\npromising results in terms of precision and accuracy, significantly enhancing the automation of ship\\nclassification tasks. However, challenges such as the need for extensive labeled datasets and the\\ncomputational demands of training these models are discussed, pointing to a need for efficient data\\naugmentation and transfer learning strategies.\\n2.2 SUBTITLE 2: ENHANCING SHIP CLASSIFICATION WITH PRETRAINED\\nMODELS AND DATA AUGMENTATION\\nIn this study, researchers explore the application of pretrained models and data augmentation\\ntechniques in improving ship classification accuracy. The findings reveal that employing models like\\nResNet50V2 not only accelerates the training process but also enhances the model's ability to\\ngeneralize to unseen data. Data augmentation strategies, such as rotation, shifting, and zooming, are\\nshown to mitigate overfitting and improve the robustness of the classification system. Despite the\\nadvancements, the study identifies potential limitations, including the dependency on the quality of the\\ntraining data and the challenge of maintaining model performance across various environmental\\nconditions. The integration of these techniques is crucial for developing a reliable ship classification\\nsystem that operates effectively in diverse maritime scenarios.\"),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 12}, page_content='12\\n2.3 LIMITATIONS IDENTIFIED FROM LITERATURE\\nSURVEY (RESEARCH GAPS)\\nThe review of recent methods for ship classification highlighted several limitations in existing\\napproaches, particularly in Synthetic Aperture Radar (SAR) image recognition and fine-grained ship\\nclassification:\\n1. Manual Feature Selection in Traditional Methods: Earlier methods, such as those using\\nCFAR (Constant False Alarm Rate), rely on manually designed features, which are not only\\nlabor-intensive but also struggle with generalization. These methods are particularly vulnerable\\nto challenges like sea clutter and complex maritime environments, limiting their scalability.\\n2. Class Imbalance and Dataset Limitations: Despite advances in deep learning, including the\\nuse of CNNs for ship classification, models often suffer from class imbalance, where\\nunderrepresented ship classes are inaccurately classified. Studies have shown that class\\nimbalance impacts model performance, especially in SAR datasets where some ship types are\\nrare.\\n3. Spatial Information Loss in Deep CNNs: Conventional CNNs, especially as they deepen,\\nface the challenge of spatial information loss. As features are compressed and reduced through\\nlayers, finer details necessary for distinguishing between ships with similar structures may be\\nlost, leading to lower classification accuracy.\\n4. Insufficient Handling of High Intra-Class Variation: Fine-Grained Ship Classification\\n(FGSC) poses unique challenges due to high intra-class variation. Models often struggle to\\ndifferentiate between ships of similar hull structures but distinct superstructures, which affects\\nclassification precision, particularly in military and commercial ship datasets.\\n2.1 RESEARCH OBJECTIVES\\nOur project is guided by three core objectives designed to address the critical aspects of ship\\nclassification using deep learning models.\\n1. Achieving Fine-Grained Classification Accuracy: The first objective is to improve the fine-\\ngrained classification of ships using the FGSC-23 dataset. Focusing on six specific ship\\ncategories—Medical Ship, Hovercraft, Submarine, Fishing Boat, Passenger Ship, and Liquified\\nGas Ship—this study aims to evaluate the performance of four deep learning models: VGG16,\\nEfficientNet, ResNet50v2, and MobileNetv2. By leveraging these models, our goal is to'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 13}, page_content='13\\noptimize precision and accuracy, contributing to more effective maritime surveillance and\\ndecision-making processes.\\n2. Evaluating and Enhancing Model Performance: The second objective emphasizes the\\nevaluation of model performance based on key metrics such as accuracy, precision, and AUC.\\nThe research identifies ResNet50v2 as the most accurate model with a precision of 0.9058 and\\nMobileNetv2 as the model with the highest AUC at 0.9932. Additionally, this objective\\nexplores potential enhancements to these models through data augmentation, transfer learning,\\nand hyperparameter optimization to further improve their classification capabilities across\\nvarious maritime datasets.\\n3. Practical Application in Maritime Surveillance: The third objective is to apply the insights\\ngained from model evaluations to practical maritime surveillance and monitoring systems. This\\ninvolves identifying how these models can contribute to real-time applications such as ship\\ndetection, security, fishing control, and environmental conservation. By refining ship\\nclassification techniques, the research aims to support enhanced naval operations and global\\nmaritime safety.'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 14}, page_content='14\\n3 PROPOSED METHODOLOGIES\\nThis research investigates the application of deep learning modalities for the task of fine-grained\\nship classification on the FGSC-23 dataset. The approach focuses on six specific ship categories:\\nSubmarine, Medical ship, Hovercraft, Fishing boat, Passenger ship, and Liquified gas ship. To\\nachieve accurate classification, four pre-trained convolutional neural networks (CNNs) were utilized:\\nVGG16, EfficientNet, ResNet50v2, and MobileNetv2.\\nThe FGSC-23 dataset comprises high-resolution optical ship images spanning 23 ship categories\\nwith 4052 samples. These images are well-suited for fine-grained classification due to the\\navailability of class, aspect ratio, and distribution direction labels. For this study, six categories were\\nselected, covering both civil and naval vessels.\\n3.1 PREPROCESSING AND DATA AUGMENTATION\\nTo ensure the models generalize well and to prevent overfitting, the dataset was divided into training,\\nvalidation, and test sets. Preprocessing included resizing all images to a uniform size of 224x224\\npixels, followed by normalization. Simple data augmentation techniques such as rotation, flipping,\\nand scaling were applied to the training set to enhance generalization. These steps aimed to improve\\nmodel robustness while working with high-resolution ship images.\\nFig 3.1.1 Process Flow Diagram of Ship Classification'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 15}, page_content='15\\n3.2 MODEL ARCHITECTURES\\nFour deep learning models were employed to classify the ships from the FGSC-23 dataset. Each\\nmodel brought unique capabilities to the classification task:\\n1. VGG16: This convolutional neural network (CNN) has 16 layers. Despite its simplicity,\\nVGG16 is known for effective feature extraction. It uses convolutional and pooling layers\\nfor feature extraction, followed by fully connected layers for classification.\\n2. EfficientNet: EfficientNet optimizes both performance and computational resources by\\nscaling in three dimensions—depth, width, and image resolution. It provides high accuracy\\nwith minimal computational overhead, making it ideal for large datasets like FGSC-23.\\n3. ResNet50v2: ResNet50v2, with its 50 layers, incorporates identity mapping to address the\\nvanishing gradient problem, facilitating deeper training. The model’s architecture enables it\\nto capture hierarchical features and classify complex ship categories effectively.\\n4. MobileNetv2: MobileNetv2 employs depth-wise separable convolutions to significantly\\nreduce the computational load without compromising accuracy. This makes it particularly\\nsuitable for real-time applications on mobile and embedded devices.\\nFig 3.2.1 Architecture Diagram of Ship Classification\\nIn brief, the workflow of ship classification using deep learning, which is illustrated in Fig. 3.2.1,\\nconsists of data preprocessing, model training, model testing, and model performance testing to\\nselect an optimum deep learning model for the chosen problem.'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 16}, page_content=\"16\\n3.3 TRANSFER LEARNING AND TRAINING\\nAll four models were pre-trained on the ImageNet dataset and then fine-tuned on the FGSC-23\\ndataset. Transfer learning allowed the models to leverage pre-learned features, reducing the amount\\nof data required to achieve high performance.\\nEach model was trained using the Adam optimizer and categorical cross-entropy loss function. The\\ntraining was limited to 50 epochs with early stopping to prevent overfitting. The models were trained\\nwith careful monitoring to ensure they did not overfit, and training was halted when the validation\\nloss plateaued.\\n3.4 EVALUATION METRICS\\nThe models were evaluated using key metrics: accuracy, precision, and Area Under the Curve\\n(AUC). These metrics provided a comprehensive view of each model’s performance on the fine-\\ngrained classification task.\\n1. Accuracy: Accuracy measures the overall performance of the model by calculating the\\npercentage of correctly classified instances. It is defined as:\\n\\u200b\\n2. Precision: Precision assesses the model’s ability to avoid false positives by measuring the\\nproportion of true positives among the predicted positives. It is defined as:\\n3. Area Under the Curve (AUC): AUC evaluates the model's ability to distinguish between\\nclasses. It provides a balanced measure between True Positives (TP) and False Positives (FP)\\nacross various thresholds:\"),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 17}, page_content='17\\nIn terms of performance, EfficientNet and MobileNetv2 outperformed the other models due to their\\nlightweight architectures and efficient computation strategies. MobileNetv2, with its depth-wise\\nseparable convolutions, required fewer trainable weights and operations, allowing for high efficiency.\\nEfficientNet’s compound scaling method also optimized the model for both performance and\\ncomputational efficiency.\\nResNet50v2 demonstrated strong performance, leveraging its skip connections to handle deeper\\nmodels and capture complex patterns. However, VGG16, despite its depth, struggled with overfitting\\ndue to its large number of parameters and high computational demands, resulting in comparatively\\nlower accuracy.'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 18}, page_content=\"18\\n4 RESULTS AND DISCUSSIONS\\nThis project evaluated the performance of four deep learning models—MobileNetV2, ResNet50V2,\\nVGG16, and EfficientNet—for ship classification, using accuracy, precision, and AUC as key metrics.\\nResNet50V2 achieved the highest accuracy at 87.9%, closely followed by MobileNetV2 and\\nEfficientNet, both with 87.5%, demonstrating these models' strong feature extraction capabilities. In\\ncontrast, VGG16 lagged with an accuracy of 43.7%, likely due to its simpler architecture, which limits\\nits ability to distinguish fine-grained differences among ship types.\\nPrecision results showed a similar trend, with ResNet50V2 and MobileNetV2 leading at 90.5% and\\n90.3%, respectively, while EfficientNet scored 87.1%. VGG16 again underperformed with a precision\\nof 50%, indicating frequent misclassification. In terms of AUC, MobileNetV2 achieved the highest\\nscore at 99.3%, followed closely by EfficientNet at 99.2%, and ResNet50V2 at 98.5%, confirming\\ntheir reliability in distinguishing between classes. VGG16’s AUC of 80.5% further reflected its\\nlimitations in capturing complex patterns within the data.\\nOverall, ResNet50V2, MobileNetV2, and EfficientNet demonstrated effective and balanced\\nperformance across all metrics, highlighting the advantage of modern architectures with optimizations\\nlike residual connections and compound scaling. VGG16’s lower scores across all metrics underscore\\nthe importance of architectural complexity for accurate, fine-grained classification.\\nTable 4.1: Performance Analysis\\nModel Accuracy (%) Precision (%) AUC\\nMobileNetv2 87.5 90.3 99.3\\nResNet50v2 87.9 90.5 98.5\\nVGG16 43.7 50.0 80.5\\nEfficientNet 87.5 87.1 99.2\"),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 19}, page_content='19\\nFig 4.1: Accuracy Comparisons of Different Models\\nIn fig 4.1, the accuracy of ResNet50v2 was excellent and achieved an impressive 87.98% for most\\nship categories. On the other hand, VGG16 showed extremely low accuracy of 43.75 % (i.e\\nsignificantly lower accuracy as it has more difficulties differentiating closely related ship classes).\\n.\\nFig 4.2: Precision Comparisons of Different Models\\nIn fig 4.2,With a precision of 90.58%, it turns out that ResNet50v2 was quite reliable at predicting\\nfrom ship categories. On the other hand, VGG16 precision was 50.0%, showing a high rate of\\nmisclassifications.'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 20}, page_content='20\\nFig 4.3: AUC Comparisons of Different Models\\nAUC Comparisons the AUC overall score gives the amount by which the model can correctly\\nseparate between positive and negative classes at different thresholds. This is shown in Fig. 4.3\\nwhere the accuracy of MobileNetv2 with the maximum AUC score of 99.32% portrays a good\\ndiscriminating ability between the six ship categories. EfficientNet was right behind at a 99.25%\\nAUC, and a very good performance by ResNet50v2 at 98.51%. VGG16 shortly with an AUC of\\n80.50%.\\n.'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 21}, page_content=\"21\\n5 CONCLUSION AND FUTURE ENHANCEMENT\\n5.1 CONCLUSION\\nThis study focuses on the classification of six ship categories from the FGSC-23 dataset using four\\ndeep learning models: VGG16, ResNet50v2, EfficientNet, and MobileNetv2 are on the list. The\\nFGSC-23 dataset, famous for its in-depth classification and wealth of scenes, provided an ideal\\nplatform for assessing these model performances. Among the choices, ResNet50v2 excelled by\\nreaching an accuracy score of 87.98%, a precision rate of 90.58%, along with a high AUC score of\\n98.51%, which serves as potential evidence of its applicability for classifying the positive and\\nnegative categories with much certainty. MobileNetv2 saw 90.32% precision along with an AUC of\\n99.32%, both indicators which were approximately equal to EfficientNet's strong performance-to-\\nsize ratio measured at 99.25% AUC.\\nResNet50v2 has surpassed all networks repeatedly in both accuracy and precision, thus emerging as\\nthe favored option for maritime object classification, which requires accurate typology. The success\\nof VGG16 in image categorization tasks was not sufficient for the fine-grained classification\\nchallenge, resulting in an accuracy of 43.75% and 50.00% precision. Across the FGSC-23 dataset,\\nfindings show that ResNet50v2 is the leading model for ship classification, making it usable for real\\nmaritime applications in security, traffic management, and environmental monitoring.\\nInvestigations going forward might examine ensemble learning methods that fuse several models\\nfor better classification, along with expanding the analysis to represent all 23 vessel types in the\\nFGSC-23 dataset, improving both preprocessing and data augmentation to improve performance\\nand generalization.\\nIn the Future, the flexibility of the model can be increased by integrating supplementary ship\\nclasses from the complete FGSC-23 dataset or alternative resources.\\n5.2 FUTURE ENHANCEMENTS\\nThis project holds several promising avenues for future improvement. By implementing these\\nenhancements, we can increase model accuracy, reduce computational load, and broaden the\\napplicability of the ship classification system to real-world scenarios.\"),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 22}, page_content=\"22\\n1. Hyperparameter Optimization is an essential step to ensure that our model performs at its best.\\nCurrently, fixed values for hyperparameters like learning rate, batch size, and dropout rates are\\nused, but these may not be optimal. In the future, we can explore advanced hyperparameter\\ntuning techniques, such as Grid Search or Random Search. Tools like Optuna and Keras Tuner\\ncan automate this search, identifying the ideal combination of hyperparameters more efficiently\\nthan manual adjustments. This optimization could lead to improved model accuracy and\\npotentially reduce training time by minimizing the need for trial and error.\\n2. Another valuable enhancement would be to experiment with Additional Pretrained Models\\nbeyond those already employed. While we currently use VGG16, MobileNetV2, EfficientNet,\\nand ResNet50V2, other architectures like InceptionNet or DenseNet could offer unique\\nadvantages. For instance, DenseNet's connectivity pattern helps retain spatial information,\\nwhich may be beneficial for distinguishing fine details in ship images. Additionally, Vision\\nTransformers (ViT), known for excelling in vision tasks by capturing long-range dependencies,\\ncould further improve classification accuracy by focusing on critical features in different parts\\nof the image.\\n3. Integrating Attention Mechanisms could also improve the model’s ability to identify critical\\nfeatures. Techniques like Self-Attention or Squeeze-and-Excitation (SE) blocks allow the\\nmodel to focus more on important areas within the image, such as specific structures or\\nmarkings unique to each ship type. This could enhance classification performance, especially\\nfor classes that share similar shapes but have distinct details.\\n4. While basic data augmentation has already been applied, Advanced Data Augmentation\\nTechniques could further increase model robustness. Introducing sophisticated transformations\\nsuch as cutout, random erasing, or mixup can simulate more diverse conditions in the training\\ndata. These techniques would make the model less susceptible to minor variations in image\\norientation, lighting, or background, which could occur in real-world maritime environments.\"),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 23}, page_content='23\\n6 REFERENCES\\n[1] Q. Guo, Z. Wang, Y. Sun and N. Liu, \"Maritime Ship Target Detection Based on the\\nYOLOv7 Model,\" 2023 International Conference on Image Processing, Computer Vision and\\nMachine Learning (ICICML), Chengdu, China, 2023.\\n[2] S. Arull Murugan, S. Dharsini, S. Ganapathi Subramaniyan, M. Kumar, O. Ashok\\nLokhande and Y. Shankar Narayanan, \"A Non-Lethal System for Preventing Maritime\\nVessels from Invading or Evading Naval Perimeters,\" 2022 10th RSI International Conference\\non Robotics and Mechatronics (ICRoM), Tehran, Iran, 2022.\\n[3] Huang, Q., Sun, H., Guo, X., Yuan, Y., Wang, Y., Gao, Q.: Ship detection based on\\nYOLO algorithm for visible images. IET Image Process. 18, 481–492, 2024\\n[4] J. Si, B. Song, J. Wu, W. Lin, W. Huang and S. Chen, \"Maritime Ship Detection Method\\nfor Satellite Images Based on Multiscale Feature Fusion,\" in IEEE Journal of Selected Topics in\\nApplied Earth Observations and Remote Sensing, vol. 16, pp. 6642-6655, 2023.\\n[5] Zheng Y, Zhang Y, Qian L, Zhang X, Diao S, Liu X, et al. (2023) A lightweight ship\\ntarget detection model based on improved YOLOv5s algorithm. PLoS ONE 18(4): e0283932,\\n2023.\\n[6] Xinqiang Chen, Meilin Wang, Jun Ling, Huafeng Wu, Bing Wu, Chaofeng Li, Ship\\nimaging trajectory extraction via an aggregated you only look once (YOLO) model, Engineering\\nApplications of Artificial Intelligence, Volume 130, 2024\\n[7] Fang, Z.; Wang, X.; Zhang, L.; Jiang, B. YOLO-RSA: A Multiscale Ship Detection\\nAlgorithm Based on Optical Remote Sensing Image. J. Mar. Sci. Eng, 2024\\n[8] M. He, Z. Yin, J. Liu and Z. Yang, \"SD-YOLO: High-precision network for SAR ship\\ntarget detection,\" 2024 5th International Conference on Computer Vision, Image and Deep\\nLearning (CVIDL), Zhuhai, China, 2024.\\n[9] Huang, L.; Wang, F.; Zhang, Y.; Xu, Q. Fine-Grained Ship Classification by Combining\\nCNN and Swin Transformer. Remote Sens. 2022.\\n[10] Huang, I.-L.; Lee, M.-C.; Nieh, C.-Y.; Huang, J.-C. Ship Classification Based on AIS\\nData and Machine Learning Methods. Electronics 2024.'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 24}, page_content='24\\n[11] X. Xu, X. Zhang and T. Zhang, \"Multi-Scale SAR Ship Classification with Convolutional\\nNeural Network,\" 2021 IEEE International Geoscience and Remote Sensing Symposium\\nIGARSS, Brussels, Belgium, 2021.\\n[12] B. W. Tienin, C. Guolong and R. M. Esidang, \"Comparative Ship Classification in\\nHeterogeneous Dataset with Pre-trained Models,\" 2022 IEEE Radar Conference (RadarConf22),\\nNew York City, NY, USA, 2022.\\n[13] J. He, H. Xie, X. Jiang, Z. Wu and G. Wang, \"Ship Recognition Algorithm Based on\\nResNet in SAR Images,\" 2022 IEEE International Conference on Signal Processing,\\nCommunications and Computing (ICSPCC), Xi\\'an, China, 2022.\\n[14] W. Yu et al., \"Multi-Stage Marine Ship Recognition Based on Stackable Residual Network,\"\\n2023 19th International Conference on Natural Computation, Fuzzy Systems and Knowledge\\nDiscovery (ICNC-FSKD), Harbin, China, 2023.\\n[15] H. Fu, Y. Li, Y. Wang and P. Li, \"Maritime Ship Targets Recognition with Deep\\nLearning,\" 2018 37th Chinese Control Conference (CCC), Wuhan, China, 2018'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 25}, page_content='25\\n7 APPENDIX\\n7.1 A - CONFERENCE PRESENTATION\\nThis project has been accepted for presentation at SmartCom-2025-Pune, India and publication\\nin Springer LNNS series subject to fulfilment of Guidelines by Springer.'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 26}, page_content='26\\n7.2 B - PUBLICATION DETAIL\\n'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 27}, page_content='27\\n7.3 C - PLAGIARISM REPORT\\n')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PyPDF Loader for reading the text in pdf\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "pdf_loader=PyPDFLoader(\"Minor Project Report.pdf\")\n",
    "pdf_docs=pdf_loader.load()\n",
    "pdf_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pdf_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web based Loader\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "web_loader=WebBaseLoader(\"https://en.wikipedia.org/wiki/Ferrari\",\n",
    "                        bs_kwargs=dict(parse_only=bs4.SoupStrainer(\n",
    "                            class_=(\"mw-page-title-main\",\"mw-default-size\")))\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://en.wikipedia.org/wiki/Ferrari'}, page_content=\"FerrariThree Scuderia Ferrari cars in 1934, all Alfa Romeo P3s. Drivers, left to right: Achille Varzi, Louis Chiron, and Carlo Felice Trossi.Ferrari's factory in the early 1960s: everything in its production line was handmade by machinists, who followed technical drawings with extreme precision.[13] Much of this work is now done by industrial robots.[14]A Ferrari F2004 Formula One car, driven by Michael Schumacher. Schumacher is one of the most decorated drivers in F1 history.A 312 P, driven by Jacky Ickx, during Ferrari's final year in the World Sportscar ChampionshipFerrari 499P No. 51 at the 2023 6 Hours of Spa-Francorchamps166 Inter Touring BerlinettaEnzo FerrariFerrari Pinin1963 Ferrari 250 GTOTifosi flying Prancing Horse flags at the 2003 Italian Grand PrixA Ferrari 550 painted in rosso corsa. Both varieties of the Prancing Horse logo are present: the shield is located in front of the door, the rectangle is on the bonnet. The horse alone can also be found on the wheels, grille, and seats.A pink Ferrari 360. Ferrari offers no pink paint from the factory, and has discouraged its customers from customising their cars in a manner contrary to the company's brand image.\")]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Arxiv paper loader\n",
    "from langchain_community.document_loaders import ArxivLoader\n",
    "docs=ArxivLoader(query=\"2411.03403\",load_max_docs=2).load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Published': '2024-11-05', 'Title': 'Enhancing Maritime Situational Awareness through End-to-End Onboard Raw Data Analysis', 'Authors': 'Roberto Del Prete, Manuel Salvoldi, Domenico Barretta, Nicolas Longépé, Gabriele Meoni, Arnon Karnieli, Maria Daniela Graziano, Alfredo Renga', 'Summary': 'Satellite-based onboard data processing is crucial for time-sensitive\\napplications requiring timely and efficient rapid response. Advances in edge\\nartificial intelligence are shifting computational power from ground-based\\ncenters to on-orbit platforms, transforming the\\n\"sensing-communication-decision-feedback\" cycle and reducing latency from\\nacquisition to delivery. The current research presents a framework addressing\\nthe strict bandwidth, energy, and latency constraints of small satellites,\\nfocusing on maritime monitoring. The study contributes three main innovations.\\nFirstly, it investigates the application of deep learning techniques for direct\\nship detection and classification from raw satellite imagery. By simplifying\\nthe onboard processing chain, our approach facilitates direct analyses without\\nrequiring computationally intensive steps such as calibration and\\northo-rectification. Secondly, to address the scarcity of raw satellite data,\\nwe introduce two novel datasets, VDS2Raw and VDV2Raw, which are derived from\\nraw data from Sentinel-2 and Vegetation and Environment Monitoring New Micro\\nSatellite (VENuS) missions, respectively, and enriched with Automatic\\nIdentification System (AIS) records. Thirdly, we characterize the tasks\\'\\noptimal single and multiple spectral band combinations through statistical and\\nfeature-based analyses validated on both datasets. In sum, we demonstrate the\\nfeasibility of the proposed method through a proof-of-concept on CubeSat-like\\nhardware, confirming the models\\' potential for operational satellite-based\\nmaritime monitoring.'}, page_content='Enhancing Maritime Situational Awareness by End-to-End\\nOnboard Raw Data Analysis⋆,⋆⋆\\nRoberto Del Prete*a,b, Manuel Salvoldia,c, Domenico Barrettaa,d, Nicolas Longépéa,\\nGabriele Meonia,e, Arnon Karnielic, Maria Daniela Grazianob and Alfredo Rengab\\naΦ-Lab, European Space Agency, Via Galileo Galilei 1, Frascati, 00044, Rome, Italy\\nbDepartment of Industrial Engineering, University of Naples Federico II, P.le Vincenzo Tecchio 80, 80125, Napoli, Italy\\ncBen-Gurion University of the Negev, Sede Boker Campus, 8499000, Negev, Israel\\ndDepartment of Engineering, University of Campania “L. Vanvitelli”, Via Roma 29, 81031, Caserta, Italy\\neAdvanced Concepts and Studies Office, European Space Agency, Via Galileo Galilei 1, Frascati, 00044, Rome, Italy\\nA R T I C L E I N F O\\nKeywords:\\nSentinel-2\\nVENµS\\nRaw MultiSpectral Data\\nVessel Detection\\nVessel Classification\\nOnboard Processing\\nA B S T R A C T\\nSatellite-based onboard data processing is crucial for time-sensitive applications requiring\\ntimely and efficient rapid response. Advances in edge artificial intelligence are shifting com-\\nputational power from ground-based centers to on-orbit platforms, transforming the \"sensing-\\ncommunication-decision-feedback\" cycle and reducing latency from acquisition to delivery.\\nThe current research presents a framework addressing the strict bandwidth, energy, and latency\\nconstraints of small satellites, focusing on maritime monitoring. The study contributes three main\\ninnovations. Firstly, it investigates the application of deep learning techniques for direct ship\\ndetection and classification from raw satellite imagery. By simplifying the onboard processing\\nchain, our approach facilitates direct analyses without requiring computationally intensive steps\\nsuch as calibration and ortho-rectification. Secondly, to address the scarcity of raw satellite\\ndata, we introduce two novel datasets, VDS2Raw and VDV2Raw, which are derived from\\nraw data from Sentinel-2 and Vegetation and Environment Monitoring New Micro Satellite\\n(VENµS) missions, respectively, and enriched with Automatic Identification System (AIS)\\nrecords. Thirdly, we characterize the tasks’ optimal single and multiple spectral band combi-\\nnations through statistical and feature-based analyses validated on both datasets. In sum, we\\ndemonstrate the feasibility of the proposed method through a proof-of-concept on CubeSat-like\\nhardware, confirming the models’ potential for operational satellite-based maritime monitoring.\\n1. Introduction\\nConsidering the enormous impact on maritime applications, the efficient and timely recognition of vessels using\\nEarth Observation (EO) satellite imagery is imperative for scenarios requiring rapid response. Applications such\\nas traffic and environmental monitoring, emergency search and rescue operations, and detecting illegal fishing or\\nsmuggling require rapid, low-latency responses to be effective. The traditional data processing chains based on the\\nclassical bent-pipe approaches [1, 2] face significant challenges in addressing these needs due to several inherent\\nlimitations, such as the increased latency for data download, ground station availability and high-level product\\ncalculation, thereby incurring substantial delays from image acquisition to information delivery [3]. Additionally, the\\nneed to transmit satellite data to Earth strains the available communication bandwidth [1, 2].\\nAI can enable real-time data processing, reducing the need for large data transfers to Earth and accelerating response\\n∗Corresponding author\\nORCID(s): 0000-0003-0810-4050 (R. Del Prete*); 0000-0001-5810-6156 (M. Salvoldi); 0000-0001-0000-0000 (D. Barretta);\\n0000-0001-0000-0000 (N. Longépé); 0000-0001-9311-6392 (G. Meoni); 0000-0001-8065-9793 (A. Karnieli); 0000-0001-0000-0000\\n(M.D. Graziano); 0000-0002-1236-0594 (A. Renga)\\nR. Del Prete et al.: Preprint submitted to Elsevier\\nPage 1 of 38\\narXiv:2411.03403v1  [cs.CV]  5 Nov 2024\\nEnhancing Maritime Situational Awareness through End-to-End Onboard Raw Data Analysis\\ntimes to various events [4]. A growing body of research is focused on leveraging Artificial Intelligence (AI) onboard\\nsatellites to retrieve actionable information for latency-sensitive applications quickly. This includes natural disaster\\nresponse [5, 6, 3] and the detection of anomalies or targets in localized areas [7, 8]. The increasing interest in this area\\nis further demonstrated by the rising number of companies and research institutes worldwide developing advanced edge\\nAI avionics subsystems for CubeSats [9]. Recent missions, such as ΦSat-2 [10], Intuition-1 by KP Labs, CogniSAT-\\n6U by Ubotica [11], and Kanyini by SmartSat CRC [12], showcase the growing commitment to AI-enabled satellite\\ntechnology. These missions utilize AI-enabled processing units, demonstrating the significant advantages of AI in\\nenhancing real-time maritime surveillance and other critical applications. This trend underscores the pivotal role of\\nonboard AI as the key to revolutionizing maritime monitoring and response, providing faster, more accurate, and more\\nefficient operations in the ever-challenging maritime domain.\\nPast satellite missions, such as Φ-Sat-1 [2] and HYPSO-1 [13], relied on extensive pre-processing workflows, including\\ngeometric and radiometric corrections, to prepare data for onboard Machine Learning (ML) applications. Φ-Sat-1,\\nfor example, implemented a Convolutional Neural Network (CNN) on an Intel® Movidius™Myriad™2 Vision\\nProcessing Unit (VPU), processing selected hyperspectral bands after creating the hyperspectral data cube and\\nperforming band-to-band spatial registration. Similarly, HYPSO-1 employed a hyperspectral payload to monitor ocean\\ncolor, requiring onboard image processing that involved linear radiometric and geometric corrections.\\nAlthough current research is advancing towards novel technologies, particularly in Deep Learning (DL), few attention\\nhas been dedicated to the pre-processing stage, which continues to mimic traditional ground-based workflows. The re-\\nliance on such demanding schemes necessitates specialized hardware on orbit which increases payload complexity and\\nresource utilzation. Therefore, to optimize onboard resource usage while providing real-time actionable information,\\nit is essential to bypass all unnecessary pre-processing steps, realising models that can analyse raw imagery. Tackling\\nthis issue poses several challenges, including hardware and energy limitations, resource efficiency of ML models, but\\nalso the scarcity of available raw data datasets.\\nThe very first direct attempt to process raw data end-to-end for onboard machine learning was made during the “OPS-\\nSAT Case” competition [14, 15], hosted on the European Space Agency (ESA) Kelvins platform, which focused on\\nfew-shot learning for satellite applications. This effort represented a significant shift from previous missions, directly\\ntackling the challenges of onboard raw data processing. Building on this, Meoni et al. [16] developed a methodology for\\ncreating raw datasets using Sentinel-2 (S-2) imagery, providing the first raw dataset of thermal hotspots. Continuing this\\ntrend, Del Prete et al. [8] introduced VDS2Raw, a dataset specifically designed for vessel detection using raw S-2 data,\\noffering a comparative analysis of various DL techniques for the task. ΦSat-2 [10] offers the possibility of processing\\nLevel-1A (L1A) data on board thanks to an advanced data processing framework for generating multispectral and\\nR. Del Prete et al.: Preprint submitted to Elsevier\\nPage 2 of 38\\nEnhancing Maritime Situational Awareness through End-to-End Onboard Raw Data Analysis\\npanchromatic imagery at three distinct levels 1. Emphasizing on this innovative apporach of raw data exploitation, the\\nOrbital AI challenge [17] was the first to explore onboard AI applications with raw satellite data simulated.\\nThis manuscript builds upon the aforementioned works and makes several novel key contributions:\\n1. End-to-End Workflow: This work presents the first fully integrated end-to-end workflow for onboard vessel\\nidentification (detection and classification), streamlining the process from data acquisition to information\\ndelivery, thereby reducing latency and improving the efficiency of maritime surveillance operations.\\n2. Dataset Creation: Two new datasets of raw, uncalibrated multispectral data for vessel detection & classification\\nhave been created, incorporating additional Automatic Identification System (AIS) information and a novel\\nannotation format that includes both bounding boxes and AIS records. These datasets are built from two different\\nEO space missions with different characteristics\\n3. Spectral Band Analysis: Through the application of DL techniques on the developed datasets, the study\\nidentifies the most useful raw spectral bands across the spectrum for vessel detection and classification, providing\\ninsights into the performance across different geographic areas, sensors, and resolutions.\\n4. Onboard Implementation: A proof-of-concept for onboard implementation is demonstrated using an AI edge\\ndevice with flight heritage, such as CogniSAT-6 [11, 18]. This deployment, tested under varying sensor operating\\nconditions, confirms the feasibility of real-time and efficient maritime surveillance.\\nThe remainder of the paper is organized as follows. Section 2 details the data creation and curation strategy for\\nthe two raw multispectral datasets designed for vessel detection and classification, enriched with AIS information.\\nSection 3 discusses the proposed methodology, focusing on the cascaded application of coregistration and DL-\\nbased detection techniques. Section 4 presents the results obtained from the developed datasets, highlighting the\\ngeneralization and applicability of the proposed approach to several multispectral bands. Section 5 is dedicated to the\\nonboard implementation, showcasing a proof-of-concept demonstration by representative hardware. Finally, Section 6\\nprovides a discussion of the results and concludes the paper.\\n2. Datasets Creation Strategy\\nThis section details the development of raw multispectral datasets. The two selected space missions are initially\\npresented, i.e., Sentinel-2 and VENµS. Then, inherent characteristics and challenges associated with raw data are\\nexamined, and a corresponding solution is proposed. Subsequently, the data acquisition and labelling strategy are\\nreported along with the characteristics of the datasets derived from the two imagers. Concluding the section, the\\nproblem of matching AIS records with remote sensing data is addressed.\\n1The L1A product provides Top Of Atmosphere (TOA) radiance without geo-referencing or band alignment, while Level 1B enhances this\\nwith precise geo-referencing and band alignment. Level 1C delivers TOA reflectance with fine geo-referencing and band alignment, though it lacks\\northorectification.\\nR. Del Prete et al.: Preprint submitted to Elsevier\\nPage 3 of 38\\nEnhancing Maritime Situational Awareness through End-to-End Onboard Raw Data Analysis\\n2.1. The Sentinel-2 and VENµS Missions\\nThe Sentinel-2 mission, an integral component of the European Union’s Copernicus program, comprises three\\nsatellites: Sentinel-2A, which was launched in June 2015, Sentinel-2B, launched in March 2017, and Sentinel-2C,\\nrecently deployed on 5 September 2024. These satellites are designed for high-resolution, multispectral imaging of\\nEarth’s land and coastal areas. Sentinel-2 satellites operate in a sun-synchronous orbit with a 290 km swath width\\nand a revisit time of 5 days at the Equator. Each satellite is equipped with a MultiSpectral Instrument (MSI) that\\ncaptures 13 spectral bands at different spatial resolutions: four bands at 10 meters (𝐵2, 𝐵3, 𝐵4, 𝐵8), six bands at\\n20 meters (𝐵5, 𝐵6, 𝐵7, 𝐵8𝐴, 𝐵11, 𝐵12), and three bands at 60 meters (𝐵1, 𝐵9, 𝐵10). These capabilities allow for\\ndetailed observation of vegetation, soil, water cover, and changes in land use. Data products from S-2 are available at\\ndifferent processing levels: Level-1C (top-of-atmosphere reflectance), Level-2A (bottom-of-atmosphere reflectance),\\nand higher-level products. The MSI mounts 12 detectors in a staggered configuration, chosen for achieving an high\\nswathwidth. Each detector produces a granule containing the aforementioned spectral bands. As defined in [3], Level-0\\n(L0) data refers to the sensor-acquired information that has been equalized and compressed onboard the satellite before\\nbeing transmitted to the ground. After downlinking, this data is decompressed and supplemented with metadata, but\\nit remains unprocessed in terms of geometric and radiometric correction2. We refer to this data as raw data, thus,\\nrepresenting the earliest stage of the processing chain after decompression, preceding further refinement steps such as\\nco-registration, radiometric calibration, ortho-rectification, required for the generation of higher level products. The\\nonly publicly available datasets of raw S-2 data are those provided in our previous works [3, 8], as L0 products are\\ngenerally not distributed to the public.\\nThe VENµS mission, a collaboration between the Israel Space Agency (ISA) and the French Space Agency (CNES), has\\nbeen in sun-synchronous LEO since August 2017, acquiring multispectral imagery every two days over 120+ sites at 5-\\nmeter resolution, covering the visible (VIS) to near-infrared (NIR) spectrum for environmental and scientific research.\\nThe VENµS MSI, i.e., the VENµS SuperSpectral Camera (VSSC), provide observations with high spatial, temporal,\\nand spectral resolutions [19], [20], [21]. The VSSC is a push broom imager comprising a catadioptric objective (0.25\\nm in diameter), a focal plane (1.75 m in length) assembly with narrow-band filters, and four detector units with three\\nseparate charge-coupled device-time delay integration (Charge-Coupled Device (CCD)-Time Delay Integration (TDI))\\narrays each one containing the sensing capability for three spectral bands. The first detector (A) includes bands 𝐵1, 𝐵2,\\nand 𝐵5; the second (B) includes bands 𝐵10, 𝐵11, and 𝐵12; the third (C) includes bands 𝐵7, 𝐵8, and 𝐵9; and the fourth (D)\\nincludes bands 𝐵3, 𝐵4, and 𝐵6. This configuration results in a pre-scheduled capture of all 12 spectral bands during each\\nmultispectral image acquisition. Three product levels are available: Level-1C (L1C), Level-2A (L2), and Level-3 (L3,\\n10-day L2 composites) [22]. L0 products are archived but have never been disseminated to end-users. Nevertheless, the\\n2Further details are available in the S-2 Product Specification Document (PSD v15): https://sentinel.esa.int/documents/d/\\nsentinel/s2-pdgs-cs-di-psd-v15-0\\nR. Del Prete et al.: Preprint submitted to Elsevier\\nPage 4 of 38\\nEnhancing Maritime Situational Awareness through End-to-End Onboard Raw Data Analysis\\nRemote Sensing Laboratory3 at Ben Gurion University of the Negev processes, archives, and disseminates products\\nfor three Israeli sites. These latter have been exploited to develop two novel comprehensive datasets detailed in the\\nupcoming section of this manuscript.\\nFinally, the Figure 1 compares the spectral responses of the MSIs of VENµS and S-2, highlighting their similarities\\nand differences.\\nFigure 1: Graphical comparison of the normalized spectral responses between the MSI on the VENµS satellite (top) and the\\nS-2 (bottom) highlighting key differences in their spectral band coverage. Specifically, the VENµS bands 𝐵𝑖(𝑖= 1, 5, 6, 12)\\ndo not have corresponding bands in the S-2 imager. Conversely, bands 𝐵8 and 𝐵9 of S-2 are absent in VENµS, indicating\\nthat each MSI is optimized for different spectral features.\\n2.2. Raw Data Characteristics\\nAs discussed earlier, most of literature focuses on methods applied to high-level products, due to the limited use and\\navailability of raw data. Consequently, approaches for handling raw data remain relatively new and underdeveloped, as\\nworking with raw data introduces unique and often uncharted challenges. In this section, we outline these challenges\\nand propose effective solutions to address them.\\nIt is essential to recognize that the L0 bands represent raw, decompressed data in its most fundamental form. As such,\\nthey do not undergo the standard ground segment processing pipeline, which includes computationally-intensive tasks\\nsuch as calibration, ortho-rectification, and georeferencing; processing required to generate an L1C product. Indeed,\\n3https://karnieli-rsl.com/\\nR. Del Prete et al.: Preprint submitted to Elsevier\\nPage 5 of 38\\nEnhancing Maritime Situational Awareness through End-to-End Onboard Raw Data Analysis\\nthey exhibit various forms of radiometric noise and artifacts (Figure 2). In the case of VENµS, this noise is particularly\\npronounced, including effects such as stray light [23] or signal non-uniformity across the camera detectors’ pixels and\\nfixed pattern noise (stripe noise). This spatially coherent kind of noise is typically found in multispectral data [24]\\nand arises from improper correction of the CCD response function, owing to unexpected temperature changes on the\\nphotoelectric system [25]. Lastly, an unusual artifact, termed “radiometric spike” was identified in VENµS images by\\n[26]. These spikes affect hundreds of pixels across all spectral bands, both in-flight and during ground measurements,\\nshowing an offset variation dependent on incoming radiance. The spikes’ amplitude and location vary by spectral band,\\nbut their shape remains consistent. Each spike influences four consecutive pixels oppositely based on their position in\\nthe left or right register, and their locations are stationary between ground and in-flight observations. The Figure 2(a-b)\\nclearly shows the artifacts and noise affecting VENµS imagery.\\nFor what concerns S-2 images, the data do not present the same level of noise and artifacts of VENµS MSI as the\\nFigure 2(c-d) highlights. This is due to onboard equalization, aimed at enhancing the compression rates, that takes into\\naccount dark signal variations and inter-pixel offsets [27, 28].\\nWhile noise and artifacts can be effectively managed by the robust generalization capabilities of DL methods, the lack\\nof band alignment poses more significant challenges. Specifically, (a) models may lose crucial spatial information,\\npotentially undermining the accuracy of the analysis, and (b) annotations, especially at the pixel and box levels,\\ndemand meticulous attention to ensure consistent accuracy across all spectral bands. The ability of DL to handle noise\\nand artifacts is crucial, but precise band alignment remains critical for maintaining spatial coherence and annotation\\nintegrity. The issue becomes particularly pronounced for small objects like vessels, where even minor discrepancies,\\nsuch as 1-pixel shift, can substantially impact the model performance (refer to Section 4.1).\\n(a)\\n(b)\\n(c)\\n(d)\\nFigure 2: (a) Unequalized VENµS L0 image of the Ebro Delta, showing significant stray light artifacts in band 𝐵2, which\\naffects the visibility of underlying features. (b) Striping noise observed in band 𝐵2 of the VENµS L0 image captured over\\nthe port of Ashdod, illustrating the impact of lack of calibration on coastal imagery. (c) Radiometric noise present in band\\n𝐵3 of the S-2 L0 image over an algal bloom area, highlighting the challenges of detecting subtle biological features amidst\\nsensor noise. (d) Radiometric noise detected in band 𝐵3 of the S-2 L0 image over the Danish Fjord, demonstrating the\\neffects of sensor-induced noise on the accurate interpretation of aquatic environments.\\nR. Del Prete et al.: Preprint submitted to Elsevier\\nPage 6 of 38\\nEnhancing Maritime Situational Awareness through End-to-End Onboard Raw Data Analysis\\n2.3. Data Acquisition and Labelling\\nThe data acquisition and labeling strategy is structured according to the algorithmic procedure outlined by Meoni\\net al. [3]. Initially, external information relevant to the task, specifically AIS records, is collected. This is followed by\\nutilizing L1C data for labeling, where the L1C images facilitate the clear visual detection of vessels and the retrieval of\\ntheir latitude and longitude coordinates. Subsequently, a robust image matching technique [29] is employed to transpose\\nthe annotations from L1C to L0. Even though residual errors may occur due to inaccuracies in L0-L1C matching\\nor band-to-band coregistration residual errors. To address these labelling inconsistency, we propose a coarse-to-fine\\nbounding box strategy: we initially label the vessels with a coarse approximation, followed by applying an automated\\nbounding box fitting technique to refine the accuracy across spectral bands. Specifically, we optimize the bounding\\nbox fit to the vessel using information derived from four distinct masking techniques. These techniques include Otsu,\\nLi, Isodata, and Mean thresholding methods, and are used to separate foreground from background pixels.\\nOtsu’s Method [30] exploits the intra-class variance to segment vessels assuming that the image contains two classes\\nof pixels, it calculates the threshold that separates these classes such that the intra-class variance is minimized. Li’s\\nMethod [31] is an iterative approach to refining the threshold. It starts with an initial guess and iteratively updates\\nthe threshold based on a relationship that adjusts for differences between the current threshold and a function of it.\\nThe Isodata Method [32], also known as the Riddler-Calvar method, is another iterative scheme that determines the\\nthreshold by calculating the means of pixel intensities that fall below and above the current threshold value. This process\\ncontinues until the threshold converges to a stable value. Finally, the Mean Thresholding [33] is a straightforward\\nmethod where the threshold is simply set as the average intensity of all pixels in the image. The equations for each of\\nthese methods are presented below:\\nOtsu ∶\\n𝑡= argmin\\n𝑡\\n[\\n𝜔bg(𝑡)𝜎2\\nbg(𝑡) + 𝜔fg(𝑡)𝜎2\\nfg(𝑡)\\n]\\n;\\nLi ∶\\n𝑡𝑖+1 = 𝑡𝑖+ 𝑡𝑖−Li(𝑡𝑖)\\n1 + Li(𝑡𝑖) ;\\nIsodata ∶\\n𝑡= 𝑚𝐿(𝑡) + 𝑚𝐻(𝑡)\\n2\\n;\\nMean ∶\\n𝑡= 1\\n𝑁\\n𝑁\\n∑\\n𝑖=1\\n𝑥𝑖\\n(1)\\nNotably, the terms used in the equations are defined as follows: 𝜔bg(𝑡) and 𝜔fg(𝑡) represent the probabilities of the\\nbackground and foreground classes, respectively. The 𝜎2\\nbg(𝑡) and 𝜎2\\nfg(𝑡) denote the variances of the background and\\nforeground classes. The terms 𝑚𝐿(𝑡) and 𝑚𝐻(𝑡) are the means of the lower and higher intensity classes, respectively.\\nFinally, 𝑁is the total number of pixels, and 𝑥𝑖represents the intensity of the 𝑖-th pixel.\\nAfter thresholding, we then retain the pixels that are present in at least two of the segmentation maps (see Figure 3).\\nR. Del Prete et al.: Preprint submitted to Elsevier\\nPage 7 of 38\\nEnhancing Maritime Situational Awareness through End-to-End Onboard Raw Data Analysis\\nFigure 3: Bounding box fitting of a label in the 𝐵6 band (VENµS MSI). Image gathered over the port of Ashdod on\\n2020/01/06. The vessel, identified by MMSI 636019532, is a Container Ship with a length of 159.8 meters and a width of\\n24.8 meters. The ship was located at a longitude of 34.58744 and a latitude of 31.8442 at the time of the capture.\\nIn the end, we iterate this step for each spectral band, producing an accurate vessel annotation within the L0 data for\\neach of the spectral band under analysis.\\nIn this manner, the two novel datasets have been compiled from scratch using VENµS and Sentinel-2 MSIs, each\\ncovering distinct geographic regions, as illustrated in Figure 4(a).\\nThese datasets cope to two specific tasks, namely detection and classification, obtained thanks to the AIS ancillary\\ndata, consisting of information like the MMSI, vessel type, dimensions (length and width), status, speed, position\\n(longitude, latitude) and timestamp for each available vessel. It is important to acknowledge that AIS time intervals do\\nnot provide real-time ship data, due to the storage data policy of AIS vendors. Thus, in certain navigation scenarios,\\nsuch as in narrow waterways, regions with high ship exchange flow density, or areas with extremely low navigation\\nactivity, AIS may become unreliable or invalid.\\nThe next following paragraphs present the distinct characteristics of the VENµS and Sentinel-2 raw datasets, describing\\ntheir mutual differences and highlighting their potential for scientific research.\\n2.3.1. Sentinel-2 Dataset (VDS2Raw)\\nBuilding upon our previous study [8], where we introduced the first raw multispectral dataset (VDS2Raw dataset),\\nwe employed the methodology outlined in our earlier work on THRawS [16]. In the study, we identified a reference\\ndataset comprising Sentinel-2 L1C products containing vessels. We utilized the dataset by Ruiloba et al. [34], which\\nincludes Sentinel-2 L1C tiles from 2019, acquired in Danish coastal areas. To compile the dataset, we used a polygon\\nsurrounding the Region of Interest (ROI) that included all ships for each of the eight acquisition days. We applied a\\nsufficient margin to ensure that all the relevant bands were downloaded. This process led to the download of 390 L0\\ngranules, which we then decompressed to obtain raw processable data. For labelling the dataset, we considered bands 𝐵𝑖\\nR. Del Prete et al.: Preprint submitted to Elsevier\\nPage 8 of 38\\nEnhancing Maritime Situational Awareness through End-to-End Onboard Raw Data Analysis\\nFigure 4: Graphical representation of the geographical coverage by the S-2 and VENµS datasets (a). The histograms\\nillustrate the distribution of bounding boxes area and aspect ratio, offering a clear view of the training, validation, and test\\ndatasets for S-2 (b) and VENµS (c) missions.\\n(𝑖= 2, 3, 4), using band 𝐵2 serving as the reference for manual annotation. We created bounding boxes around each ship\\nmanually. To facilitate manual labelling, we used the coarse spatial coregistration technique described in our previous\\nwork [16]. We filled missing elements caused by the coregistration procedures using pixels from adjacent granules when\\npossible [16]. In cases where this was not possible, we cropped the areas with missing pixels, resulting in granules with\\ndifferent pixel areas. After labelling, we selected 166 raw granules from the initial 390 downloaded granules. We split\\nthese into training (105), validation (27), and test (34) sets, with the number of annotations being 483, 119, and 93,\\nrespectively. The average granule size in the dataset is approximately estimated as 2588.9 px×1669.4 px, while the mean\\nbounding boxes size is 13.59 px×15.67 px. As stated above, this process ensured that we had a comprehensive dataset,\\nalthough it introduced variability in granule sizes due to the coregistration adjustments. Further details regarding the\\ncreation of the initial version of VDS2Raw are available in [8].\\nCompared to the preliminary version, we have implemented several enhancements to increase its utility for the scientific\\ncommunity. Here, we introduce VDS2Raw (v2), which will henceforth be referred to as VDS2Raw throughout this\\nR. Del Prete et al.: Preprint submitted to Elsevier\\nPage 9 of 38\\nEnhancing Maritime Situational Awareness through End-to-End Onboard Raw Data Analysis\\npaper. First, we have expanded the dataset by incorporating additional ancillary AIS records. The AIS data come\\ndelivered free by the Danish government4. This AIS source is particularly valuable due to its per-second sampling\\naccuracy, which significantly enhances temporal resolution. Second, we have included the 𝐵8 band, providing an\\nadditional spectral band at 10m spatial resolution. This enhancement allows for more detailed and accurate analysis of\\nthe multispectral imagery, improving object detection and classification capabilities. We offer a more comprehensive\\nand precise dataset by incorporating these improvements, facilitating more robust scientific research and applications.\\nThe vessel width and length distribution as the vessel classes are reported in Figure 5 (a). How it is possible to observe,\\nthe majority of vessels have a width of less than 10m with length of roughly 25m. The predominant ship classes are\\nCargo, Tanker, and Fishing type, as shown in Figure 5 (c).\\n2.3.2. VENµS Dataset (VDVRaw)\\nThe Vessel Detection from VENµS Raw (VDVRaw) is created using the ROI encompassing the open sea adjacent\\nto the port of Ashdod in Israel (Figure 4 (a)). The VENµS MSI captured imagery of this ROI approximately every two\\ndays at around 8:30 UTC during the initial phase of its scientific mission. AIS data for vessels within the ROI was\\nsourced from a maritime analytics provider5. However, the dataset presents a notable limitation: it only provides one\\nAIS record per vessel per day within the ROI, typically recorded around midnight UTC. Consequently, information\\nregarding a vessel’s position at the precise moment the spacecraft sensed the ROI is unavailable. Nonetheless, it is\\ncommon for vessels to remain stationary for extended periods, often several days, as they await authorization from port\\nauthorities to enter the port. This standard procedure enables port authorities to schedule maritime traffic efficiently\\nbased on the characteristics of the ships and prevailing conditions [35].\\nThe database compiled for this study includes 3,827 vessels with bounding box labels in 282 multispectral images\\ncaptured during the VENµS first mission phase. Among these vessels, 2,733 (71.4%) have corresponding AIS records\\nin the MarineTraffic database. The AIS database categorizes these vessels into 18 different types. The Figure 5 (b)\\nprovides statistics on the length and width of vessels in the training validation and test dataset. Figure 5 (d) instead\\nshows a bar plot counting each category reported in the AIS database. As shown, the categories are quite unbalanced\\ntoward the General Cargo class, with consequently more vessel dimension towards the length 100m and 15m of width,\\nfor all the datasets.\\nThe database further incorporates flags (𝐹𝑙) to indicate several vessel characteristics: presence of visible wakes (𝐹𝑙=1),\\ncloud cover (𝐹𝑙=3), location on the image border (𝐹𝑙=2), and proximity to other vessels (𝐹𝑙=7). These flags can be\\ncombined to provide richer information about each vessel. The distribution of vessel counts by flag is as follows: 3,264\\nvessels (85.3%) had no specific flag, 457 vessels (11.9%) had visible wakes, 21 vessels (0.5%) were located on the\\n4https://web.ais.dk/aisdata/\\n5MarineTraffic: www.marinetraffic.com\\nR. Del Prete et al.: Preprint submitted to Elsevier\\nPage 10 of 38\\nEnhancing Maritime Situational Awareness through End-to-End Onboard Raw Data Analysis\\nimage border, 74 vessels (1.9%) were under cloud cover, 4 vessels (0.1%) were in proximity to other vessels, 1 vessel\\n(0.0%) had both cloud and wake flags, and 6 vessels (0.2%) had both proximity and wake flags. The final product of\\nthis process is a comprehensive dataset with AIS and ancillary information appended.\\n2.3.3. Dataset Comparison\\nAs stated above, the two datasets encompass distinct geographical regions and span discrete time periods. As the\\nFigure 5 displays, the vessel type distribution is quite dissimilar. In addition, despite the similar spectral responses of\\nthe bands under analysis (Fig. 1), their overall characteristics differ significantly.\\nAlthough the predominant vessel classes in the VDS2Raw (v2) dataset remain Tanker and Cargo, this dataset\\nencompasses a broader range of vessel types, including those that typically operate at higher speeds, such as Sailing,\\nSAR, and Fishing vessels. This variation is primarily attributed to the distinct AIS records type utilized.\\nVENµS boasts superior spatial resolution compared to the MSI of Sentinel-2, although it exhibits increased noise levels\\nand artifacts in the acquired images. Additionally, compared to S-2, the AIS used for VDVRaw has been gathered with\\nminor timing accuracy (once a day), further contributing to highlight the differences between the two. The purpose of\\nthis study is not to emphasize differences in model performance between the two datasets, but rather to highlight the\\nsimilarities in how the models behave when applied to different types of raw data across distinct tasks. In summary,\\nthe goal of the present manuscript is to offer a representative analysis of model behavior when handling various kinds\\nof raw data. The differences between these two aforementioned data are summarised in the Table 1.\\n2.3.4. AIS Records\\nAIS records are essential for tracking maritime vessels, but they present several challenges. Firstly, data providers\\ntypically sample AIS messages at intervals of several minutes, leading to gaps in continuous tracking and historical\\nAIS records are often maintained only with a low frequency, further limiting their effectiveness for retrospective\\nFigure 5: The AIS characteristics of the raw vessel datasets analyzed through various statistical visualizations. Histograms\\nand kernel density estimates of length and width distributions are presented across training, validation, and test subsets for\\nboth the VDS2Raw (a) and VDVRaw (b) datasets. Additionally, bar plots (c) and (d) illustrate the frequency distribution\\nof each vessel category within the VDS2Raw and VDVRaw datasets, respectively.\\nR. Del Prete et al.: Preprint submitted to Elsevier\\nPage 11 of 38\\nEnhancing Maritime Situational Awareness through End-to-End Onboard Raw Data Analysis\\nTable 1\\nComparative table showing the differences between the VDS2Raw and VDVRaw datasets.\\nAttribute\\nSentinel-2\\nVENµS\\nDataset Name\\nVDS2Raw (Official)\\nVDVRaw\\nSource\\nRaw granules from Sentinel-2 products\\nImages from VENµS satellite sensors\\nSpatial Resolution\\n10m\\n5.3m at Nadir\\nSpectral Bands\\n𝐵2, 𝐵3, 𝐵4, 𝐵8\\n12, spanning visible to NIR\\nReference Dataset\\nRuiloba et al.[34]\\nFrom scratch\\nArea of Focus\\nDanish Fjords\\nPort of Ashdod, Israel\\nTime Period\\n2019\\n2018 to end of October 2020\\nLabeling\\nManual, Polygons\\nSemi-Manual, Bounding Boxes\\nAIS Included\\nYes\\nYes\\nSample Size (Avg)\\n2588.9 px × 1669.4 px\\n2798 px × 1929 px\\nBBox Size (Avg)\\n13.59 px × 15.67 px\\n14.32 px × 17.80\\nReference Band\\n𝐵2\\n𝐵5\\nCoregistration\\nTechnique\\nCoarse Spatial (Meoni et al. (2023))\\nAffine Transform (SIFT)\\nN. Samples\\n166 (105 Training, 27 Validation, 34 Testing)\\n284 (140 Training, 85 Validation, 57 Testing)\\nN. Annotations\\n695 (483 Training, 119 Validation, 93 Testing)\\n3.827 (1921 Training, 1061 Validation, 845 Testing)\\nanalysis. Secondly, raw multispectral imagery used for georeferencing can be imprecise, further complicating the task\\nof accurately locating vessels. Thirdly, AIS messages themselves can be corrupted, falsified, or contain erroneous\\ninformation as highlighted by [36] and [37]. These issues collectively contribute to significant difficulties in matching\\nlabelled ship locations with those indicated by AIS data. Given that the AIS data in the two datasets differs significantly\\nin temporal sampling, two distinct strategies were employed to address the matching problem.\\nFor the VDS2Raw dataset, which features a high sampling rate, a structured multi-step approach was implemented. In\\nthe first step, metadata is extracted to facilitate temporal and geographical filtering of the AIS data. This step retains\\nthe useful AIS records, thereby focusing only on the most relevant data points. In the second step, a cost matrix is\\nconstructed based on a weighted combination of perpendicular and Euclidean distances between the AIS points and\\nthe bounding box centers. The weights of this matrix have been further adjusted to account the navigational status of\\nthe vessels, giving more importance to the vessel in movement. Then, an Hungarian algorithm [38] is systematically\\napplied to optimally assign MMSIs to the bounding box centers for each image granule. Notably, to ensure consistency\\nacross all image granules, each MMSI is uniquely assigned to a single bounding box. The assignment results have been\\nstored and visually inspected to further verify the correctness of the matches.\\nIt is important to state that, during the association process, we encountered instances where a single MMSI was\\na candidate for different bounding boxes in near, but different, granules. Given also the complexities of handling\\ndensely trafficked areas, we deliberately avoided re-matching the unmatched bounding boxes with the globally-stored\\nunmatched MMSIs. Instead, we preferred to focus on determining the best association between a unique MMSI and\\nmultiple bounding box candidates within the current set of processed granules. This decision is motivated by a lack of\\nabsolute trust in the AIS data due to the aforementioned issues.\\nR. Del Prete et al.: Preprint submitted to Elsevier\\nPage 12 of 38\\nEnhancing Maritime Situational Awareness through End-to-End Onboard Raw Data Analysis\\nTable 2\\nComparative table summarizing the composition of the two classification datasets. For Sentinel-2, the classes Sailing and\\nPleasure have been combined (S&P) due to their similar characteristics in order to increase the sample size; for VENµS,\\nwe deliberately excluded the General Cargo class in order to focus on the cargo-specific classes.\\nAttribute\\nSentinel-2\\nVENµS\\nShip-types\\nCargo\\nS&P\\nFishing\\nBulk Carrier\\nContainer Ship\\nTrain\\n58\\n58\\n58\\n286\\n286\\nValidation\\n6\\n6\\n6\\n32\\n32\\nTest\\n42\\n35\\n59\\n325\\n80\\nN. Samples (Tot.)\\n106\\n99\\n123\\n643\\n398\\nFor the VDVRaw dataset, featuring only one daily record, the AIS data was associated with the vessels based on a\\nspatial and temporal criteria. Spatially, AIS data points were selected within a 300-meter radius of the vessel’s center\\nin the L1C image, ensuring spatial alignment. Temporally, to address the limitation of AIS data providing only one\\ndaily record around midnight Coordinated Universal Time (UTC), a temporal window was applied, including records\\nfrom the day the L1C image was captured, as well as the day before and after. The broader range improved the chances\\nof accurately matching the AIS record to the vessel’s position in the image. This dual approach of combining spatial\\nproximity with a flexible temporal range ensured that the vessel’s position closely matched the corresponding AIS\\nrecords. This simple but effective approach was adopted because many vessels in the database remained stationary for\\nextended periods. Nonetheless, any discrepancies were further resolved through visual inspection to ensure accurate\\nmatching.\\nIn the end, to enhance the accuracy and generalizability of the ML models, the issue of data imbalance is systematically\\naddressed. This step is crucial, as both datasets exhibit substantial disparities in the distribution of vessel classes, as\\nillustrated in Figure 5(c) and Figure 5(d). First of all, a coarse-grained type classification has been chosen to perform.\\nBy focusing on these common and most promiscuous classes, we aim to create a more balanced and representative\\ndataset for the classification task. In the VDS2Raw dataset, we selected the vessel classes Cargo, Fishing, Sailing, and\\nPleasure, combining the last two (S&P) due to their similar characteristics and to increase the sample size. For the\\nVDVRaw dataset, we deliberately focused on the cargo-specific classes Bulk Carrier and Container Ship, excluding\\nGeneral Cargo as its broader definition would introduce ambiguity and complicate classification. A comprehensive\\noverview of two classification datasets is reported in Table 2.\\nTo further address data imbalance and enhance model robustness, a combination of data augmentation techniques is\\nemployed, including random horizontal and vertical flips, random rotations up to forty degrees, and random perspective\\ntransformations. Additionally, a random elastic transform is applied to simulate realistic distortions. A toroidal shift,\\nwhich shifts the image in a wrap-around manner resembling the shape of a torus, is also utilized. Random shifts within\\na specified range are applied both vertically and horizontally to introduce further variability into the augmented images.\\nR. Del Prete et al.: Preprint submitted to Elsevier\\nPage 13 of 38\\nEnhancing Maritime Situational Awareness through End-to-End Onboard Raw Data Analysis\\nCareful consideration is given to preserving the metadata of the original images, conveniently embedding them\\nalong with the AIS information directly within the COCO annotation file [39]. Specifically, we insert the MMSI,\\ninformation about vessel’s type and route inside the annotation attribute of each vessel annotated, naming this extended\\nformat as AISCOCO.\\n3. Processing Chain\\nWith the aim of improving Maritime Situational Awareness (MSA) by satellite technologies, past research focused\\non extracting information from SAR data [40, 41, 42] and multispectral data [43, 44]. Concerning the latter, without\\nloss of generality, we can cluster the methods into a) Threshold Segmentation Methods [45, 46, 47], b) Statistical\\nMethods [48, 49, 50, 51], c) Feature-Based Methods [43, 52, 53], and d) Deep-Learning Methods [54, 44].\\nThe DL-based techniques offer the advantage of not requiring manual feature extraction or threshold tuning, unlike\\nthreshold-based methods that rely on predefined value thresholds or statistical and feature-based methods that\\ndepend on specific models or descriptors. Their hierarchical representations within large datasets allow for greater\\ngeneralization across varying imaging conditions and challenging environments [54, 44], as the abundant noise and\\nartifacts present in raw data.\\nThe task of detection is to accurately identify ship location through bounding boxes. Differently, the primary objective\\nfor classification is to categorize the detected vessel correctly. With the term identification, we intend the cascaded\\napproach of detection and classification of each detected vessel. It must be pointed out that an object detection\\nframework enables the concurrent end-to-end detection and classification of instances, while in the current study,\\nwe chose to analyze these two tasks separately. By adopting this approach, we aim to disentangle the losses and the\\nlearned gradients, thereby optimizing each problem individually to achieve a better accuracy. This strategy facilitates\\na more effective understanding of each band’s information across various tasks.\\nIn summary, the processing chain follows three essential steps:\\n1. Band-to-Band Registration: Co-registration is performed to ensure accurate per-pixel alignment across bands.\\nProcessing efficiency is improved by activating co-registration only when multiple bands are demanded, thereby\\nreducing computational overhead.\\n2. Detection: DL models detect and locate vessels within the imagery, generating bounding boxes that focus\\nsubsequent analysis on relevant areas.\\n3. Classification: Detected vessels are categorized into types (e.g., cargo ships, fishing boats) using a separate DL\\nmodel, optimizing accuracy by isolating this task.\\nR. Del Prete et al.: Preprint submitted to Elsevier\\nPage 14 of 38\\nEnhancing Maritime Situational Awareness through End-to-End Onboard Raw Data Analysis\\n3.1. Band-to-Band Registration\\nBand-to-Band registration is crucial in remote sensing image analysis, particularly when dealing with multispectral\\nimages. One of the main challenges in automatic alignment arises from significant non-linear intensity variations due to\\nradiometric differences [55]. This problem is especially severe in raw multispectral bands, where the lack of calibration\\nintensifies these differences, making the registration process more complex. Ensuring accurate registration is essential\\nas it directly impacts the performance of subsequent model inference and the overall effectiveness of remote sensing\\napplications. In the context of satellite operations, energy efficiency is of utmost importance.\\nThe work [56] groups the registration methods in global and local. For S-2, we successfully adopted a statistically-based\\napproach to conserve energy onboard, as described in our previous paper [3]. This method falls in the global approaches\\nas it provides with just two band offsets, for along-track and cross-track directions. Besides, it is specifically designed\\nto optimize the registration process while minimizing energy consumption, thereby ensuring efficient and reliable\\nsatellite operations. Concerning VENµS imagery, this approach was leading to considerable registration error (> 5𝑝𝑥)\\nowing to the optical distortion at the borders of the stripmap acquistion. Therefore, for VENµS data we opted for a\\nfine co-registration method employing SIFT [57] keypoints: after identifying tie points, the bands are aligned using an\\nnon-linear transformation.\\n3.2. Detection\\nFor our benchmark, we select as vessel detector the model that in our previous study [8] was outperforming the\\nothers, i.e., VarifocalNet (VFNet) [58]. We argue that the reason lies in its highly engineered head layers with: a)\\nan tailored loss function [58] and b) an anchor-free mechanism which directly classify and refine proposals without\\ngenerating prior anchor boxes. This dense object detector was born from the combination of the works of FCOS [59]\\nand ATSS [60]. The model has been further made more lightweight trough the adoption of a residual convolutional\\nneural network (ResNet-18) as backbone encoder for feature extraction. The multi-scale characteristics of vessels are\\naddressed trough the usage of a Feature Pyramid Network (FPN) [61] module. This module, known as neck, merges\\nthe features of different levels with a bottom-up and a top-down pathway structure. Finally, the head layers, responsible\\nfor the bounding box regression and classification, are particularly convenient for small object detection thanks to the\\nstar-shaped deformable convolution (star dconv) [58] applied for bounding box refinement, which inherently captures\\nbackground sea information.\\nLet 𝐶𝑖represent the i-th convolutional module where 𝑖ranges from 1 to 5, the encoder is represented trough these five\\nconvolutional modules. Noteworthy, the stride of each convolutional module is two, meaning that spatial dimension\\nis halved after each 𝐶𝑖forming the feature pyramid top-down pathway. Each feature map is then convolved to d=256\\nchannels by 1×1 convolution, making the 𝑀𝑖feature maps. The parameter 𝑑was set according to the original paper\\nR. Del Prete et al.: Preprint submitted to Elsevier\\nPage 15 of 38\\nEnhancing Maritime Situational Awareness through End-to-End Onboard Raw Data Analysis\\n[58]. For 𝑖spanning from 5 to 3, the feature map 𝑀𝑖is upsampled and added to the 𝑀(𝑖−1) following bottom-up pathway.\\nA 3×3 convolution is further applied to the feature maps 𝑀2, 𝑀3, 𝑀4. The feature maps resulting from this process\\nare termed 𝑃𝑖. VFNet head layers are subsequently applied to each feature map 𝑃𝑖. Each head layer is composed of two\\nsub-networks, one for bounding box regression and one for classification. These networks show similar characteristics,\\nemploying three 3×3 convolutions followed by ReLU activation. The regression network is highly engineered adopting\\na bounding box refinement scheme where the initial bounding box coordinates are improved thanks to the information\\nsampled at the nine points identified by the star dconv [58]. Notably, this sampled information is also passed to the\\nclassifier branch to improve the classification performance. The number of channels in output equals the number of\\nclasses considered for the problem. In the end, Non-Maximum Suppression (NMS) is applied to all suppress all the\\npredictions from the diverse heads to remove spurious detections. This component is necessary due to the fact that the\\npredictions are not one-to-one assigned but rather a series of predictions produced by the network.\\n3.3. Classification\\nAfter vessel localization, category classification is performed using the ResNet-18 feature extractor as in the\\ndetection encoder. ResNet-18, conceptualized as an exponential ensemble of shallow networks [62], mitigates\\nvanishing gradients via “skip connections” that enable direct gradient propagation across layers, ensuring efficient\\nbackpropagation. The 18-layers architecture balances depth and computational efficiency, making it optimal for high-\\naccuracy, low-latency tasks. Unlike detection, we leverage only the final layer’s feature map, containing the most\\nabstracted representations. A classification head is appended to these high-level features to categorize vessel types\\neffectively.\\n4. Experimental Results\\nThis section rigorously evaluates the model’s performance on the custom-developed datasets across single and\\nmulti-band inputs. The following Table 3 provides a comprehensive overview of the model evaluation and training\\nmethodologies used in this study.\\nIt highlights key aspects such as the performance evaluation on custom-developed, the computational setup, and\\nthe systematic approach to hyperparameter optimization. Additionally, it summarizes the data augmentation techniques\\nand training strategies employed to enhance model generalization. In Section 4.1, we clarify the adoption of certain\\nmetrics for model evaluation. Sections 4.2-4.3 aim to demonstrate the advantages and disadvantages of using a single\\nor a combination of spectral bands. By comparing the performance of single and multiple spectral bands, the study\\nwill elucidate the conditions under which synergistic exploitation is most beneficial. This structured approach ensures\\na detailed evaluation of the spectral bands. Specifically, we tested the spectral bands from S-2 at the highest spatial\\nR. Del Prete et al.: Preprint submitted to Elsevier\\nPage 16 of 38\\nEnhancing Maritime Situational Awareness through End-to-End Onboard Raw Data Analysis\\nTable 3\\nSummary of Model Evaluation, Optimization, and Training Techniques\\nSetting\\nDescription\\nTraining Setup\\nLinux-based system, NVIDIA A100 GPU (40GB), 16-core AMD EPYC-Rome\\nprocessor at 2.8 GHz.\\nHyperparameter Optimization\\nGrid search optimizing learning rate, epochs, batch size, learning rate schedule\\nEarly Stopping\\nPatience of 30 epochs\\nData Augmentation\\nRotations, flips, scaling, shearing to increase variability and model generalization\\n(detection); Rotations, flips, perspective transformations, elastic deformations\\n(classification)\\nInput Size\\n2048 × 2048 (detection); 64 × 64 (classification)\\nOptimizer\\nStochastic Gradient Descent (momentum=0.9, weight decay=0.0001) (detection);\\nAdamW (weight decay=0.01) (classification)\\nLearning Rate Scheduler\\nLinear warm-up (10% epochs), multi-step decay (factor 0.8 up to 50% of epochs),\\ncosine annealing (final phase)\\nresolution (10m), including individual bands and their combined usage. For VENµS, which has all the bands at the\\nsame spatial resolution (5m), the analysis encompasses bands 𝐵1 through 𝐵12, alongside their combinations.\\nIt must be noted the performance over a particular band or set of bands may be influenced by the specific characteristics\\nof the data set used in this study, raising questions about their generalizability to other contexts or datasets. We cope\\nwith this issue by analysing the behaviours of the bands in the two mentioned datasets.\\n4.1. Metrics\\nSeveral considerations are critical in the context of vessel identification from raw multispectral data, as the lack\\nof calibration, band-to-band registration, and geometric corrections can hamper model performance. Additionally,\\nvarying conditions, e.g. atmospheric, sea and water reflections, further complicate the tasks. Therefore, an effective\\nevaluation must take into account these effects, selecting appropriate metrics for accurately assessing the model’s\\nability to locate and categorize vessels in each band.\\nThe Intersection over Union (IoU) [39] is common among the detection metrics and measures the similarity between\\npredicted and actual bounding boxes. Given two shapes 𝐴and 𝐵, IoU is the ratio of their overlap area to their union\\narea. It is used to classify true positives (TP) and false positives (FP) based on a specified threshold. Denoting FN as\\nfalse negatives, from IoU the metrics of Precision (P) and Recall (R) and F-1 score (𝐹1) can be derived as:\\nIoU = |𝐴∩𝐵|\\n|𝐴∪𝐵|,\\n𝑃=\\nTP\\nTP + FP,\\n𝑅=\\nTP\\nTP + FN,\\n𝐹1 = 2 ⋅P ⋅R\\nP + R\\n(2)\\nWe note that high Recall is crucial to ensure that all vessels, including smaller ones, are detected, while high precision\\nis essential to minimize the number of false alarms, ensuring proper resource allocation from marine agencies. Finally,\\nthe F1-score provides a balanced measure of the model’s overall performance. These metrics are a common choice for\\nR. Del Prete et al.: Preprint submitted to Elsevier\\nPage 17 of 38\\nEnhancing Maritime Situational Awareness through End-to-End Onboard Raw Data Analysis\\nobject detection benchmarks.\\nNotwithstanding, these metrics face difficulties when the problem is shifted from generic object detection to small\\nobjects owing to the limited amount of spatial features [63] and significant variance of IoU at lower scales [64]. The\\nvariance arises from the scale-invariant nature of IoU: if the IoU between predicted (𝑏1) and a ground truth (𝑏2) boxes\\nis equal to IoU(𝑏1, 𝑏2) = 𝑢, then scaling all coordinates of both bounding boxes by a factor 𝑘results in the same IoU\\nvalue: IoU(𝑏1, 𝑏2) = IoU(𝑘𝑏1, 𝑘𝑏2) = 𝑢.\\nIn contrast, the ratio (𝜀loc∕𝜔) between the localization error (𝜀loc = ‖𝑏1 −𝑏2‖1) and the object size (𝜔) increases as\\nthe objects become smaller. Hence, IoU is particularly sensitive to spatial alignment and bounding box precision when\\ndealing with small objects, as highlighted in the study of [64]. This is particularly relevant since detection models lack\\nof scale-invariant properties as they do not localize small and large objects with the same accuracy level.\\nIn conclusion, the scale-invariant property is advantageous for classical object detection but has problems when dealing\\nwith small object detection because it actually causes IoU to be overly sensitive to small localization errors, affecting\\nmetrics evaluation [64]. IoU drops dramatically when the localization error increases for small objects, without\\ndiminishing the quality of the detection from a human perspective [64].\\nWhile past research [65, 66, 67, 68, 69, 70] was conceived on formulating IoUs tailored for the regression loss, few\\nattention has been dedicated to small object detection and its evaluation. Recently, [64] reflected on the variance issue\\nhighlighting the importance of using a low-variance criterion for evaluation, particularly when dealing with detectors\\nthat, on average, produce well-localized bounding boxes. Indeed, an high-variance criterion can lead to inconsistent\\nevaluations, where even adequately localized boxes may be incorrectly classified as false negatives due to random\\nvariations in performance. Addressing these challenges, the Scale-adaptive IoU (SIoU) [64] has been proposed as a\\nnovel similarity metric in small object detection. To mitigate the high variance of IoU at smaller scales, SIoU introduces\\na scaling factor 𝑝that dynamically adapts according to the size of the objects, making the metric more lenient towards\\nsmall shifts in smaller objects. The mathematical formulation of SIoU is given by:\\nSIoU(𝑏1, 𝑏2) = (IoU(𝑏1, 𝑏2))𝑝,\\nwhere\\n𝑝= 1 −𝛾exp\\n(\\n−\\n√\\n𝑤1ℎ1 + 𝑤2ℎ2\\n√\\n2𝜅\\n)\\n(3)\\nHere, 𝑏1 and 𝑏2 are the bounding boxes with dimensions 𝑤1, ℎ1 and 𝑤2, ℎ2, respectively. The parameter 𝛾controls the\\ndegree of scaling, particularly for smaller objects, while 𝜅influences the rate at which the scaling effect diminishes\\nas object size increases. The exponential function ensures that the scaling factor 𝑝decreases gradually based on the\\nbounding boxes’ sizes. Since SIoU yields higher expected values than IoU for small objects [64], it compensates for\\ngreater localization errors, offering a more robust and perceptually consistent metric for object detection. In this study,\\nwe set the parameter 𝛾= 0.5, following the original work by [64], while 𝜅=\\n√\\n8 has been chose empirically.\\nR. Del Prete et al.: Preprint submitted to Elsevier\\nPage 18 of 38\\nEnhancing Maritime Situational Awareness through End-to-End Onboard Raw Data Analysis\\nUnlike object detection, classification deals solely with assigning a label to an entire tile, assuming that the object of\\ninterest is already localized. This difference means that classification models emphasize discriminative power among\\ndifferent classes without the additional burden of spatial accuracy. When dealing with raw multispectral data, where\\nspectral bands offer additional discriminative features, the challenge lies in effectively leveraging this rich information\\nto distinguish between classes. Moreover, since the datasets available contains very few samples in comparable\\ncategories, the choice was to adopt for Matthew Correlation Coefficient (MCC) as the metric to evaluate and compare\\nthe training models, which already found numerous applications for assessing classification problems on unbalanced\\ndatasets [71, 72]. Using the same nomenclature of Precision and Recall, the MCC can be formulated as:\\nMCC =\\nTN ⋅TP −FP ⋅FN\\n√\\n(TP + FP) (TP + FN) (TN + FN) (TN + FP)\\n(4)\\n4.2. Single-Band Analysis\\n4.2.1. VDVRaw\\nSeveral factors significantly influence the overall detection accuracy of the studied model, including the spectral\\nresponse of each band and its associated noise level. Figure 6 illustrates these factors for each spectral band. The top\\npanel displays a vessel (Cargo Type) while the bottom panel presents (a) the mean intensity values of vessels and sea\\nsurface, (b) the number of Histogram of Oriented Gradients (HOG) [52] features computed at various thresholds (𝜏),\\nand (c) the Precision, Recall, and 𝐹1 scores evaluated at an SIoU threshold of 0.40. The number of HOG features\\nis considered a measure of the information content within each spectral band. HOG calculated with a 2 × 2 kernel\\nprovide insights into the amount of variability and, consequently, the information contained within the band. By\\napplying different thresholds, we identified a growing pattern in information content from 𝐵1 to 𝐵12, as shown in\\nFigure 6 (b). Furthermore, to account for the quality of the input information to our model, we indirectly measure\\nthe noise by calculating the average spectral response over the sea surface. We then compare it with respect to the\\naverage spectral response of vessels in each band, noting an interesting behaviour. Recalling that spectral bands are\\nuncalibrated, the model’s performance shows a direct correlation with the number of features present in the bounding\\nboxes for each band. We measure this “quantity of information” by estimating the number of strong gradients, or\\nchanges, in adjacent 2 × 2 kernels. Specifically, we use the HOG feature descriptor [52] with different thresholds. The\\ntwo kinds of information, quality (a vessel-to-sea ratio) and quantity (number of strong gradients) enable us to identify\\na correlation with the model results.\\nBy looking at Figure 6(a), it is possible to notice a descending trend in the average spectral response (expressed in\\nDigital Number (DN)) of the sea surface moving from lower to higher wavelengths. A similar trend is present in the\\nnumber of HOG features, this time growing from lower to higher bands.\\nR. Del Prete et al.: Preprint submitted to Elsevier\\nPage 19 of 38\\nEnhancing Maritime Situational Awareness through End-to-End Onboard Raw Data Analysis\\nFigure 6: VENµS (VDVRaw) mean intensity (DN) for vessel and sea clutter (a), mean detection metric values (b), and\\nnormalized number of HOG features (c) in each spectral band under consideration. Fluctuation of the vessel in the various\\nbands due to the residual co-registration errors.\\nTable 4\\nVENµS (VDVRaw) evaluation metric (MCC) computed for different single spectral bands for classification.\\nSpectral\\nBands\\nB1\\nB2\\nB3\\nB4\\nB5\\nB6\\nB7\\nB8\\nB9\\nB10\\nB11\\nB12\\nMean\\n0.33\\n0.48\\n0.50\\n0.52\\n0.57\\n0.58\\n0.57\\n0.58\\n0.56\\n0.62\\n0.57\\n0.51\\nStd\\n±0.02\\n±0.05\\n±0.04\\n±0.05\\n±0.02\\n±0.03\\n±0.03\\n±0.04\\n±0.04\\n±0.02\\n±0.02\\n±0.02\\nThe bands 𝐵1 and 𝐵2 are particularly sensitive to water clarity and depth variations, thus resulting much more\\naffected by noise. Band 𝐵1 shows the lowest performance with a mean Precision of 0.42, mean Recall of 0.54, and mean\\n𝐹1 Score of 0.47. The bands {𝐵𝑖}5\\n𝑖=2 show a progressive improvement in all metrics, peaking at band 𝐵5 that achieves\\na mean Precision of 0.75 and a mean Recall of 0.82, resulting in a mean 𝐹1 Score of 0.78. The highest-performing\\nbands are {𝐵𝑖}12\\n𝑖=6, which are characterized by similar metric values. Among these, the bands 𝐵10, 𝐵11, and 𝐵12 have\\nthe highest mean 𝐹1 Scores (around 0.81), and provide the most stable performance across all metrics.\\nClassification results display a similar, even though less pronounced, trend. This is also reflected by the stable\\nperformance values displayed in the confusion matrices of Figure 7. Among the twelve spectral bands, band 𝐵10\\nachieves the highest MCC value of 0.62 (±0.02), suggesting it provides the most discriminative power for the two-class\\nproblem at hand. Bands 𝐵6, 𝐵8, and 𝐵11 also demonstrate relatively strong performance with MCC values of 0.57 to\\n0.58, though their variation remains within a narrow range, reflecting the stable yet modest differentiation capability\\nacross these bands.\\nR. Del Prete et al.: Preprint submitted to Elsevier\\nPage 20 of 38\\nEnhancing Maritime Situational Awareness through End-to-End Onboard Raw Data Analysis\\n(a)\\n(b)\\n(c)\\n(d)\\n(e)\\n(f)\\n(g)\\n(h)\\n(i)\\n(j)\\n(k)\\n(l)\\nFigure 7: VENµS (VDVRaw) confusion matrices for each spectral band under consideration. The bands are labeled as\\nfollows: (a) B1, (b) B2, (c) B3, (d) B4, (e) B5, (f) B6, (g) B7, (h) B8, (i) B9, (j) B10, (k) B11, and (l) B12.\\n4.2.2. VDS2Raw\\nConsistently with VENµS, we assess the performance of the model on the several bands of S-2. Figure 8 provides\\nan overview of the key factors for each spectral band under consideration (𝐵𝑖\\nfor\\n𝑖∈{2, 3, 4, 8}). The top panel\\nin Figure 8(a) shows the mean intensity values for vessels and sea clutter, which serve as an indicator of the quality\\nof the input data. Similar to our analysis for VENµS, the vessel-to-sea ratio is a critical measure for understanding\\nthe noise characteristics in each band. Figure 8(b) displays, like in the previous paragraph, the mean values of the\\ndetection metrics—Precision, Recall, and 𝐹1 score—for each spectral band. It is evident that certain bands consistently\\noutperform others, with bands closer to NIR demonstrating the highest values across all three metrics. This observation\\naligns with the trend observed for VENµS, where NIR bands with a higher number of strong gradient features and\\nbetter vessel-to-sea ratios yielded superior detection performance. The bottom panel of Figure 8(c) shows again the\\nFigure 8: Sentinel-2 (VDS2Raw) mean intensity for vessel and sea clutter (a), mean detection metric values (b), and\\nnormalized number of HOG features (c) in each spectral band under consideration. Fluctuation of the vessel in the various\\nbands due to the residual co-registration errors.\\nR. Del Prete et al.: Preprint submitted to Elsevier\\nPage 21 of 38\\nEnhancing Maritime Situational Awareness through End-to-End Onboard Raw Data Analysis\\nTable 5\\nSentinel-2 (VDS2Raw) evaluation metric (MCC) computed for different single spectral bands for classification.\\nSpectral\\nBands\\nB2\\nB3\\nB4\\nB8\\nMean\\n0.31\\n0.35\\n0.33\\n0.33\\nStd\\n±0.05\\n±0.05\\n±0.10\\n±0.01\\nnormalized number of HOG features calculated for each band at varying thresholds. As with VENµS, the number of\\nHOG features serves as a measure of the information content in each band. Also in this case, a consistent increase in\\nthe number of HOG features is observed from increasing wavelengths.\\nOnce again, when examining both the vessel-to-sea ratio and the number of strong HOG features, the duality\\ninformation content—quality and quantity—enables us to draw a correlation with the model’s detection metrics.\\nDifferently from the VENµS case, the improvements are less prominent with increasing wavelengths. In particular,\\nthe bands 𝐵3 and 𝐵8 scored higher Precision and Recall values, respectively. The results in terms of 𝐹1 score lie\\nconsistently around 0.7 for the 𝐵3, 𝐵4 and 𝐵8 bands.\\nIn conclusion, consistent with the findings from VENµS, the Sentinel-2 analysis shows that bands lying in spectral\\nregions close to 800𝑛𝑚demonstrate remarkable results in Precision, Recall, and 𝐹1 scores. This further corroborates the\\nrelationship between the number of strong HOG features in bounding boxes for each band and the model’s performance,\\nunderscoring the importance of both spectral response and noise levels in vessel detection from raw data.\\nConcerning classification scores, the Figure 9 remarks how even for S-2 the results remained consistent across all\\nspectral bands.\\n(a)\\n(b)\\n(c)\\n(d)\\nFigure 9: Sentinel-2 (VDS2Raw) confusion matrices in each spectral band under consideration. The bands are labeled as\\nfollows: (a) B2, (b) B3, (c) B4, and (d) B8.\\n4.3. Multi-Band Results\\n4.3.1. VDVRaw v2\\nFor VDVRaw, instead of evaluating all possible combinations from the 12 spectral bands of the VENµS MSI, we\\nfocused on selecting the most dissimilar bands to provide the model with diverse, complementary information. We used\\ntwo metrics to quantify band dissimilarity: the Pearson Correlation Coefficient (PCC) and Euclidean Distance (ED).\\nR. Del Prete et al.: Preprint submitted to Elsevier\\nPage 22 of 38\\nEnhancing Maritime Situational Awareness through End-to-End Onboard Raw Data Analysis\\nFigure 10: Dissimilarity matrices obtained over the VDVRaw dataset (bbox only): PCC (left) and ED (right).\\nThe PCC measures linear relationships between bands, while the ED assesses their geometric separation. Together,\\nthese metrics help identify band combinations that maximize informational diversity. The PCC is defined as:\\n𝜌𝐵𝑖𝐵𝑗=\\ncov(𝐵𝑖, 𝐵𝑗)\\n𝜎𝐵𝑖𝜎𝐵𝑗\\n,\\n(5)\\nwhere 𝜌𝐵𝑖𝐵𝑗is the correlation coefficient between bands 𝐵𝑖and 𝐵𝑗, cov(𝐵𝑖, 𝐵𝑗) is their covariance, and 𝜎𝐵𝑖, 𝜎𝐵𝑗are\\ntheir standard deviations. The ED between bands 𝐵𝑖and 𝐵𝑗is:\\n𝑑(𝐵𝑖, 𝐵𝑗) =\\n√\\n√\\n√\\n√\\n𝑛\\n∑\\n𝑘=1\\n(𝐵𝑖,𝑘−𝐵𝑗,𝑘)2,\\n(6)\\nwhere 𝑑(𝐵𝑖, 𝐵𝑗) is the distance, and 𝐵𝑖,𝑘, 𝐵𝑗,𝑘are the 𝑘-th elements of 𝐵𝑖and 𝐵𝑗.\\nThe analysis focused only on the bounding boxes around vessel structures to ensure relevant regions were considered.\\nFigure 10 shows the dissimilarity matrices obtained using PCC and ED, illustrating the dissimilarity between spectral\\nbands to guide the selection of the most informative ones.\\nBased on the dissimilarities identified, we selected various sets of band combinations to optimize the model’s\\nperformance. In doing so, we intentionally excluded lower-performing bands identified in previous analyses to focus\\non combinations that maximize the diversity of information provided to the model. This selective approach is designed\\nto enhance the model’s ability to differentiate and detect features more effectively by leveraging the most distinct and\\ninformative spectral bands.\\nFor two-band combinations, three pairs emerged as particularly significant: 𝐵5 (visible) with 𝐵8 (visible), 𝐵5 (visible)\\nwith 𝐵10 (near-infrared) and 𝐵5 (visible) with 𝐵12 (near-infrared). These pairs were notable for their distinct spectral\\ninformation, making them effective in distinguishing between various features within the data. The strength of these\\ncombinations lies in their simplicity and ease of implementation, which can be highly beneficial in applications\\nR. Del Prete et al.: Preprint submitted to Elsevier\\nPage 23 of 38\\nEnhancing Maritime Situational Awareness through End-to-End Onboard Raw Data Analysis\\nTable 6\\nVENµS (VDVRaw) evaluation metrics computed for different spectral band combinations: Precision, Recall, 𝐹1 score for\\ndetection, and MCC for classification.\\nSpectral Bands\\nPrecision\\nRecall\\n𝐹1\\nMCC\\nB10\\n0.82 (±0.01)\\n0.87 (±0.00)\\n0.85 (±0.00)\\n0.62 (±0.02)\\nB5B8\\n0.80 (±0.01)\\n0.86 (±0.00)\\n0.83 (±0.00)\\n0.53 (±0.03)\\nB5B10\\n0.81 (±0.01)\\n0.86 (±0.00)\\n0.84 (±0.00)\\n0.56 (±0.03)\\nB5B12\\n0.81 (±0.01)\\n0.87 (±0.00)\\n0.84 (±0.01)\\n0.53 (±0.06)\\nB5B10B11\\n0.84 (±0.01)\\n0.86 (±0.01)\\n0.85 (±0.01)\\n0.57 (±0.00)\\nB3B4B7\\n0.85 (±0.00)\\n0.87 (±0.00)\\n0.86 (±0.00)\\n0.60 (±0.01)\\nB3B4B7B11\\n0.84 (±0.01)\\n0.87 (±0.00)\\n0.86 (±0.00)\\n0.58 (±0.01)\\nB3B5B7B11\\n0.85 (±0.00)\\n0.88 (±0.00)\\n0.86 (±0.00)\\n0.53 (±0.05)\\nrequiring quick, preliminary analysis. However, the reliance on only two bands may limit the breadth of spectral\\nvariation captured, potentially overlooking subtler features that could be detected with additional bands.\\nFor this reason, we identified two other sets of three-band combinations: 𝐵3, 𝐵4, and 𝐵7 (all visible RGB) as well\\nas 𝐵5 (visible) with 𝐵10 and 𝐵11 (both NIR). The strength of these combinations is their ability to capture a wider\\nrange of spectral variation, thus offering more variegated insights into the structures of vessels under analysis. Finally,\\nfor four-band combinations, two key sets were highlighted: 𝐵3, 𝐵4, and 𝐵7 (all visible) with 𝐵11 (near-infrared), as\\nwell as 𝐵3, 𝐵5, and 𝐵7 (visible) with 𝐵11 (near-infrared). These combinations are particularly valuable as they offer a\\ncomprehensive view of the spectral characteristics, enabling a deeper and more detailed understanding of the data.\\nWe evaluated the different band combinations using the same strategy applied to the individual bands, with the results\\npresented in Table 6.\\nIn general, results show how the performance of models utilizing multiple bands is superior to those using a single\\nband. Among the double-band combinations, B5B8 and B5B10 performed comparably, achieving precision values of\\n0.80 (±0.01) and 0.81 (±0.01), respectively. However, the B5B12 combination exhibited a slightly higher recall of\\n0.87 (±0.00), leading to a superior 𝐹1 score of 0.84 (±0.01). Moving to multi-band combinations, the triple-band\\nsetup B3B4B7 recorded the highest precision at 0.85 (±0.00), indicating a high degree of accuracy in detection while\\nminimizing false positives. However, the 4-band combinations, such as B3B4B7B11 and B3B5B7B11, demonstrated a\\nbalanced performance across all metrics, with recall values of 0.87 (±0.00) and 0.88 (±0.00), respectively. Notably,\\nB3B5B7B11 achieved the highest metric values among all combinations, suggesting its effectiveness in comprehensive\\ndetection with fewer missed instances.\\nHowever, it must be noted that although the application of multiple spectral bands yields performance improvements,\\nthese gains (≈2%) are not substantial enough to justify the onboard implementation of a co-registration technique.\\nWhen a resource constrained environment is concerned, such as the one equipped onboard a cubesat, these improve-\\nments are traded with an increased power consumption and delays in processing time.\\nR. Del Prete et al.: Preprint submitted to Elsevier\\nPage 24 of 38\\nEnhancing Maritime Situational Awareness through End-to-End Onboard Raw Data Analysis\\nTable 7\\nSentinel-2 (VDS2Raw) evaluation metrics computed for different spectral band combinations: Precision, Recall, 𝐹1 score\\nfor detection, and MCC for classification.\\nSpectral Bands\\nPrecision\\nRecall\\n𝐹1\\nMCC\\nB8\\n0.59 (±0.08)\\n0.85 (±0.03)\\n0.70 (±0.07)\\n0.33 (±0.01)\\nB2B4\\n0.55 (±0.04)\\n0.75 (±0.02)\\n0.63 (±0.03)\\n0.28 (±0.01)\\nB2B3\\n0.50 (±0.06)\\n0.77 (±0.03)\\n0.61 (±0.05)\\n0.33 (±0.04)\\nB2B8\\n0.56 (±0.05)\\n0.74 (±0.03)\\n0.64 (±0.04)\\n0.30 (±0.04)\\nB3B8\\n0.64 (±0.06)\\n0.85 (±0.02)\\n0.74 (±0.05)\\n0.39 (±0.07)\\nB4B8\\n0.62 (±0.05)\\n0.83 (±0.02)\\n0.71 (±0.04)\\n0.38 (±0.02)\\nB2B4B8\\n0.65 (±0.03)\\n0.76 (±0.02)\\n0.70 (±0.02)\\n0.32 (±0.02)\\nB2B3B4\\n0.66 (±0.09)\\n0.80 (±0.08)\\n0.72 (±0.09)\\n0.34 (±0.06)\\nB2B3B8\\n0.68 (±0.02)\\n0.81 (±0.04)\\n0.74 (±0.02)\\n0.34 (±0.03)\\n4.3.2. VDS2Raw\\nComplementary to the analysis performed for VENµS, we evaluate different spectral band combination for\\nVDS2Raw, reporting the results in the Table 7. The Table summarizes the detection metrics for various double and\\ntriple spectral band combinations.\\nAmong the double band combinations, 𝐵3𝐵8 shows slightly better performance in terms of Precision (0.64), Recall\\n(0.85) and 𝐹1 Score (0.74). The triple band combinations are in general better performing than the double combinations\\nacross all metrics. The combination 𝐵2𝐵3𝐵8 (blue, green, and near-infrared) consistently yields the best results,\\nachieving the highest Precision (0.68), Recall (0.81), and 𝐹1 Score (0.74), although the Recall rate is not the highest\\noverall. This indicates that incorporating the near-infrared band 𝐵8 with the visible bands 𝐵2 and 𝐵3 enhances the\\nmodel’s ability to detect features more accurately. The combination 𝐵2𝐵4𝐵8 (blue, red, and near-infrared) and 𝐵2𝐵3𝐵4\\n(blue, green, and red) also perform well, with 𝐹1 Scores of 0.70 and 0.72, respectively, suggesting that adding the third\\nspectral band improves overall performance. However, they are slightly less effective than 𝐵2𝐵3𝐵8, emphasizing the\\nimportance of the near-infrared band in improving detection accuracy.\\nIn conclusion, adding a near-infrared band to visible bands resulted in improvements in performance, and our findings\\ndemonstrate that using a triple band combination, particularly the 𝐵2𝐵3𝐵8, is more effective for detection tasks than\\ndouble band combinations. We argue that this is primarily due to the increased spectral diversity and complementary\\ninformation provided. Compared to the best single band, 𝐵8, the improvement in performance evaluated in Precision\\nis significant. Notwithstanding, the improvement is again negligible in terms of a more balanced metric such as 𝐹1\\nscore (0.74 vs. 0.70). Compared to VENµS, the higher performance improvement observed in a multispectral scenario\\nsuggests that leveraging broader spectral diversity can compensate for limited spatial resolution.\\n5. Onboard Proof-of-Concept\\nThe section first discusses the practical challenges of applying the model in a real-world scenario, particularly\\nfocusing on the onboard implementation, highlighting the practical results of the deployed system.\\nR. Del Prete et al.: Preprint submitted to Elsevier\\nPage 25 of 38\\nEnhancing Maritime Situational Awareness through End-to-End Onboard Raw Data Analysis\\nAs demonstrated earlier, owing to the marginal improvements in multiple band combinations, thus we select a single\\nband, i.e. 𝐵8 for Sentinel-2 and the 𝐵10 for VENµS. In deploying the models, we employed a cascaded approach for\\nvessel detection and classification, i.e., after identifying regions of interest via the detector, the trained classifier was\\ntasked with categorizing the vessels. This method was chosen to reduce the rate of misclassifications: a classifier\\ntrained end-to-end with the detector samples regions from the sea surface, thereby further complicating the task.\\nWhile acknowledging the need for further investigation, we propose that future research should focus on refining and\\nexpanding this approach.\\nThe model’s robustness when facing different sensor conditions is evaluated in the first part of this section. Then, the\\npractical implementation details are discussed, and finally, power and latency results are presented.\\n5.1. Impact of SNR and MTF\\nCritical insights can be drawn when benchmarking models under different sensor characteristics, specifically the\\nModulation Transfer Function (MTF) and Signal-to-Noise Ratio (SNR). This information is crucial as the onboard\\ndata distribution can shift significantly from the one faced during training, as remarked in [17]. We evaluate the effect\\nof this domain gap by analysing the model behaviour against different sensor working conditions.\\nThe optical system can be modelled using the MTF and SNR to simulate the sensor’s spatial response and noise\\nlevels. The MTF aims to replicate the spatial domain response of the image (i.e., emulating the signal recorded by the\\ninstrument detector element), which is closely associated with the instrument characteristics, such as pixel size and\\nsystem F-number. The MTF filter is thus represented as a two-dimensional kernel with independent across- and along-\\ntrack parameterizations. By utilizing key instrument parameters (mainly the pixel pitch that determines the sampling\\nfrequency and the F-number that determines the cutoff frequency for each band), a two-dimensional MTF kernel of\\nsize 𝑛× 𝑛is computed [17]. The corresponding Point Spread Function (PSF) kernel is obtained as the inverse Fourier\\ntransform of the MTF kernel, and this PSF kernel is convolved with the input image using a sliding-window approach.\\nLet 𝑀(𝐵𝑖) the MTF amplitude at the Nyquist frequency for each spectral band 𝐵𝑖, the MTF function (expressed in\\nterms of normalized frequency with respect to the Nyquist) can be represented as:\\n𝑀𝑇𝐹(𝐵𝑖, 𝑘) = 𝑒ln 𝑀(𝐵𝑖)⋅𝑘2\\n(7)\\nThe 𝑀(𝐵𝑖) are known for Sentinel-2 (𝑀𝑆2(𝐵𝑖) ≈0.3 [28]), and for VENµS (𝑀𝑉(𝐵10) ≈0.15 [23]), therefore we can\\nperform a deconvolution of the input image with the source PSF followed by a convolution with the target PSF as in\\nthe simulator tool of [17], with a single step adopting the Gaussian hypothesis.\\nConcerning the noise simulation, an additional noise term (𝑁) is imposed to the raw images to account for SNR\\nR. Del Prete et al.: Preprint submitted to Elsevier\\nPage 26 of 38\\nEnhancing Maritime Situational Awareness through End-to-End Onboard Raw Data Analysis\\nconditions, following again the formulation by [17]:\\n𝑁(𝑖, 𝑗, 𝑏𝑛) =\\n𝐿𝑟𝑒𝑓(𝑏𝑛)\\n𝑆𝑁𝑅(𝑏𝑛) ⋅\\ue23a(0, 1),\\n(8)\\nwhere \\ue23a(0, 1) is a Gaussian variable with zero mean and unit standard deviation, and 𝐿𝑟𝑒𝑓the reference radiance.\\nNotably, the Equation (8) must be modified from the work of [17] to address raw data since the information is stored\\nas DNs. Therefore, instead of a reference radiance, we adopt a 𝐷𝑁𝑟𝑒𝑓of 100 for both VENµS and Sentinel-2 imagery.\\nWe impose this additional noise term on the existing noise, starting from a SNR value of 174 (theoretical SNR ratio\\nfor Sentinel-2 at the 𝐵8 band); we assume the same initial value also for VENµS.\\nUnder the hypothesis of this modelling framework, we apply varying levels of SNR and MTF to evaluate the model’s\\nrobustness and generality. The results, displayed in Figure 11, illustrate the detection metrics: precision, recall, and 𝐹1\\nscore. As shown in the graphs, the left panel displays results for the VDS2Raw dataset, while the right panel shows\\nresults for VDVRaw The results indicate that lower MTF values—leading to increased image blurring—decrease the\\ndetection performance, with precision metric being the most affected among the three.\\nFigure 11: Detection performance metrics (precision, recall, and 𝐹1 score) across varying levels of MTF and SNR for the\\ndatasets VDS2Raw (left panel) and VDVRaw (right panel). The top and bottom panels show the impact of different SNR\\nvalues on Sentinel-2 and VENµS raw tiles, respectively.\\nAt higher SNR rates, evidence also shows that the S-2 model is much more influenced by MTF variations, mainly due\\nto the lower spatial resolution. An interesting behaviour is noted for both models: lower MTF values shift the plateau\\nR. Del Prete et al.: Preprint submitted to Elsevier\\nPage 27 of 38\\nEnhancing Maritime Situational Awareness through End-to-End Onboard Raw Data Analysis\\nfrom which model performance begins to decline rapidly. This can be attributed to the fact that lower MTF values act\\nas a median filter, thus mitigating the noise and thereby reducing the number of false alarms. In summary, for relatively\\nlow SNR values, having a lower MTF is advantageous despite the overall reduced performance.\\nRegarding the SNR, lower values, which correspond to increased noise (as illustrated in the top and bottom panels\\nof Figure 11 for Sentinel-2 and VENµS imagery, respectively), lead to reduced detector performance. The results\\nhighlight again that VDVRaw is more resilient to noise due to the higher spatial resolution of the sensor, whereas the\\nmodel trained on VDS2Raw demonstrates degraded performance.\\n5.2. Onboard Implementation\\nBenchmarking tests were conducted on a Raspberry Pi 4B (Quad core Cortex-A72 ARM v8 64-bit SoC @ 1.5GHz),\\na popular low-power device, coupled with the Intel® Neural Comput Stick 2 (NCS2) connected through USB bus. The\\nNCS2 features the Intel® Movidius™Myriad™X VPU. This chip is designed to accelerate deep learning tasks at\\nthe edge, featuring 16 programmable 128-bit VLIW Vector Processors and can execute over 4 trillion operations per\\nsecond (TOPS).\\nTo enable onboard deployment, several modifications were made to the detection model. The input dimensions\\nwere reduced to optimise memory usage, aligning with the memory constraints of the VPU. As this VPU does not\\nnatively support deformable convolutions, the star-shaped deformable convolutions were replaced with a custom-\\ndeveloped module. More in-depth, we introduce the Residual-Attention-Dilated-Convolution (RADC) module. The\\nRADC module, drawn in Figure 12, integrates skip connections with dilated convolutions at multiple dilation scales.\\nFor each dilated convolutional block with dilation 𝑑𝑖, the output 𝐗𝑖is given by:\\n𝐗𝑖= ReLU(𝐗∗𝑑𝑖𝐖𝑖+ 𝐛𝑖) + 𝐗\\n(9)\\nwhere 𝐗is the input tensor, ∗𝑑𝑖denotes the dilated convolution with dilation rate 𝑑𝑖, 𝐖𝑖represents the weights of\\nthe 𝑖-th dilated convolutional layer, 𝐛𝑖is the bias of the 𝑖-th dilated convolutional layer, and ReLU(⋅) is the Rectified\\nLinear Unit activation function. Subsequently, the Channel Attention Module (CAM) computes an attention map 𝐀\\nthat re-weights the channels of the output:\\n𝐀= 𝜎(𝐗3 ∗𝐖att)\\n(10)\\nR. Del Prete et al.: Preprint submitted to Elsevier\\nPage 28 of 38\\nEnhancing Maritime Situational Awareness through End-to-End Onboard Raw Data Analysis\\nFigure 12: Proposed RADC module integrates skip connections with dilated convolutions at multiple dilation scales to\\nenhance feature extraction across various receptive fields. The module also incorporates a channel attention mechanism to\\ndynamically re-weight the channels on the last layer of the module.\\nwhere 𝜎(⋅) is the sigmoid activation function, and 𝐖att represents the weights of the attention layer. The attention map\\n𝐀is applied to the output of the last dilated convolutional block:\\n𝐗att = 𝐗3 ⊙𝐀\\n(11)\\nThe different dilation rates (𝑑𝑖where 𝑖∈[2,4,8]) favour learning multi-scale feature representation by greatly enlarging\\nthe receptive fields at different levels, thereby helping the modelling of complex sea surface distributions. The CAM\\nlayer further refines the feature maps, enhancing the model’s ability to focus on the most important channels for vessels\\nand the sea surface.\\nThis new version of the model built on top of VFNet–termed RADCNet–is then trained using automatic mixed-\\nprecision technique. Upon completing the training phase, the model is converted into its Intermediate Representation\\n(IR) using the OpenVINO framework, utilizing the 16-bit floating-point format. This conversion is necessitated by\\nthe VPU’s limitation to 16-bit floating-point precision. An identical procedure is applied to the classification model,\\nensuring both models are compiled in IR with the same numerical precision, thereby adhering to the hardware\\nconstraints imposed by the VPU and optimizing performance for deployment.\\nRADCNet closely matches the original VFNet across all metrics, maintaining high precision, recall, and 𝐹1 scores, as\\nshown in Table 8.\\nIn terms of parameter count, RADCNet exhibits a modest increase of approximately +3 million parameters, primarily\\nattributable to the introduction of the RADC module. However, in terms of throughput, RADCNet substantially\\nsurpasses VFNet, achieving a frame rate of 18 images per second compared to VFNet’s 14 images per second. Latency\\nR. Del Prete et al.: Preprint submitted to Elsevier\\nPage 29 of 38\\nEnhancing Maritime Situational Awareness through End-to-End Onboard Raw Data Analysis\\nTable 8\\nComparison of Precision, Recall, 𝐹1 score, number of parameters, and FPS between VFNet and RADCNet models on\\nVDS2Raw (𝐵8 band) and VDVRaw (𝐵10 band) datasets. Despite being quantized, RADCNet shows minimal performance\\ndegradation. [Benchmark computed using 2000 iterations with a warmup of 5]\\nModel\\nDataset\\nPrecision\\nRecall\\n𝐹1\\nParams (M)\\nFPS (img/s)\\nVFNet\\nVDS2Raw\\n0.59 (± 0.08)\\n0.85 (± 0.03)\\n0.70 (± 0.07)\\n19.68\\n14.9\\nRADCNet\\nVDS2Raw\\n0.63 (± 0.05)\\n0.81 (± 0.04)\\n0.71 (± 0.04)\\n22.04\\n18.0\\nVFNet\\nVDVRaw\\n0.82 (± 0.01)\\n0.87 (± 0.00)\\n0.85 (± 0.00)\\n19.68\\n14.9\\nRADCNet\\nVDVRaw\\n0.80 (± 0.02)\\n0.84 (± 0.03)\\n0.82 (± 0.02)\\n22.04\\n18.0\\nmeasurements were conducted over 2000 iterations, with 5 warmup iterations, on the Linux system detailed in Table 3.\\nThese results highlight the significant influence of memory access costs and demonstrate RADCNet’s competitive\\nperformance, underscoring its suitability for deployment in resource-constrained environments.\\n5.3. Power and Latency Benchmarks\\nThis subsection presents the timing and power consumption results of the on-device tests. Latency was first\\nevaluated on single models, then the entire processing chain, including pre-processing (tiling, normalization), and\\ninference, encompassing both detection and classification has been benchmarked.\\nFigure 13 presents the evaluation conducted on the detection model, whereas Figure 14 displays the power consumption\\nof the edge-AI hardware chosen performing separate detection and classification tasks.\\nSeveral batch size dimensions have been considered along with different input sizes. The results are averaged over\\none thousand iterations using the benchmark tool of OpenVINO. The average inference time is shown in Figure 13(a).\\nAdditionally, the throughput has been estimated and reported in Figure 13(b). In the end, the graph of Figure 13(c)\\nconsiders the input size of 2048 × 2048 pixel image and applies the Slicing Aided Hyper Inference (SAHI) approach\\nFigure 13: Benchmark of detection model compiled using OpenVINO: graph (a) presents the average latency (ms), graph\\n(b) illustrates the average throughput (FPS), and graph (c) displays the total inference time for an image with dimensions\\n2048 × 2048 pixels.\\nR. Del Prete et al.: Preprint submitted to Elsevier\\nPage 30 of 38\\nEnhancing Maritime Situational Awareness through End-to-End Onboard Raw Data Analysis\\nTable 9\\nThroughput, average, minimum and maximum inference time of the classification model deployed with the OpenVINO\\nframework, prompted for different batch sizes.\\nBatch Size\\nThroughput (FPS)\\nAvg Inference Time (ms)\\nMin Inference Time (ms)\\nMax Inference Time (ms)\\n1\\n308.53\\n12.70\\n9.47\\n17.90\\n2\\n306.61\\n25.76\\n14.99\\n30.82\\n4\\n319.22\\n49.70\\n26.66\\n53.86\\n8\\n328.04\\n97.01\\n48.26\\n103.63\\n16\\n329.99\\n193.30\\n95.27\\n200.12\\n32\\n328.70\\n388.22\\n202.70\\n408.18\\n[73] to perform a complete inference using smaller tiles.\\nRegarding power consumption, Figure 14 illustrates the power consumption profile of the Intel® Neural Comput Stick\\n(NCS)2 connected via USB to the Raspberry Pi 4B. The device executes inference tasks using both detection and\\nclassification models. Specifically, subplots (a), (b), and (c) display the power consumption for the detection model\\nwith input dimensions of 256 × 256 for batch sizes of 1 and 2, and 352 × 352 for a batch size of 4, respectively.\\nInstead, subplots (d), (e), and (f) show the corresponding results for the classification model with input dimensions of\\n64 × 64 for batch sizes of 8, 16, and 32, respectively. These models exhibit lower total inference times as depicted in\\nFigure 13. In the proposed configuration, the NCS2 operates with a baseline idle power consumption of 0.66W. Power\\nmeasurements are sampled at intervals of Δ𝑡= 10 ms using the FNIRSI FNB58 USB tester. The number of inference\\noperations conducted is set to 100 for the detection models and 1000 for the classification models.\\nRegarding the classification task, we repeat the same steps for the classifier model, obtaining the latency and throughput\\nvalues reported in Table 9. The results indicate that the throughput remained relatively stable across batch sizes, ranging\\nfrom 306.61 Frames Per Second (FPS) (batch size 2) to 329.99 FPS (batch size 16). As expected, the average inference\\ntime increased with larger batch sizes, from 12.70 ms at batch size 1 to 388.22 ms at batch size 32. These findings\\nsuggest that the optimal balance between throughput and inference time occurs at batch size 4, where a high throughput\\n(319 FPS) is achieved with manageable latency (50ms).\\nIn the end of the manuscript, we present an end-to-end demonstration of our system, processing a complete acquisition\\nunder a worst-case scenario involving 200 vessels per acquisition, with results averaged over 10 iterations. The\\npre-processing phase is highly efficient, with an average duration of 0.49 seconds, suggesting that tasks such as\\nnormalization and resizing are not the primary computational bottlenecks. Conversely, the detection inference stage,\\ntasked with identifying vessel locations, is the most time-consuming step, with an average execution time of 22.97\\nseconds, underscoring the complexity of the detection process. The classification phase, where detected vessels are\\ncategorized, is significantly faster, averaging 1.77 seconds, reflecting the optimized nature of this step.\\nThese performance metrics indicate that the detection stage consumes the majority of computational resources.\\nR. Del Prete et al.: Preprint submitted to Elsevier\\nPage 31 of 38\\nEnhancing Maritime Situational Awareness through End-to-End Onboard Raw Data Analysis\\nFigure 14: Graph displaying the power consumption of the Intel® Neural Compute Stick 2 (NCS2) connected through\\nUSB bus to the Raspberry Pi 4B. The device performs separate inferences using the detection model (graphs (a), (b),\\nand (c), having an input shape of 256x256 with batch size 1 and 2, and 352x352 with batch size 4, respectively) and the\\nclassification model (graphs (d), (e) and (f), having an input shape of 64x64 with batch size 8, 16, and 32, respectively)\\nthat require lower total inference time (Figure 13). In the proposed setup, the NCS2 consumes 0.66W in its idle state, data\\nsampling is performed with a Δ𝑡= 10 ms using the FNIRSI FNB58 USB tester, and the number of inferences selected for\\nthe detection and classification models is 100 and 1000, respectively.\\nNotably, our system’s execution time is approximately double that of comparable benchmarks, which we attribute\\nto our Python-based implementation as opposed to the more optimized C++ implementations used in the benchmark\\ntools.\\n6. Conclusions and Future work\\nThe paper showcased the capability of vessel identification onboard satellites in an end-to-end fashion, starting\\nfrom raw, unprocessed, multispectral imagery. For this purpose, two novel datasets have been compiled, encompassing\\ntwo distinct geographic regions captured by different sensors with unique spatial and radiometric characteristics. The\\ndiversity, also reflected in terms of noise and artefacts, allowed us to explore the performance of our detection models\\nacross varying conditions.\\nThrough a comprehensive statistical analysis, including feature and metric estimations, we identified the most effective\\nspectral bands for vessel detection, i.e., 𝐵8 and 𝐵10 for Sentinel-2 and VENµS, respectively. The spectral responses of\\nthese two bands are closely aligned, covering similar portions of the spectrum. These findings are significant, as they\\nnot only enhance our understanding of the optimal bands for this specific task but also demonstrate the robustness of our\\napproach in adapting to different sensor configurations and environmental contexts. Additionally, our study indicates\\nR. Del Prete et al.: Preprint submitted to Elsevier\\nPage 32 of 38\\nEnhancing Maritime Situational Awareness through End-to-End Onboard Raw Data Analysis\\nthat the advantages of using multiple spectral bands, particularly in improving detection accuracy, are negligible in the\\ncontext of onboard-constrained resources.\\nFinally, with a bare minimal pre-processing, we achieved onboard execution in under 26 seconds on a representative\\nonboard edge-AI device (Raspberry Pi 4B + NCS2) with a power consumption below 2W registered on the NCS2,\\nshowcasing the feasibility of near real-time vessel detection and classification. Notwithstanding, it must be pointed\\nout that, at the time of writing this manuscript, other models have been released, such as YOLOv10 [74], and Real-\\nTime DEtection TRansformer (RT-DETR) [75], which exhibit exceptional performance in detection tasks. These\\nmodels benefit from end-to-end capabilities for detecting objects thanks to one-to-one prediction assignments, thus\\neliminating the need for NMS component. Given the promising results demonstrated by these models, their application\\nand performance evaluation in the context of our research would be valuable. However, due to the rapid advancements\\nin this field and the scope of our current study, the analysis of these more representative models is deferred to future\\nwork.\\nAlthough results demonstrated the detection phase is the computational bottleneck, the adopted cascaded approach can\\nbe further refined by directly integrating the classifier in the detection heads. This modification could streamline the\\nworkflow, allowing for a reduction in latency and overall better resource management. In addition, findings suggest\\nthat future work aiming for enhanced efficiency should consider leveraging C++ for improved resource utilization.\\nThe AIS records have not been fully exploited. Future work should focus on identifying the classes that are most\\nchallenging to detect. This will enable to optimize our models for improved efficiency in targeting those specific\\nclasses.\\nFinally, noise appears to affect model performance significantly. Hence, future research should explore integrating\\nadvanced denoising techniques to mitigate the impact of noise. Incorporating such techniques could enhance the\\nrobustness of the models, especially in real-time operational settings, and lead to more accurate and reliable vessel\\ndetection and classification. We believe that developing models resilient to variations in MTF and SNR represents a\\npromising direction for future research addressing domain gap challenges.\\nData Availability\\n• The VDS2Raw (v2) dataset, which is integral to our research, is publicly accessible for further exploration\\nand utilization. Researchers and practitioners can download the dataset from the following link: 10.5281/zen-\\nodo.13889073.\\n• The VDVRaw dataset is publicly accessible for further exploration and utilization. The dataset is accessible at\\nthe following link: 10.5281/zenodo.13897485.\\nR. Del Prete et al.: Preprint submitted to Elsevier\\nPage 33 of 38\\nEnhancing Maritime Situational Awareness through End-to-End Onboard Raw Data Analysis\\n• Both classification datasets are publicly accessible for further exploration and utilization at the following link:\\n10.5281/zenodo.14007820.\\nDeclaration of Generative AI\\nDuring the preparation of this work the authors used GPT-4o in order to improve the readability of some sentences.\\nAfter using this tool/service, the authors reviewed and edited the content as needed and took full responsibility for the\\ncontent of the publication.\\nReferences\\n[1] Gianluca Furano, Gabriele Meoni, Aubrey Dunne, David Moloney, Veronique Ferlet-Cavrois, Antonis Tavoularis, Jonathan Byrne, Léonie\\nBuckley, Mihalis Psarakis, Kay-Obbe Voss, et al. Towards the use of artificial intelligence on the edge in space systems: Challenges and\\nopportunities. IEEE Aerospace and Electronic Systems Magazine, 35(12):44–56, 2020.\\n[2] Gianluca Giuffrida, Luca Fanucci, Gabriele Meoni, Matej Batič, Léonie Buckley, Aubrey Dunne, Chris van Dijk, Marco Esposito, John\\nHefele, Nathan Vercruyssen, Gianluca Furano, Massimiliano Pastena, and Josef Aschbacher. The 𝜙-sat-1 mission: The first on-board deep\\nneural network demonstrator for satellite earth observation. IEEE Transactions on Geoscience and Remote Sensing, 60:1–14, 2022.\\n[3] Gabriele Meoni, Roberto Del Prete, Federico Serva, Alix De Beusscher, Olivier Colin, and Nicolas Longépé. Unlocking the use of raw\\nmultispectral earth observation imagery for onboard artificial intelligence. IEEE Journal of Selected Topics in Applied Earth Observations\\nand Remote Sensing, 2024.\\n[4] Agata M Wijata, Michel-François Foulon, Yves Bobichon, Raffaele Vitulli, Marco Celesti, Roberto Camarero, Gianluigi Di Cosimo, Ferran\\nGascon, Nicolas Longépé, Jens Nieke, et al.\\nTaking artificial intelligence into space through objective selection of hyperspectral earth\\nobservation applications: To bring the “brain” close to the “eyes” of satellite missions. IEEE Geoscience and Remote Sensing Magazine,\\n11(2):10–39, 2023.\\n[5] Gonzalo Mateo-Garcia, Joshua Veitch-Michaelis, Lewis Smith, Silviu Vlad Oprea, Guy Schumann, Yarin Gal, Atılım Güneş Baydin, and\\nDietmar Backes. Towards global flood mapping onboard low cost satellites with machine learning. Scientific Reports, 11(1):7249, March\\n2021. Number: 1 Publisher: Nature Publishing Group.\\n[6] Lorenzo Diana, Jia Xu, and Luca Fanucci. Oil spill identification from sar images for low power embedded systems using cnn. Remote Sensing,\\n13(18):3606, 2021.\\n[7] Vít Ruzicka, Anna Vaughan, Daniele De Martini, James Fulton, Valentina Salvatelli, Chris Bridges, Gonzalo Mateo-Garcia, and Valentina\\nZantedeschi. Ravæn: unsupervised change detection of extreme events using ml on-board satellites. Scientific Reports, 12(1):16939, 2022.\\n[8] Roberto Del Prete, Gabriele Meoni, Nicolas Longépé, Maria Daniela Graziano, and Alfredo Renga. First results of vessel detection with\\nonboard processing of sentinel-2 raw data by deep learning. In IGARSS 2023-2023 IEEE International Geoscience and Remote Sensing\\nSymposium, pages 6262–6265. IEEE, 2023.\\n[9] Angela Cratere, Leandro Gagliardi, Gabriel A. Sanca, Federico Golmar, and Francesco Dell’Olio. On-board computer for cubesats: State-of-\\nthe-art and future trends. IEEE Access, 12:99537–99569, 2024.\\n[10] N Melega, N Longepe, V Marchese, A Paskeviciute, Oriol Aragon, Irina Babkina, Alessandro Marin, Jakub Nalepa, Leonie Buckley, Giorgia\\nGuerrisi, et al. Implementation of the 𝜙sat-2 on board image processing chain. In Sensors, Systems, and Next-Generation Satellites XXVII,\\nvolume 12729, pages 264–276. SPIE, 2023.\\nR. Del Prete et al.: Preprint submitted to Elsevier\\nPage 34 of 38\\nEnhancing Maritime Situational Awareness through End-to-End Onboard Raw Data Analysis\\n[11] David Rijlaarsdam, Tom Hendrix, Pablo T Toledano González, Alberto Velasco-Mata, Léonie Buckley, Juan Puig Miquel, Oriol Aragon\\nCasaled, and Aubrey Dunne. Autonomous operational scheduling on cognisat-6 based on onboard artificial intelligence. In 17th Symposium\\non Advanced Space Technologies in Robotics and Automation, Leiden, NL, 2023.\\n[12] Sha Lu, Eriita Jones, Liang Zhao, Yu Sun, Kai Qin, Jixue Liu, Jiuyong Li, Prabath Abeysekara, Norman Mueller, Simon Oliver, et al. Onboard\\nai for fire smoke detection using hyperspectral imagery: an emulation for the upcoming kanyini hyperscout-2 mission. IEEE Journal of Selected\\nTopics in Applied Earth Observations and Remote Sensing, 2024.\\n[13] Aksel S Danielsen, Tor Arne Johansen, and Joseph L Garrett. Self-organizing maps for clustering hyperspectral images on-board a cubesat.\\nRemote Sensing, 13(20):4174, 2021.\\n[14] Dawa Derksen, Gabriele Meoni, Gurvan Lecuyer, Anne Mergy, Marcus Märtens, and Dario Izzo. Few-shot image classification challenge\\non-board. In Workshop-Data Centric AI, NeurIPS, 2021.\\n[15] Gabriele Meoni, Marcus Märtens, Dawa Derksen, Kenneth See, Toby Lightheart, Anthony Sécher, Arnaud Martin, David Rijlaarsdam,\\nVincenzo Fanizza, and Dario Izzo. The ops-sat case: A data-centric competition for onboard satellite image classification. Astrodynamics,\\npages 1–22, 2024.\\n[16] Gabriele Meoni, Roberto Del Prete, Federico Serva, Alix De Beussche, Olivier Colin, and Nicolas Longépé. THRawS: A Novel Dataset for\\nThermal Hotspots Detection in Raw Sentinel-2 Data. arXiv preprint arXiv:2305.11891, 2023.\\n[17] Nicolas Longépé, Isabella Petrelli, Nika Oman Kadunc, Devis Peressutti, Roberto Del Prete, Mauro Casaburi, Irina Babkina, Nathan\\nVercruyssen, Elisa Callejo Luis, Álvaro Morón Elorza, et al. Simulation of multispectral and hyperspectral eo products for onboard machine\\nlearning application. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2024.\\n[18] David Rijlaarsdam, Tom Hendrix, Pablo T Toledano González, Alberto Velasco-Mata, Léonie Buckley, Juan Puig Miquel, Oriol Aragon\\nCasaled, and Aubrey Dunne. The next era for earth observation spacecraft: An overview of cognisat-6. Authorea Preprints, 2024.\\n[19] Manuel Salvoldi, Aviv L. Cohen-Zada, and Arnon Karnieli. Using the VEN𝜇S super-spectral camera for detecting moving vehicles. ISPRS\\nJournal of Photogrammetry and Remote Sensing, 192:33–48, 2022.\\n[20] I. Herrmann, A. Pimstein, A. Karnieli, Y. Cohen, V. Alchanatis, and D.J. Bonfil. Lai assessment of wheat and potato crops by ven𝜇s and\\nsentinel-2 bands. Remote Sensing of Environment, 115(8):2141–2151, 2011.\\n[21] Erwin W.J. Bergsma, Rafael Almar, Amandine Rolland, Renaud Binet, Katherine L. Brodie, and A. Spicer Bak. Coastal morphology from\\nspace: A showcase of monitoring the topography-bathymetry continuum. Remote Sensing of Environment, 261:112469, 2021.\\n[22] Arthur Dick, Jean-Louis Raynaud, Amandine Rolland, Sophie Pelou, Sophie Coustance, Gérard Dedieu, Olivier Hagolle, Jean-Pascal\\nBurochin, Renaud Binet, and Agathe Moreau. VEN𝜇S: Mission characteristics, final evaluation of the first phase and data production. Remote\\nSensing, 14(14), 2022.\\n[23] Philippe Gamet, Sébastien Fourest, Tuvia Sprecher, and Emmanuel Hillairet. Measuring, modeling and removing optical straylight from ven𝜇s\\nsuper spectral camera images. In International Conference on Space Optics—ICSO 2018, volume 11180, pages 1638–1661. SPIE, 2019.\\n[24] Yongkun Liu, Tengfei Long, Weili Jiao, Yihong Du, Guojin He, Bo Chen, and Peng Huang. Automatic segment-wise restoration for wide\\nirregular stripe noise in sdgsat-1 multispectral data using side-slither data. The Egyptian Journal of Remote Sensing and Space Science,\\n26(3):747–757, 2023.\\n[25] Hervé Carfantan and Jérôme Idier. Statistical linear destriping of satellite-based pushbroom-type images. IEEE transactions on geoscience\\nand remote sensing, 48(4):1860–1871, 2009.\\n[26] A. Dick, P. Gamet, S. Marcq, G. Dedieu, O. Hagolle, P. Crebassol, J-L. Raynaud, E. Hillairet, and S. Juglea Enache. VEN𝜇S commissioning\\nphase: Specificities of radiometric calibration. In IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium, pages\\nR. Del Prete et al.: Preprint submitted to Elsevier\\nPage 35 of 38\\nEnhancing Maritime Situational Awareness through End-to-End Onboard Raw Data Analysis\\n4320–4323, 2018.\\n[27] A Gatti and A Bertolini. Sentinel-2 products specification document. Rapport technique, pages 4–7, 2015.\\n[28] Ferran Gascon, Catherine Bouzinac, Olivier Thepaut, Mathieu Jung, Benjamin Francesconi, Jerome Louis, Vincent Lonjou, Bruno Lafrance,\\nStéphane Massera, Angélique Gaudel-Vacaresse, Florie Languille, Bahjat Alhammoud, Françoise Viallefont, Bringfried Pflug, Jakub Bieniarz,\\nSebastien Clerc, Laëtitia Pessiot, Thierry Trémas, Enrico Cadau, and Valérie Fernandez. Copernicus sentinel-2a calibration and products\\nvalidation status. Remote Sensing, 8, 06 2017.\\n[29] Paul-Edouard Sarlin, Daniel DeTone, Tomasz Malisiewicz, and Andrew Rabinovich. Superglue: Learning feature matching with graph neural\\nnetworks. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 4938–4947, 2020.\\n[30] Nobuyuki Otsu et al. A threshold selection method from gray-level histograms. Automatica, 11(285-296):23–27, 1975.\\n[31] CH Li and Peter Kwong-Shun Tam. An iterative algorithm for minimum cross entropy thresholding. Pattern recognition letters, 19(8):771–776,\\n1998.\\n[32] Thomas Wilhelm Ridler, S Calvard, et al. Picture thresholding using an iterative selection method. IEEE Trans. Syst. Man Cybern, 8(8):630–\\n632, 1978.\\n[33] Chris A Glasbey. An analysis of histogram-based thresholding algorithms. CVGIP: Graphical models and image processing, 55(6):532–537,\\n1993.\\n[34] Rosa Ruiloba, François De Vieilleville, Adrien Lagrange, and Bertrand Le Saux. Sentinel-2 dataset for ship detection, June 2020.\\n[35] Jianwen Ma, Yue Zhou, and Zhaoxin Zhu. Identification and analysis of ship waiting behavior outside the port based on ais data. Scientific\\nReport, 13(11267), 2023.\\n[36] Marco Balduzzi, Alessandro Pasta, and Kyle Wilhoit. A security evaluation of ais automated identification system. In Proceedings of the 30th\\nannual computer security applications conference, pages 436–445, 2014.\\n[37] Cyril Ray, Clément Iphar, and Aldo Napoli. Methodology for real-time detection of ais falsification. In Maritime Knowledge Discovery and\\nAnomaly Detection Workshop, pages 74–77, 2016.\\n[38] Harold W Kuhn. The hungarian method for the assignment problem. Naval research logistics quarterly, 2(1-2):83–97, 1955.\\n[39] Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollár, and C Lawrence Zitnick. Microsoft\\ncoco: Common objects in context. In Computer Vision–ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014,\\nProceedings, Part V 13, pages 740–755. Springer, 2014.\\n[40] Knut Eldhuset. An automatic ship and ship wake detection system for spaceborne sar images in coastal regions. IEEE transactions on\\nGeoscience and Remote Sensing, 34(4):1010–1019, 1996.\\n[41] Mariví Tello, Carlos López-Martínez, and Jordi J Mallorqui. Automatic vessel monitoring with single and multidimensional sar images in the\\nwavelet domain. ISPRS Journal of Photogrammetry and Remote Sensing, 61(3-4):260–278, 2006.\\n[42] Tao Zhang, Linfeng Jiang, Deliang Xiang, Yifang Ban, Ling Pei, and Huilin Xiong. Ship detection from polsar imagery using the ambiguity\\nremoval polarimetric notch filter. ISPRS Journal of Photogrammetry and Remote Sensing, 157:41–58, 2019.\\n[43] Zhenwei Shi, Xinran Yu, Zhiguo Jiang, and Bo Li. Ship Detection in High-Resolution Optical Imagery Based on Anomaly Detector and Local\\nShape Feature. IEEE Transactions on Geoscience and Remote Sensing, 52(8):4511–4523, August 2014.\\n[44] Janne Mäyrä, Elina Virtanen, Ari-Pekka Jokinen, Joni Koskikala, Sakari Väkevä, and Jenni Attila. Mapping recreational marine traffic from\\nsentinel-2 imagery with yolov8. Available at SSRN 4827287, 2024.\\n[45] Deborah W Burgess. Automatic ship detection in satellite multispectral imagery. Photogrammetric engineering and remote sensing, 59(2):229–\\n237, 1993.\\nR. Del Prete et al.: Preprint submitted to Elsevier\\nPage 36 of 38\\nEnhancing Maritime Situational Awareness through End-to-End Onboard Raw Data Analysis\\n[46] Christina Corbane, Fabrice Marre, and Michel Petit. Using spot–5 hrg data in panchromatic mode for operational detection of small ships in\\ntropical area. Sensors, 8(5):2959–2973, 2008.\\n[47] Henning Heiselberg. A Direct and Fast Methodology for Ship Recognition in Sentinel-2 Multispectral Imagery. Remote Sensing, 8(12):1033,\\nDecember 2016.\\n[48] Nadia Proia and Vincent Pagé. Characterization of a bayesian ship detection method in optical satellite images. IEEE geoscience and remote\\nsensing letters, 7(2):226–230, 2009.\\n[49] Guang Yang, Bo Li, Shufan Ji, Feng Gao, and Qizhi Xu. Ship detection from optical satellite images based on sea surface analysis. IEEE\\nGeoscience and Remote Sensing Letters, 11(3):641–645, 2014.\\n[50] Christina Corbane, Laurent Najman, Emilien Pecoul, Laurent Demagistri, and Michel Petit. A complete processing chain for ship detection\\nusing optical satellite imagery. International journal of remote sensing, 31(22):5837–5854, 2010.\\n[51] Domenico Barretta, Leonardo M. Millefiori, and Paolo Braca. Analytical classification performance analysis of machine-learning-based ship\\ndetection from optical satellite imagery. In IGARSS 2024 - 2024 IEEE International Geoscience and Remote Sensing Symposium, pages\\n8861–8865, 2024.\\n[52] Navneet Dalal and Bill Triggs. Histograms of oriented gradients for human detection. In 2005 IEEE computer society conference on computer\\nvision and pattern recognition (CVPR’05), volume 1, pages 886–893. Ieee, 2005.\\n[53] Jun Guo and Chang Ren Zhu. A novel method of ship detection from spaceborne optical image based on spatial pyramid matching. Applied\\nMechanics and Materials, 190:1099–1103, 2012.\\n[54] Alina Ciocarlan and Andrei Stoian. Ship Detection in Sentinel 2 Multi-Spectral Images with Self-Supervised Learning. Remote Sensing,\\n13(21):4255, October 2021.\\n[55] Yuanxin Ye and Jie Shan. A local descriptor based registration method for multispectral remote sensing images with non-linear intensity\\ndifferences. ISPRS Journal of Photogrammetry and Remote Sensing, 90:83–95, 2014.\\n[56] Giandomenico De Luca, Federico Carotenuto, Lorenzo Genesio, Monica Pepe, Piero Toscano, Mirco Boschetti, Franco Miglietta, and\\nBeniamino Gioli. Improving prisma hyperspectral spatial resolution and geolocation by using sentinel-2: development and test of an operational\\nprocedure in urban and rural areas. ISPRS Journal of Photogrammetry and Remote Sensing, 215:112–135, 2024.\\n[57] David G Lowe. Distinctive image features from scale-invariant keypoints. International journal of computer vision, 60:91–110, 2004.\\n[58] Haoyang Zhang, Ying Wang, Feras Dayoub, and Niko Sunderhauf. Varifocalnet: An iou-aware dense object detector. In Proceedings of the\\nIEEE/CVF conference on computer vision and pattern recognition, pages 8514–8523, 2021.\\n[59] Zhi Tian, Xiangxiang Chu, Xiaoming Wang, Xiaolin Wei, and Chunhua Shen. Fully convolutional one-stage 3d object detection on lidar range\\nimages. Advances in Neural Information Processing Systems, 35:34899–34911, 2022.\\n[60] Shifeng Zhang, Cheng Chi, Yongqiang Yao, Zhen Lei, and Stan Z Li. Bridging the gap between anchor-based and anchor-free detection via\\nadaptive training sample selection. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 9759–9768,\\n2020.\\n[61] Tsung-Yi Lin, Piotr Dollár, Ross Girshick, Kaiming He, Bharath Hariharan, and Serge Belongie. Feature pyramid networks for object detection.\\nIn Proceedings of the IEEE conference on computer vision and pattern recognition, pages 2117–2125, 2017.\\n[62] Andreas Veit, Michael Wilber, and Serge Belongie. Residual networks are exponential ensembles of relatively shallow networks. arXiv\\npreprint arXiv:1605.06431, 1(2):3, 2016.\\n[63] Guang Chen, Haitao Wang, Kai Chen, Zhijun Li, Zida Song, Yinlong Liu, Wenkai Chen, and Alois Knoll. A survey of the four pillars for small\\nobject detection: Multiscale representation, contextual information, super-resolution, and region proposal. IEEE Transactions on systems, man,\\nR. Del Prete et al.: Preprint submitted to Elsevier\\nPage 37 of 38\\nEnhancing Maritime Situational Awareness through End-to-End Onboard Raw Data Analysis\\nand cybernetics: systems, 52(2):936–953, 2020.\\n[64] Pierre Le Jeune and Anissa Mokraoui. Rethinking intersection over union for small object detection in few-shot regime. arXiv preprint\\narXiv:2307.09562, 2023.\\n[65] Hamid Rezatofighi, Nathan Tsoi, JunYoung Gwak, Amir Sadeghian, Ian Reid, and Silvio Savarese. Generalized intersection over union: A\\nmetric and a loss for bounding box regression. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages\\n658–666, 2019.\\n[66] Zhaohui Zheng, Ping Wang, Wei Liu, Jinze Li, Rongguang Ye, and Dongwei Ren. Distance-iou loss: Faster and better learning for bounding\\nbox regression. In Proceedings of the AAAI conference on artificial intelligence, volume 34, pages 12993–13000, 2020.\\n[67] Jiabo He, Sarah Erfani, Xingjun Ma, James Bailey, Ying Chi, and Xian-Sheng Hua. 𝛼-iou: A family of power intersection over union losses\\nfor bounding box regression. Advances in Neural Information Processing Systems, 34:20230–20242, 2021.\\n[68] Chang Xu, Jinwang Wang, Wen Yang, Huai Yu, Lei Yu, and Gui-Song Xia. Detecting tiny objects in aerial images: A normalized wasserstein\\ndistance and a new benchmark. ISPRS Journal of Photogrammetry and Remote Sensing, 190:79–93, 2022.\\n[69] Ziqi Guo, Chu He, Lian Zhou, Qingyi Zhang, and Shilei Sun. Robust bounding box regression for small object detection. In 2023 IEEE\\nInternational Conference on Image Processing (ICIP), pages 2290–2294. IEEE, 2023.\\n[70] Thi-Hoang-Giang Tran, Dinh-Khoa Tran, and Ho-Si-Hung Nguyen. An updated iou loss function for bounding box regression. In International\\nConference on Artificial Intelligence and Big Data in Digital Era, pages 13–22. Springer, 2021.\\n[71] Rosario Delgado and Xavier-Andoni Tibau. Why cohen’s kappa should be avoided as performance measure in classification. PLoS ONE, 14,\\n2019.\\n[72] Davide Chicco, Valery V. Starovoitov, and Giuseppe Jurman. The benefits of the matthews correlation coefficient (mcc) over the diagnostic\\nodds ratio (dor) in binary classification assessment. IEEE Access, 9:47112–47124, 2021.\\n[73] Fatih Cagatay Akyon, Sinan Onur Altinuc, and Alptekin Temizel. Slicing aided hyper inference and fine-tuning for small object detection. In\\n2022 IEEE International Conference on Image Processing (ICIP), pages 966–970, 2022.\\n[74] Ao Wang, Hui Chen, Lihao Liu, Kai Chen, Zijia Lin, Jungong Han, and Guiguang Ding. Yolov10: Real-time end-to-end object detection.\\narXiv preprint arXiv:2405.14458, 2024.\\n[75] Yian Zhao, Wenyu Lv, Shangliang Xu, Jinman Wei, Guanzhong Wang, Qingqing Dang, Yi Liu, and Jie Chen. Detrs beat yolos on real-time\\nobject detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 16965–16974, 2024.\\nR. Del Prete et al.: Preprint submitted to Elsevier\\nPage 38 of 38\\n')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[Document(metadata={'title': 'Generative artificial intelligence', 'summary': 'Generative artificial intelligence (generative AI, GenAI, or GAI) is a subset of artificial intelligence that uses generative models to produce text, images, videos, or other forms of data. These models often generate output in response to specific prompts. Generative AI systems learn the underlying patterns and structures of their training data, enabling them to create new data. \\nImprovements in transformer-based deep neural networks, particularly large language models (LLMs), enabled an AI boom of generative AI systems in the early 2020s. These include chatbots such as ChatGPT, Copilot, Gemini and LLaMA, text-to-image artificial intelligence image generation systems such as Stable Diffusion, Midjourney and DALL-E, and text-to-video AI generators such as Sora. Companies such as OpenAI, Anthropic, Microsoft, Google, and Baidu as well as numerous smaller firms have developed generative AI models.\\nGenerative AI has uses across a wide range of industries, including software development, healthcare, finance, entertainment, customer service, sales and marketing, art, writing, fashion, and product design. However, concerns have been raised about the potential misuse of generative AI such as cybercrime, the use of fake news or deepfakes to deceive or manipulate people, and the mass replacement of human jobs. Intellectual property law concerns also exist around generative models that are trained on and emulate copyrighted works of art.', 'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence'}, page_content='Generative artificial intelligence (generative AI, GenAI, or GAI) is a subset of artificial intelligence that uses generative models to produce text, images, videos, or other forms of data. These models often generate output in response to specific prompts. Generative AI systems learn the underlying patterns and structures of their training data, enabling them to create new data. \\nImprovements in transformer-based deep neural networks, particularly large language models (LLMs), enabled an AI boom of generative AI systems in the early 2020s. These include chatbots such as ChatGPT, Copilot, Gemini and LLaMA, text-to-image artificial intelligence image generation systems such as Stable Diffusion, Midjourney and DALL-E, and text-to-video AI generators such as Sora. Companies such as OpenAI, Anthropic, Microsoft, Google, and Baidu as well as numerous smaller firms have developed generative AI models.\\nGenerative AI has uses across a wide range of industries, including software development, healthcare, finance, entertainment, customer service, sales and marketing, art, writing, fashion, and product design. However, concerns have been raised about the potential misuse of generative AI such as cybercrime, the use of fake news or deepfakes to deceive or manipulate people, and the mass replacement of human jobs. Intellectual property law concerns also exist around generative models that are trained on and emulate copyrighted works of art.\\n\\n\\n== History ==\\n\\n\\n=== Early history ===\\nSince its inception, researchers in the field have raised philosophical and ethical arguments about the nature of the human mind and the consequences of creating artificial beings with human-like intelligence; these issues have previously been explored by myth, fiction and philosophy since antiquity. The concept of automated art dates back at least to the automata of ancient Greek civilization, where inventors such as Daedalus and Hero of Alexandria were described as having designed machines capable of writing text, generating sounds, and playing music. The tradition of creative automations has flourished throughout history, exemplified by Maillardet\\'s automaton created in the early 1800s. Markov chains have long been used to model natural languages since their development by Russian mathematician Andrey Markov in the early 20th century. Markov published his first paper on the topic in 1906, and analyzed the pattern of vowels and consonants in the novel Eugeny Onegin using Markov chains. Once a Markov chain is learned on a text corpus, it can then be used as a probabilistic text generator.\\n\\n\\n=== Academic artificial intelligence ===\\nThe academic discipline of artificial intelligence was established at a research workshop held at Dartmouth College in 1956 and has experienced several waves of advancement and optimism in the decades since. Artificial Intelligence research began in the 1950s with works like Computing Machinery and Intelligence (1950) and the 1956 Dartmouth Summer Research Project on AI. Since the 1950s, artists and researchers have used artificial intelligence to create artistic works. By the early 1970s, Harold Cohen was creating and exhibiting generative AI works created by AARON, the computer program Cohen created to generate paintings.\\nThe terms generative AI planning or generative planning were used in the 1980s and 1990s to refer to AI planning systems, especially computer-aided process planning, used to generate sequences of actions to reach a specified goal. Generative AI planning systems used symbolic AI methods such as state space search and constraint satisfaction and were a \"relatively mature\" technology by the early 1990s. They were used to generate crisis action plans for military use, process plans for manufacturing and decision plans such as in prototype autonomous spacecraft.\\n\\n\\n=== Generative neural nets (2014-2019) ===\\n\\nSince its inception, the field of machine learning used both discriminative models and generative models, to model a'), Document(metadata={'title': 'Runway (company)', 'summary': \"Runway AI, Inc. (also known as Runway and RunwayML) is an American company headquartered in New York City that specializes in generative artificial intelligence research and technologies. The company is primarily focused on creating products and models for generating videos, images, and various multimedia content. It is most notable for developing the commercial text-to-video and video generative AI models Gen-1, Gen-2 and Gen-3 Alpha.\\nRunway's tools and AI models have been utilized in films such as Everything Everywhere All At Once, in music videos for artists including A$AP Rocky, Kanye West, Brockhampton, and The Dandy Warhols, and in editing television shows like The Late Show and Top Gear.\", 'source': 'https://en.wikipedia.org/wiki/Runway_(company)'}, page_content=\"Runway AI, Inc. (also known as Runway and RunwayML) is an American company headquartered in New York City that specializes in generative artificial intelligence research and technologies. The company is primarily focused on creating products and models for generating videos, images, and various multimedia content. It is most notable for developing the commercial text-to-video and video generative AI models Gen-1, Gen-2 and Gen-3 Alpha.\\nRunway's tools and AI models have been utilized in films such as Everything Everywhere All At Once, in music videos for artists including A$AP Rocky, Kanye West, Brockhampton, and The Dandy Warhols, and in editing television shows like The Late Show and Top Gear.\\n\\n\\n== History ==\\nThe company was founded in 2018 by the Chileans Cristóbal Valenzuela, Alejandro Matamala, and the Greek Anastasis Germanidis after they met at New York University Tisch School of the Arts ITP. The company raised US$2 million in 2018 to build a platform to deploy machine learning models at scale inside multimedia applications.\\nIn December 2020, Runway raised US$8.5 million in a Series A funding round.\\nIn December 2021, the company raised US$35 million in a Series B funding round.\\nIn August 2022, the company co-released an improved version of their Latent Diffusion Model called Stable Diffusion together with the CompVis Group at Ludwig Maximilian University of Munich and a compute donation by Stability AI.\\nOn December 21, 2022 Runway raised US$50 million in a Series C round. Followed by a $141 million Series C extension round in June 2023 at a $1.5 billion valuation from Google, Nvidia, and Salesforce to build foundational multimodal AI models for content generation to be used in films and video production.\\nIn February 2023 Runway released Gen-1 and Gen-2 the first commercial and publicly available foundational video-to-video and text-to-video generation model accessible via a simple web interface.\\nIn June 2023 Runway was selected as one of the 100 Most Influential Companies in the world by Time magazine.\\n\\n\\n== Services and technologies ==\\nRunway is focused on generative AI for video, media, and art. The company focuses on developing proprietary foundational model technology that professionals in filmmaking, post-production, advertising, editing, and visual effects can utilize. Additionally, Runway offers an iOS app aimed at consumers\\nThe Runway product is accessible via a web platform and through an API as a managed service.\\n\\n\\n=== Stable Diffusion ===\\nStable Diffusion is an open-source deep learning, text-to-image model released in 2022 based on the original paper High-Resolution Image Synthesis with Latent Diffusion Models published by Runway and the CompVis Group at Ludwig Maximilian University of Munich. Stable Diffusion is mostly used to create images conditioned on text descriptions.\\n\\n\\n=== Gen-1 ===\\nGen-1 is a video-to-video generative AI system that synthesize new videos by applying the composition and style of an image or text prompt to the structure of a source video. The model was released in February 2023. The Gen-1 model was trained and developed by Runway based on the original paper Structure and Content-Guided Video Synthesis with Diffusion Models from Runway Research. Gen-1 is an example of Generative artificial intelligence for video creation.\\n\\n\\n=== Gen-2 ===\\nGen-2 is a multimodal AI system that can generate novel videos with text, images or video clips. The model is a continuation of Gen-1 and includes a modality to generate video conditioned to text. Gen-2 is one of the first commercially available text-to-video models.\\n\\n\\n=== Gen-3 Alpha ===\\nGen-3 Alpha is the first of an upcoming series of models trained by Runway on a new infrastructure built for large-scale multimodal training. It is a major improvement in fidelity, consistency, and motion over Gen-2, and a step towards building General World Models.\\nTraining data for Gen-3 has been sourced from thousands of YouTube videos and potentially pirated films.\")]\n"
     ]
    }
   ],
   "source": [
    "# Wikipedia Data Loader\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "docs=WikipediaLoader(query=\"Gen AI\",load_max_docs=2).load()\n",
    "print(len(docs))\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation(Data to Text Chunks) using LangChain_Community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'Minor Project Report.pdf', 'page': 0}, page_content='Multi-Class Ship Classification of Commercial and\\nNaval Vessels using Convolutional Neural Network\\nA PROJECT REPORT\\nSubmitted by\\nAKASH VARMA DATLA [RA2111047010131]\\nAMAN PARASHER [RA2111047010157]\\nUnder the Guidance of\\nDr. U.Sakthi\\nAssistant Professor,\\nDepartment of Computational Intelligence\\nin partial fulfilment of the requirements for the degree of\\nBACHELOR OF TECHNOLOGY\\nin\\nARTIFICIAL INTELLIGENCE\\nDEPARTMENT OF COMPUTATIONAL INTELLIGENCE\\nCOLLEGE OF ENGINEERING AND TECHNOLOGY\\nSRM INSTITUTE OF SCIENCE AND TECHNOLOGY\\nKATTANKULATHUR- 603 203\\nOCTOBER 2024\\n'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 1}, page_content='1\\nDepartment of Computational Intelligence\\nSRM Institute of Science & Technology\\nOwn Work* Declaration Form\\nThis sheet must be filled in (each box ticked to show that the condition has been met). It must\\nbe signed and dated along with your student registration number and included with all\\nassignments you submit – work will not be marked unless this is done.\\nTo be completed by the student for all assessments\\nDegree/ Course: B. Tech / Artificial Intelligence\\nStudent Name: Akash Varma Datla, Aman Parasher\\nRegistration Number: RA2111047010131, RA2111047010157\\nTitle of Work: Multi-Class Ship Classification of Commercial and Naval Vessels using\\nConvolutional Neural Network\\nI / We hereby certify that this assessment compiles with the University’s Rules and\\nRegulations relating to Academic misconduct and plagiarism**, as listed in the University\\nWebsite, Regulations, and the Education Committee guidelines.\\nI / We confirm that all the work contained in this assessment is my / our own except where\\nindicated, and that I / We have met the following conditions:\\n● Clearly referenced / listed all sources as appropriate\\n● Referenced and put in inverted commas all quoted text (from books, web, etc)\\n● Given the sources of all pictures, data etc. that are not my own\\n● Not made any use of the report(s) or essay(s) of any other student(s) either past or\\npresent\\n● Acknowledged in appropriate places any help that I have received from others (e.g.\\nfellow students, technicians, statisticians, external sources)\\n● Compiled with any other plagiarism criteria specified in the Course handbook /\\nUniversity website\\nI understand that any false claim for this work will be penalized in accordance with the\\nUniversity policies and regulations.\\nDECLARATION:\\nI am aware of and understand the University’s policy on Academic misconduct and\\nplagiarism and I certify that this assessment is my / our own work, except were indicated by\\nreferring, and that I have followed the good academic practices noted above.\\nIf you are working in a group, please write your registration numbers and sign with the date\\nfor every student in your group.\\n'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 2}, page_content='2\\nSRM INSTITUTE OF SCIENCE AND TECHNOLOGY\\nKATTANKULATHUR – 603 203\\nBONAFIDE CERTIFICATE\\nCertified that 18CSP107L - Minor Project report titled “Multi-Class Ship\\nClassification of Commercial and Naval Vessels using Convolutional Neural\\nNetwork” is the bonafide work of AKASH VARMA DATLA\\n[RA2111047010131] and AMAN PARASHER [RA2111047010157] who\\ncarried out the project work under my supervision. Certified further, that to the best of\\nmy knowledge the work reported herein does not form any other project report or\\ndissertation on the basis of which a degree or award was conferred on an earlier\\noccasion on this or any other candidate.\\nSIGNATURE SIGNATURE\\nDr. U.Sakthi Dr. R. ANNIE UTHRA\\nSUPERVISOR\\nASSISTANT PROFESSOR PROFESSOR & HEAD\\nDEPARTMENT OF\\nCOMPUTATIONAL\\nINTELLIGENCE\\nDEPARTMENT OF\\nCOMPUTATIONAL\\nINTELLIGENCE'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 3}, page_content='3\\nACKNOWLEDGEMENTS\\nWe express our humble gratitude to Dr. C. Muthamizhchelvan, Vice-Chancellor, SRM Institute of\\nScience and Technology, for the facilities extended for the project work and his continued support.\\nWe extend our sincere thanks to Dr. T. V. Gopal, Dean-CET, SRM Institute of Science and\\nTechnology, for his invaluable support.\\nWe wish to thank Dr. Revathi Venkataraman, Professor and Chairperson, School of Computing,\\nSRM Institute of Science and Technology, for her support throughout the project work.\\nWe encompass our sincere thanks to Dr. M. Pushpalatha, Professor and Associate Chairperson,\\nSchool of Computing and Dr. C.Lakshmi, Professor and Associate Chairperson, School of\\nComputing, SRM Institute of Science and Technology, for their invaluable support. We are\\nincredibly grateful to our Head of the Department, Dr. R. Annie Uthra, Professor, Department of\\nComputational Intelligence, SRM Institute of Science and Technology, for her suggestions and\\nencouragement at all the stages of the project work.\\nWe want to convey our thanks to our Project Coordinator, Dr.M.Abirami, Panel Head, Dr.Saad\\nYunus Sait and Panel Members, Dr. M Vimaladevi, Dr.R.Babu, Mrs. Shaik Rasheeda Begum,\\nDepartment of Computational Intelligence, SRM Institute of Science and Technology, for their\\ninputs during the project reviews and support.\\nWe register our immeasurable thanks to our Faculty Advisor, Dr. B. Pitchaimanickam, Department\\nof Computational Intelligence, SRM Institute of Science and Technology, for leading and helping us\\nto complete our course.\\nOur inexpressible respect and thanks to our guide, Dr. U.Sakthi , Department of Computational\\nIntelligence, SRM Institute of Science and Technology, for providing us with an opportunity to\\npursue our project under her mentorship. She provided us with the freedom and support to explore\\nthe research topics of our interest. Her passion for solving problems and making a difference in the\\nworld has always been inspiring.\\nWe sincerely thank all the staff and students of Computational Intelligence, School of Computing,\\nS.R.M Institute of Science and Technology, for their help during our project. Finally, we would like\\nto thank our parents, family members, and friends for their unconditional love, constant support and\\nencouragement'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 4}, page_content='4\\nABSTRACT\\nThis work seeks to classify various ship categories on the high-resolution optical remote sensing\\ndataset known as FGSC-23 using deep learning models. The dataset contains 23 types of ships, but for\\nthis study, six categories are selected: Medical Ship, Hovercraft, Submarine, Fishing Boat, Passenger\\nShip and Liquified Gas Ship. The adopted ship categories were thereafter used to train four deep\\nlearning models which included VGG16, EfficientNet, ResNet50v2, and MobileNetv2. The accuracy,\\nprecision, and AUC parameters were used to evaluate the models where the best one, ResNet50v2, was\\nset up as accurate. Using these models, it should be possible to achieve a practical deployment aiming\\nat fine-grained classification of ships that will contribute to enhancing maritime surveillance\\ntechniques. ResNet50v2 model had the highest precision of 0.9058 and on the other hand MobileNetv2\\nhad the highest AUC of 0.9932. The analysis of the identified models is performed further in this work\\nto illustrate their advantages and shortcomings in adherence to fine-grained ship classification tasks.\\nBased on this research, the practical implications transcend theoretical comparisons of performance\\nmetrics, as useful information is provided to improve security applications in the maritime domain,\\nsurveillance, and monitoring systems.\\nCategorization and identification of ships is a very important process in global maritime business\\nbecause it is used in decision-making processes in fields like security and surveillance, fishing control,\\nsearch and rescue and conservation of the environment. The models highlighted are namely\\nResNet50v2 as well as MobileNetv2, proved to be robust in real-time applications such scenarios\\nbecause of their ability to accurately and proficiently distinguish the differences between the ship types.\\nIn addition, this study suggests the luminal possibility of doing further improvement on these models\\nusing data enhancement strategies like transfer learning, data augmentation, and hyperparameter\\noptimization which would enable it to perform impressively on any other maritime datasets. Therefore,\\nthe outcomes are beneficial for furthering work in automated ship detection and classification and are\\nimportant toward enhancing the overall effectiveness and safety of navies across the globe.'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 5}, page_content='5\\nTABLE OF CONTENTS\\nABSTRACT 4\\nTABLE OF CONTENTS 5\\nLIST OF FIGURES\\nLIST OF TABLE\\n6\\n7\\nABBREVIATIONS 8\\nCHAPTER NO. TITLE PAGE NO.\\n1 INTRODUCTION 9\\n1.1 General (Introduction to Project) 9\\n1.2 Motivation 10\\n2 LITERATURE SURVEY 11\\n2.1 Deep Learning Techniques for Ship Classification: A\\nComprehensive Review\\n11\\n2.2 Enhancing Ship Classification with Pretrained Models\\nand Data Augmentation\\n11\\n2.3 Limitations Identified from Literature Survey\\n(Research Gaps)\\n12\\n2.4 Research Objectives 12\\n3 PROPOSED METHODOLOGY 14\\n3.1 Preprocessing and Data Augmentation 14\\n3.1 Model Architectures 15\\n3.1 Transfer Learning and Training 16\\n3.1 Evaluation Metrics 16\\n4 RESULTS AND DISCUSSIONS 18\\n5 CONCLUSION AND FUTURE ENHANCEMENTS 21\\n5.1 Conclusion 21\\n5.2 Future Enhancements 21\\n6 REFERENCES 23\\n7 APPENDIX 25\\n7.1 A. CONFERENCE PUBLICATION 25\\n7.2 B. PUBLICATION DETAIL 26\\n7.3 C. PLAGIARISM REPORT 27'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 6}, page_content='6\\nLIST OF FIGURES\\nFIGURE NO. TITLE PAGE NO.\\n3.1.1 Process Flow Diagram of Ship Classification 14\\n3.2.1 Architecture Diagram of Ship Classification 15\\n4.1 Accuracy Comparisons of Different Models 19\\n4.2 Precision Comparisons of Different Models 19\\n4.3 AUC Comparisons of Different Models 20'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 7}, page_content='7\\nLIST OF TABLE\\nFIGURE NO. TITLE PAGE NO.\\n4.1 Performance Analysis 18'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 8}, page_content='8\\nABBREVIATIONS\\nAI Artificial Intelligence\\nFGSC Fine-Grained Ship Classification\\nVGG Visual Geometry Group\\nResNet Residual Neural Network\\nAUC Area Under the Curve\\nCNN Convolutional Neural Network\\nViT Vision Transformers\\nSE Squeeze and Excitation\\nADAM Adaptive Moment Estimation'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 9}, page_content='9\\n1 INTRODUCTION\\n1.1 GENERAL INTRODUCTION\\nShip grouping is an important procedure in maritime vigilance systems to sort different kinds of\\nships with high accuracy. Classification of ships is also important for several reasons such as\\nsecurity, environmental conservation as well as traffic control on water channels. FGSC-23 is a\\nfine-grained dataset in the ship classification field, which includes 23 different ship types and a\\ntotal of 4052 samples are divided into categories they belong to, which aspect ratio they have and\\nin which direction are dispersed. The dataset has numerous image scenes and fine categorization,\\nwhich constitutes a complex issue for machine learning since the variations of ship kinds are very\\nclose. By focusing on classifying six specific categories of ships from the FGSC-23 dataset:\\nSubmarine, Medical Ship, Hovercraft, Fishing Boat, Passenger Ship, Liquified gas ship. Each of\\nthese categories was chosen because they were appropriate for both civilian and defense markets.\\nAlthough the FGSC-23 dataset is commonly used in ship classification research, by focusing on\\nthe fine-grained nature of the task in dealing with ships whose intra class variations deviate little\\nfrom each other. The selected models effectively solve this increased complexity of the problem.\\nIt is imperative that differences between classes are well distinguished and hence the objective of\\nthe current research is to use enhanced deep learning classification for ship classification. CNN\\narchitecture is the most important choice for the tradeoff between performance and computational\\nefficiency.\\nTo achieve this, four different convolutional neural network (CNN) architectures are used, models\\nincluding VGG16, EfficientNet, ResNet50v2, and MobileNetv2. VGG16 featured for its simple and\\nclassical deep convolutional structure, which is a starting point in the construction of feature extraction.\\nVGG16 is a classic use of small 3x3 convolutional filters that can capture very fine patterns. Since it\\nhas many parameters, it is a good comparative model, though. MobileNetV2: In terms of\\ncomputational cost, one is selected for its efficiency. In MobileNetV2, depth wise separable\\nconvolutions are used, drastically reducing the number of parameters and operations while keeping on\\npar accuracy. This is particularly useful in mobile and embedded systems where resources are limited.\\nResNet50V2: Residual connections are selected for their deep architecture which alleviates vanishing\\ngradient issues. This speeds up the training, especially in deep networks. As ResNet50V2 whose depth\\nis suitable to capture complex features in larger datasets. EfficientNet: Had scalability in mind. Deep,\\nwide, and low resolution together enable a model that is efficient while achieving high accuracy with\\nless parameters.'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 10}, page_content='10\\n1.2 MOTIVATION\\nAccurate ship classification is crucial for maritime operations such as security, traffic control, and\\nenvironmental protection. The FGSC-23 dataset presents a significant challenge due to the fine-grained\\nnature of the task, where visual differences between ship types are subtle. Traditional methods struggle\\nwith such close intra-class variations, emphasizing the need for more advanced deep learning models.\\nWith maritime activities becoming increasingly diverse and complex, there is a growing need for\\nefficient systems that can operate in real-time while maintaining high accuracy. The classification of\\nships is not only essential for managing civilian maritime traffic but also for defense-related\\napplications, where timely and precise identification of vessels is critical. As the volume of maritime\\ndata grows, so does the demand for models that can scale effectively without compromising\\nperformance.\\nThis research focuses on enhancing ship classification accuracy and efficiency by using CNN\\narchitectures like VGG16, MobileNetV2, ResNet50V2, and EfficientNet. Each model offers unique\\nstrengths in feature extraction and computational efficiency, addressing both the complexity of the\\nFGSC-23 dataset and the practical need for real-time, resource-efficient applications in maritime\\nsystems. By targeting six specific ship categories relevant to both civilian and defense sectors, this\\nstudy aims to bridge the gap between high-performance models and practical deployment in maritime\\nsurveillance and monitoring.\\nUltimately, the motivation behind this study is to provide a solution that balances cutting-edge deep\\nlearning techniques with the real-world constraints of computational resources. Through this, we aim\\nto contribute to the development of more reliable and scalable ship classification systems, which can\\nimprove the safety and efficiency of maritime operations on a global scale.'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 11}, page_content=\"11\\n2 LITERATURE SURVEY\\n2.1 SUBTITLE 1: DEEP LEARNING TECHNIQUES FOR SHIP CLASSIFICATION: A\\nCOMPREHENSIVE REVIEW\\nThis paper reviews various deep learning techniques utilized for ship classification, focusing on recent\\nadvancements and methodologies. The study highlights the growing importance of accurate ship\\nclassification in maritime safety, environmental monitoring, and fleet management. With the\\nincreasing volume of maritime data, deep learning models, such as Convolutional Neural Networks\\n(CNNs) and their variants, have demonstrated remarkable effectiveness in classifying ships from\\nimages. The research emphasizes that models like VGG16, MobileNetV2, and EfficientNet show\\npromising results in terms of precision and accuracy, significantly enhancing the automation of ship\\nclassification tasks. However, challenges such as the need for extensive labeled datasets and the\\ncomputational demands of training these models are discussed, pointing to a need for efficient data\\naugmentation and transfer learning strategies.\\n2.2 SUBTITLE 2: ENHANCING SHIP CLASSIFICATION WITH PRETRAINED\\nMODELS AND DATA AUGMENTATION\\nIn this study, researchers explore the application of pretrained models and data augmentation\\ntechniques in improving ship classification accuracy. The findings reveal that employing models like\\nResNet50V2 not only accelerates the training process but also enhances the model's ability to\\ngeneralize to unseen data. Data augmentation strategies, such as rotation, shifting, and zooming, are\\nshown to mitigate overfitting and improve the robustness of the classification system. Despite the\\nadvancements, the study identifies potential limitations, including the dependency on the quality of the\\ntraining data and the challenge of maintaining model performance across various environmental\\nconditions. The integration of these techniques is crucial for developing a reliable ship classification\\nsystem that operates effectively in diverse maritime scenarios.\"),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 12}, page_content='12\\n2.3 LIMITATIONS IDENTIFIED FROM LITERATURE\\nSURVEY (RESEARCH GAPS)\\nThe review of recent methods for ship classification highlighted several limitations in existing\\napproaches, particularly in Synthetic Aperture Radar (SAR) image recognition and fine-grained ship\\nclassification:\\n1. Manual Feature Selection in Traditional Methods: Earlier methods, such as those using\\nCFAR (Constant False Alarm Rate), rely on manually designed features, which are not only\\nlabor-intensive but also struggle with generalization. These methods are particularly vulnerable\\nto challenges like sea clutter and complex maritime environments, limiting their scalability.\\n2. Class Imbalance and Dataset Limitations: Despite advances in deep learning, including the\\nuse of CNNs for ship classification, models often suffer from class imbalance, where\\nunderrepresented ship classes are inaccurately classified. Studies have shown that class\\nimbalance impacts model performance, especially in SAR datasets where some ship types are\\nrare.\\n3. Spatial Information Loss in Deep CNNs: Conventional CNNs, especially as they deepen,\\nface the challenge of spatial information loss. As features are compressed and reduced through\\nlayers, finer details necessary for distinguishing between ships with similar structures may be\\nlost, leading to lower classification accuracy.\\n4. Insufficient Handling of High Intra-Class Variation: Fine-Grained Ship Classification\\n(FGSC) poses unique challenges due to high intra-class variation. Models often struggle to\\ndifferentiate between ships of similar hull structures but distinct superstructures, which affects\\nclassification precision, particularly in military and commercial ship datasets.\\n2.1 RESEARCH OBJECTIVES\\nOur project is guided by three core objectives designed to address the critical aspects of ship\\nclassification using deep learning models.\\n1. Achieving Fine-Grained Classification Accuracy: The first objective is to improve the fine-\\ngrained classification of ships using the FGSC-23 dataset. Focusing on six specific ship\\ncategories—Medical Ship, Hovercraft, Submarine, Fishing Boat, Passenger Ship, and Liquified\\nGas Ship—this study aims to evaluate the performance of four deep learning models: VGG16,\\nEfficientNet, ResNet50v2, and MobileNetv2. By leveraging these models, our goal is to'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 13}, page_content='13\\noptimize precision and accuracy, contributing to more effective maritime surveillance and\\ndecision-making processes.\\n2. Evaluating and Enhancing Model Performance: The second objective emphasizes the\\nevaluation of model performance based on key metrics such as accuracy, precision, and AUC.\\nThe research identifies ResNet50v2 as the most accurate model with a precision of 0.9058 and\\nMobileNetv2 as the model with the highest AUC at 0.9932. Additionally, this objective\\nexplores potential enhancements to these models through data augmentation, transfer learning,\\nand hyperparameter optimization to further improve their classification capabilities across\\nvarious maritime datasets.\\n3. Practical Application in Maritime Surveillance: The third objective is to apply the insights\\ngained from model evaluations to practical maritime surveillance and monitoring systems. This\\ninvolves identifying how these models can contribute to real-time applications such as ship\\ndetection, security, fishing control, and environmental conservation. By refining ship\\nclassification techniques, the research aims to support enhanced naval operations and global\\nmaritime safety.'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 14}, page_content='14\\n3 PROPOSED METHODOLOGIES\\nThis research investigates the application of deep learning modalities for the task of fine-grained\\nship classification on the FGSC-23 dataset. The approach focuses on six specific ship categories:\\nSubmarine, Medical ship, Hovercraft, Fishing boat, Passenger ship, and Liquified gas ship. To\\nachieve accurate classification, four pre-trained convolutional neural networks (CNNs) were utilized:\\nVGG16, EfficientNet, ResNet50v2, and MobileNetv2.\\nThe FGSC-23 dataset comprises high-resolution optical ship images spanning 23 ship categories\\nwith 4052 samples. These images are well-suited for fine-grained classification due to the\\navailability of class, aspect ratio, and distribution direction labels. For this study, six categories were\\nselected, covering both civil and naval vessels.\\n3.1 PREPROCESSING AND DATA AUGMENTATION\\nTo ensure the models generalize well and to prevent overfitting, the dataset was divided into training,\\nvalidation, and test sets. Preprocessing included resizing all images to a uniform size of 224x224\\npixels, followed by normalization. Simple data augmentation techniques such as rotation, flipping,\\nand scaling were applied to the training set to enhance generalization. These steps aimed to improve\\nmodel robustness while working with high-resolution ship images.\\nFig 3.1.1 Process Flow Diagram of Ship Classification'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 15}, page_content='15\\n3.2 MODEL ARCHITECTURES\\nFour deep learning models were employed to classify the ships from the FGSC-23 dataset. Each\\nmodel brought unique capabilities to the classification task:\\n1. VGG16: This convolutional neural network (CNN) has 16 layers. Despite its simplicity,\\nVGG16 is known for effective feature extraction. It uses convolutional and pooling layers\\nfor feature extraction, followed by fully connected layers for classification.\\n2. EfficientNet: EfficientNet optimizes both performance and computational resources by\\nscaling in three dimensions—depth, width, and image resolution. It provides high accuracy\\nwith minimal computational overhead, making it ideal for large datasets like FGSC-23.\\n3. ResNet50v2: ResNet50v2, with its 50 layers, incorporates identity mapping to address the\\nvanishing gradient problem, facilitating deeper training. The model’s architecture enables it\\nto capture hierarchical features and classify complex ship categories effectively.\\n4. MobileNetv2: MobileNetv2 employs depth-wise separable convolutions to significantly\\nreduce the computational load without compromising accuracy. This makes it particularly\\nsuitable for real-time applications on mobile and embedded devices.\\nFig 3.2.1 Architecture Diagram of Ship Classification\\nIn brief, the workflow of ship classification using deep learning, which is illustrated in Fig. 3.2.1,\\nconsists of data preprocessing, model training, model testing, and model performance testing to\\nselect an optimum deep learning model for the chosen problem.'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 16}, page_content=\"16\\n3.3 TRANSFER LEARNING AND TRAINING\\nAll four models were pre-trained on the ImageNet dataset and then fine-tuned on the FGSC-23\\ndataset. Transfer learning allowed the models to leverage pre-learned features, reducing the amount\\nof data required to achieve high performance.\\nEach model was trained using the Adam optimizer and categorical cross-entropy loss function. The\\ntraining was limited to 50 epochs with early stopping to prevent overfitting. The models were trained\\nwith careful monitoring to ensure they did not overfit, and training was halted when the validation\\nloss plateaued.\\n3.4 EVALUATION METRICS\\nThe models were evaluated using key metrics: accuracy, precision, and Area Under the Curve\\n(AUC). These metrics provided a comprehensive view of each model’s performance on the fine-\\ngrained classification task.\\n1. Accuracy: Accuracy measures the overall performance of the model by calculating the\\npercentage of correctly classified instances. It is defined as:\\n\\u200b\\n2. Precision: Precision assesses the model’s ability to avoid false positives by measuring the\\nproportion of true positives among the predicted positives. It is defined as:\\n3. Area Under the Curve (AUC): AUC evaluates the model's ability to distinguish between\\nclasses. It provides a balanced measure between True Positives (TP) and False Positives (FP)\\nacross various thresholds:\"),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 17}, page_content='17\\nIn terms of performance, EfficientNet and MobileNetv2 outperformed the other models due to their\\nlightweight architectures and efficient computation strategies. MobileNetv2, with its depth-wise\\nseparable convolutions, required fewer trainable weights and operations, allowing for high efficiency.\\nEfficientNet’s compound scaling method also optimized the model for both performance and\\ncomputational efficiency.\\nResNet50v2 demonstrated strong performance, leveraging its skip connections to handle deeper\\nmodels and capture complex patterns. However, VGG16, despite its depth, struggled with overfitting\\ndue to its large number of parameters and high computational demands, resulting in comparatively\\nlower accuracy.'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 18}, page_content=\"18\\n4 RESULTS AND DISCUSSIONS\\nThis project evaluated the performance of four deep learning models—MobileNetV2, ResNet50V2,\\nVGG16, and EfficientNet—for ship classification, using accuracy, precision, and AUC as key metrics.\\nResNet50V2 achieved the highest accuracy at 87.9%, closely followed by MobileNetV2 and\\nEfficientNet, both with 87.5%, demonstrating these models' strong feature extraction capabilities. In\\ncontrast, VGG16 lagged with an accuracy of 43.7%, likely due to its simpler architecture, which limits\\nits ability to distinguish fine-grained differences among ship types.\\nPrecision results showed a similar trend, with ResNet50V2 and MobileNetV2 leading at 90.5% and\\n90.3%, respectively, while EfficientNet scored 87.1%. VGG16 again underperformed with a precision\\nof 50%, indicating frequent misclassification. In terms of AUC, MobileNetV2 achieved the highest\\nscore at 99.3%, followed closely by EfficientNet at 99.2%, and ResNet50V2 at 98.5%, confirming\\ntheir reliability in distinguishing between classes. VGG16’s AUC of 80.5% further reflected its\\nlimitations in capturing complex patterns within the data.\\nOverall, ResNet50V2, MobileNetV2, and EfficientNet demonstrated effective and balanced\\nperformance across all metrics, highlighting the advantage of modern architectures with optimizations\\nlike residual connections and compound scaling. VGG16’s lower scores across all metrics underscore\\nthe importance of architectural complexity for accurate, fine-grained classification.\\nTable 4.1: Performance Analysis\\nModel Accuracy (%) Precision (%) AUC\\nMobileNetv2 87.5 90.3 99.3\\nResNet50v2 87.9 90.5 98.5\\nVGG16 43.7 50.0 80.5\\nEfficientNet 87.5 87.1 99.2\"),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 19}, page_content='19\\nFig 4.1: Accuracy Comparisons of Different Models\\nIn fig 4.1, the accuracy of ResNet50v2 was excellent and achieved an impressive 87.98% for most\\nship categories. On the other hand, VGG16 showed extremely low accuracy of 43.75 % (i.e\\nsignificantly lower accuracy as it has more difficulties differentiating closely related ship classes).\\n.\\nFig 4.2: Precision Comparisons of Different Models\\nIn fig 4.2,With a precision of 90.58%, it turns out that ResNet50v2 was quite reliable at predicting\\nfrom ship categories. On the other hand, VGG16 precision was 50.0%, showing a high rate of\\nmisclassifications.'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 20}, page_content='20\\nFig 4.3: AUC Comparisons of Different Models\\nAUC Comparisons the AUC overall score gives the amount by which the model can correctly\\nseparate between positive and negative classes at different thresholds. This is shown in Fig. 4.3\\nwhere the accuracy of MobileNetv2 with the maximum AUC score of 99.32% portrays a good\\ndiscriminating ability between the six ship categories. EfficientNet was right behind at a 99.25%\\nAUC, and a very good performance by ResNet50v2 at 98.51%. VGG16 shortly with an AUC of\\n80.50%.\\n.'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 21}, page_content=\"21\\n5 CONCLUSION AND FUTURE ENHANCEMENT\\n5.1 CONCLUSION\\nThis study focuses on the classification of six ship categories from the FGSC-23 dataset using four\\ndeep learning models: VGG16, ResNet50v2, EfficientNet, and MobileNetv2 are on the list. The\\nFGSC-23 dataset, famous for its in-depth classification and wealth of scenes, provided an ideal\\nplatform for assessing these model performances. Among the choices, ResNet50v2 excelled by\\nreaching an accuracy score of 87.98%, a precision rate of 90.58%, along with a high AUC score of\\n98.51%, which serves as potential evidence of its applicability for classifying the positive and\\nnegative categories with much certainty. MobileNetv2 saw 90.32% precision along with an AUC of\\n99.32%, both indicators which were approximately equal to EfficientNet's strong performance-to-\\nsize ratio measured at 99.25% AUC.\\nResNet50v2 has surpassed all networks repeatedly in both accuracy and precision, thus emerging as\\nthe favored option for maritime object classification, which requires accurate typology. The success\\nof VGG16 in image categorization tasks was not sufficient for the fine-grained classification\\nchallenge, resulting in an accuracy of 43.75% and 50.00% precision. Across the FGSC-23 dataset,\\nfindings show that ResNet50v2 is the leading model for ship classification, making it usable for real\\nmaritime applications in security, traffic management, and environmental monitoring.\\nInvestigations going forward might examine ensemble learning methods that fuse several models\\nfor better classification, along with expanding the analysis to represent all 23 vessel types in the\\nFGSC-23 dataset, improving both preprocessing and data augmentation to improve performance\\nand generalization.\\nIn the Future, the flexibility of the model can be increased by integrating supplementary ship\\nclasses from the complete FGSC-23 dataset or alternative resources.\\n5.2 FUTURE ENHANCEMENTS\\nThis project holds several promising avenues for future improvement. By implementing these\\nenhancements, we can increase model accuracy, reduce computational load, and broaden the\\napplicability of the ship classification system to real-world scenarios.\"),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 22}, page_content=\"22\\n1. Hyperparameter Optimization is an essential step to ensure that our model performs at its best.\\nCurrently, fixed values for hyperparameters like learning rate, batch size, and dropout rates are\\nused, but these may not be optimal. In the future, we can explore advanced hyperparameter\\ntuning techniques, such as Grid Search or Random Search. Tools like Optuna and Keras Tuner\\ncan automate this search, identifying the ideal combination of hyperparameters more efficiently\\nthan manual adjustments. This optimization could lead to improved model accuracy and\\npotentially reduce training time by minimizing the need for trial and error.\\n2. Another valuable enhancement would be to experiment with Additional Pretrained Models\\nbeyond those already employed. While we currently use VGG16, MobileNetV2, EfficientNet,\\nand ResNet50V2, other architectures like InceptionNet or DenseNet could offer unique\\nadvantages. For instance, DenseNet's connectivity pattern helps retain spatial information,\\nwhich may be beneficial for distinguishing fine details in ship images. Additionally, Vision\\nTransformers (ViT), known for excelling in vision tasks by capturing long-range dependencies,\\ncould further improve classification accuracy by focusing on critical features in different parts\\nof the image.\\n3. Integrating Attention Mechanisms could also improve the model’s ability to identify critical\\nfeatures. Techniques like Self-Attention or Squeeze-and-Excitation (SE) blocks allow the\\nmodel to focus more on important areas within the image, such as specific structures or\\nmarkings unique to each ship type. This could enhance classification performance, especially\\nfor classes that share similar shapes but have distinct details.\\n4. While basic data augmentation has already been applied, Advanced Data Augmentation\\nTechniques could further increase model robustness. Introducing sophisticated transformations\\nsuch as cutout, random erasing, or mixup can simulate more diverse conditions in the training\\ndata. These techniques would make the model less susceptible to minor variations in image\\norientation, lighting, or background, which could occur in real-world maritime environments.\"),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 23}, page_content='23\\n6 REFERENCES\\n[1] Q. Guo, Z. Wang, Y. Sun and N. Liu, \"Maritime Ship Target Detection Based on the\\nYOLOv7 Model,\" 2023 International Conference on Image Processing, Computer Vision and\\nMachine Learning (ICICML), Chengdu, China, 2023.\\n[2] S. Arull Murugan, S. Dharsini, S. Ganapathi Subramaniyan, M. Kumar, O. Ashok\\nLokhande and Y. Shankar Narayanan, \"A Non-Lethal System for Preventing Maritime\\nVessels from Invading or Evading Naval Perimeters,\" 2022 10th RSI International Conference\\non Robotics and Mechatronics (ICRoM), Tehran, Iran, 2022.\\n[3] Huang, Q., Sun, H., Guo, X., Yuan, Y., Wang, Y., Gao, Q.: Ship detection based on\\nYOLO algorithm for visible images. IET Image Process. 18, 481–492, 2024\\n[4] J. Si, B. Song, J. Wu, W. Lin, W. Huang and S. Chen, \"Maritime Ship Detection Method\\nfor Satellite Images Based on Multiscale Feature Fusion,\" in IEEE Journal of Selected Topics in\\nApplied Earth Observations and Remote Sensing, vol. 16, pp. 6642-6655, 2023.\\n[5] Zheng Y, Zhang Y, Qian L, Zhang X, Diao S, Liu X, et al. (2023) A lightweight ship\\ntarget detection model based on improved YOLOv5s algorithm. PLoS ONE 18(4): e0283932,\\n2023.\\n[6] Xinqiang Chen, Meilin Wang, Jun Ling, Huafeng Wu, Bing Wu, Chaofeng Li, Ship\\nimaging trajectory extraction via an aggregated you only look once (YOLO) model, Engineering\\nApplications of Artificial Intelligence, Volume 130, 2024\\n[7] Fang, Z.; Wang, X.; Zhang, L.; Jiang, B. YOLO-RSA: A Multiscale Ship Detection\\nAlgorithm Based on Optical Remote Sensing Image. J. Mar. Sci. Eng, 2024\\n[8] M. He, Z. Yin, J. Liu and Z. Yang, \"SD-YOLO: High-precision network for SAR ship\\ntarget detection,\" 2024 5th International Conference on Computer Vision, Image and Deep\\nLearning (CVIDL), Zhuhai, China, 2024.\\n[9] Huang, L.; Wang, F.; Zhang, Y.; Xu, Q. Fine-Grained Ship Classification by Combining\\nCNN and Swin Transformer. Remote Sens. 2022.\\n[10] Huang, I.-L.; Lee, M.-C.; Nieh, C.-Y.; Huang, J.-C. Ship Classification Based on AIS\\nData and Machine Learning Methods. Electronics 2024.'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 24}, page_content='24\\n[11] X. Xu, X. Zhang and T. Zhang, \"Multi-Scale SAR Ship Classification with Convolutional\\nNeural Network,\" 2021 IEEE International Geoscience and Remote Sensing Symposium\\nIGARSS, Brussels, Belgium, 2021.\\n[12] B. W. Tienin, C. Guolong and R. M. Esidang, \"Comparative Ship Classification in\\nHeterogeneous Dataset with Pre-trained Models,\" 2022 IEEE Radar Conference (RadarConf22),\\nNew York City, NY, USA, 2022.\\n[13] J. He, H. Xie, X. Jiang, Z. Wu and G. Wang, \"Ship Recognition Algorithm Based on\\nResNet in SAR Images,\" 2022 IEEE International Conference on Signal Processing,\\nCommunications and Computing (ICSPCC), Xi\\'an, China, 2022.\\n[14] W. Yu et al., \"Multi-Stage Marine Ship Recognition Based on Stackable Residual Network,\"\\n2023 19th International Conference on Natural Computation, Fuzzy Systems and Knowledge\\nDiscovery (ICNC-FSKD), Harbin, China, 2023.\\n[15] H. Fu, Y. Li, Y. Wang and P. Li, \"Maritime Ship Targets Recognition with Deep\\nLearning,\" 2018 37th Chinese Control Conference (CCC), Wuhan, China, 2018'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 25}, page_content='25\\n7 APPENDIX\\n7.1 A - CONFERENCE PRESENTATION\\nThis project has been accepted for presentation at SmartCom-2025-Pune, India and publication\\nin Springer LNNS series subject to fulfilment of Guidelines by Springer.'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 26}, page_content='26\\n7.2 B - PUBLICATION DETAIL\\n'),\n",
       " Document(metadata={'source': 'Minor Project Report.pdf', 'page': 27}, page_content='27\\n7.3 C - PLAGIARISM REPORT\\n')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PyPDF Loader for reading the text in pdf\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "pdf_loader=PyPDFLoader(\"Minor Project Report.pdf\")\n",
    "pdf_docs=pdf_loader.load()\n",
    "pdf_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split text by characters using RecursiveCharacterTextSplitter (More Generic)\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=700,chunk_overlap=50)\n",
    "final_pdf_docs=text_splitter.split_documents(pdf_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='2\n",
      "SRM INSTITUTE OF SCIENCE AND TECHNOLOGY\n",
      "KATTANKULATHUR – 603 203\n",
      "BONAFIDE CERTIFICATE\n",
      "Certified that 18CSP107L - Minor Project report titled “Multi-Class Ship\n",
      "Classification of Commercial and Naval Vessels using Convolutional Neural\n",
      "Network” is the bonafide work of AKASH VARMA DATLA\n",
      "[RA2111047010131] and AMAN PARASHER [RA2111047010157] who\n",
      "carried out the project work under my supervision. Certified further, that to the best of\n",
      "my knowledge the work reported herein does not form any other project report or\n",
      "dissertation on the basis of which a degree or award was conferred on an earlier\n",
      "occasion on this or any other candidate.\n",
      "SIGNATURE SIGNATURE\n",
      "Dr. U.Sakthi Dr. R. ANNIE UTHRA\n",
      "SUPERVISOR' metadata={'source': 'Minor Project Report.pdf', 'page': 2}\n"
     ]
    }
   ],
   "source": [
    "print(final_pdf_docs[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='3\n",
      "ACKNOWLEDGEMENTS\n",
      "We express our humble gratitude to Dr. C. Muthamizhchelvan, Vice-Chancellor, SRM Institute of\n",
      "Science and Technology, for the facilities extended for the project work and his continued support.\n",
      "We extend our sincere thanks to Dr. T. V. Gopal, Dean-CET, SRM Institute of Science and\n",
      "Technology, for his invaluable support.\n",
      "We wish to thank Dr. Revathi Venkataraman, Professor and Chairperson, School of Computing,\n",
      "SRM Institute of Science and Technology, for her support throughout the project work.\n",
      "We encompass our sincere thanks to Dr. M. Pushpalatha, Professor and Associate Chairperson,\n",
      "School of Computing and Dr. C.Lakshmi, Professor and Associate Chairperson, School of\n",
      "Computing, SRM Institute of Science and Technology, for their invaluable support. We are\n",
      "incredibly grateful to our Head of the Department, Dr. R. Annie Uthra, Professor, Department of\n",
      "Computational Intelligence, SRM Institute of Science and Technology, for her suggestions and\n",
      "encouragement at all the stages of the project work.\n",
      "We want to convey our thanks to our Project Coordinator, Dr.M.Abirami, Panel Head, Dr.Saad\n",
      "Yunus Sait and Panel Members, Dr. M Vimaladevi, Dr.R.Babu, Mrs. Shaik Rasheeda Begum,\n",
      "Department of Computational Intelligence, SRM Institute of Science and Technology, for their\n",
      "inputs during the project reviews and support.\n",
      "We register our immeasurable thanks to our Faculty Advisor, Dr. B. Pitchaimanickam, Department\n",
      "of Computational Intelligence, SRM Institute of Science and Technology, for leading and helping us\n",
      "to complete our course.\n",
      "Our inexpressible respect and thanks to our guide, Dr. U.Sakthi , Department of Computational\n",
      "Intelligence, SRM Institute of Science and Technology, for providing us with an opportunity to\n",
      "pursue our project under her mentorship. She provided us with the freedom and support to explore\n",
      "the research topics of our interest. Her passion for solving problems and making a difference in the\n",
      "world has always been inspiring.\n",
      "We sincerely thank all the staff and students of Computational Intelligence, School of Computing,\n",
      "S.R.M Institute of Science and Technology, for their help during our project. Finally, we would like\n",
      "to thank our parents, family members, and friends for their unconditional love, constant support and\n",
      "encouragement' metadata={'source': 'Minor Project Report.pdf', 'page': 3}\n"
     ]
    }
   ],
   "source": [
    "# Split text by characters using CharacterTextSplitter\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "text_splitter=CharacterTextSplitter(separator=\"\\n\\n\",chunk_size=700,chunk_overlap=50)\n",
    "final_pdf_docs=text_splitter.split_documents(pdf_docs)\n",
    "print(final_pdf_docs[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='The HTML button tag defines a clickable button.  \\nThe CSS background-color property defines the background color of an element.')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split text at HTML element level using HTMLHeaderTextSplitter\n",
    "from langchain_text_splitters import HTMLHeaderTextSplitter\n",
    "html_string=\"\"\"\n",
    "<html>\n",
    "<body>\n",
    "<p>The HTML <code>button</code> tag defines a clickable button.</p>\n",
    "<p>The CSS <code>background-color</code> property defines the background color of an element.</p>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "headers_to_split_on=[(\"p\",\"Header 3\")]\n",
    "html_splitter=HTMLHeaderTextSplitter(headers_to_split_on)\n",
    "html_header_splits=html_splitter.split_text(html_string)\n",
    "html_header_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='Main menu  \\nmove to sidebar hide  \\nMain menu  \\nNavigation  \\nMain pageContentsCurrent eventsRandom articleAbout WikipediaContact us  \\nContribute  \\nHelpLearn to editCommunity portalRecent changesUpload file  \\nSearch  \\nSearch  \\nAppearance  \\nDonate Create account Log in  \\nPersonal tools  \\nDonate Create account Log in  \\nPages for logged out editors learn more  \\nContributionsTalk  \\nContents move to sidebar hide  \\nToggle Race subsection Toggle History subsection Toggle Innovations subsection  \\n(Top)  \\n1 Purpose  \\n2 Race  \\n2.1 Cars  \\n2.1.1 Garage 56  \\n2.2 Drivers  \\n2.3 Traditions and unique rules  \\n2.3.1 Schedule  \\n2.3.2 Classification  \\n2.3.3 Le Mans start  \\n3 Circuit  \\n4 History  \\n4.1 1923–1939  \\n4.2 1949–1969  \\n4.3 1970–1980  \\n4.4 1981–1993  \\n4.5 1994–1999  \\n4.6 2000–2005  \\n4.7 2006–2013  \\n4.8 2014–2020  \\n4.9 2021–present  \\n5 Innovations  \\n5.1 Aerodynamics  \\n5.2 Engines  \\n5.3 Brakes  \\n6 Winners  \\n7 Accidents  \\n8 Coverage  \\n9 Vintage racing  \\n10 See also  \\n11 Notes  \\n12 References  \\n13 Additional references  \\n14 External links  \\n24 Hours of Le Mans  \\nToggle the table of contents  \\n49 languages  \\nالعربيةAsturianuAzərbaycancaБългарскиBrezhonegCatalàČeštinaDanskDeutschEestiΕλληνικάEspañolEsperantoEuskaraفارسیFrançaisGalego한국어HrvatskiIdoBahasa IndonesiaItalianoעבריתქართულიLatviešuLietuviųLimburgsMagyarBahasa MelayuNederlands日本語Norsk bokmålNorsk nynorskPolskiPortuguêsRomânăРусскийShqipSimple EnglishSlovenčinaSlovenščinaСрпски / srpskiSrpskohrvatski / српскохрватскиSuomiSvenskaไทยTürkçeУкраїнська中文  \\nEdit links  \\nArticleTalk  \\nEnglish  \\nReadEditView history  \\nTools  \\nmove to sidebar hide  \\nTools  \\nActions  \\nReadEditView history  \\nGeneral  \\nWhat links hereRelated changesUpload fileSpecial pagesPermanent linkPage informationCite this pageGet shortened URLDownload QR code  \\nPrint/export  \\nDownload as PDFPrintable version  \\nIn other projects  \\nWikimedia CommonsWikidata item  \\nmove to sidebar hide  \\nAppearance  \\nCoordinates: 47°57′00″N 00°12′27″E\\ufeff / \\ufeff47.95000°N 0.20750°E\\ufeff / 47.95000; 0.20750  \\nFrom Wikipedia, the free encyclopedia  \\n24 Hours of Le MansFIA World Endurance ChampionshipVenueCircuit de la SartheLocation Le Mans, France47°57′00″N 00°12′27″E\\ufeff / \\ufeff47.95000°N 0.20750°E\\ufeff / 47.95000; 0.20750First race1923First WEC race2012Last race2024Distance13.626 km/ 8.467 miDuration24 hoursMost wins (driver) Tom Kristensen (9)Most wins (team) Joest Racing (13)Most wins (manufacturer) Porsche (19) The pits in the daytime The pits at dawnThe pits at night GT cars approaching Dunlop Bridge Drivers photograph from 2018 Fly-over with the tricolor of France Marshals waving safety flags to congratulate Audi in 2010 race Driver parade in Le Mans in 2018 Year Start Time Reason 1968 3:00pm Race being in September, as a result of the protests, strikes, and civil unrest in France during the spring of 1968. 1969 2:00pm 1969 French presidential election 1984 3:00pm 1984 European Parliament election in France 1998 2:00pm 1998 French Open final 2006 5:00pm To maximise television coverage between the World Cup games. 2007 3:00pm 2007 French legislative election 2020 2:30pm Race being in September, as a result of the Coronavirus Pandemic. The permanent pits and pit straight for both the Circuit de la Sarthe and Bugatti Circuit Rolling start of the 2008 race The Circuit de la Sarthe with the Bugatti Circuit (dashed line) A poster for the 1923 24 Hours of Le Mans Jaguar D-Type in 1956 Renault Alpine A443 from 1978 Group C Porsche 962 from 1988 Peugeot 905 from 1993 Ferrari F40 in 1995 race Audi R8 Bentley Speed 8 A diesel-powered Audi R10 TDI Audi R15 TDIPeugeot 908 HDi FAP Porsche 919 Hybrid in the front of Audi R18 in 2015 A 1969 Porsche 908 Langheck The 1950 Cadillac Le Monstre A 1929 supercharged Bentley 1991 Mazda 787B, the only Le Mans winner with Wankel engine The most successful participant of all time at Le Mans, Danish driver Tom Kristensen, has nine wins (7 with Audi), the latest in 2013. Tom Kristensen in the Walk of fame Le Mans-Winners 2013 A helicopter that provided aerial coverage for 2019 race An ACO host covering the 2016 race Ford GT40 alongside Chevrolet Corvette in 2015 Le Mans Legend Le Mans Start at Le Mans Classic 2018  \\nAnnual sports car race held in France  \\nThis article is about the sports car race in France. For the motorcycle race, see 24 Hours of Le Mans (motorcycle race). For other uses, see 24 Hours of Le Mans (disambiguation). For the 2024 race, see 2024 24 Hours of Le Mans.  \\nNot to be confused with 24 Hours of Lemons.  \\nThis article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources:\\xa0\"24 Hours of Le Mans\"\\xa0–\\xa0news\\xa0· newspapers\\xa0· books\\xa0· scholar\\xa0· JSTOR (June 2021) (Learn how and when to remove this message)  \\nMotor race  \\nThe 24 Hours of Le Mans (French: 24 Heures du Mans) is an endurance-focused sports car race held annually near the town of Le Mans, France.[1] It is widely considered to be one of the world\\'s most prestigious races,[2][3] and is one of the races—along with the Monaco Grand Prix and Indianapolis 500—that form the Triple Crown of Motorsport, and is also one of the races alongside the 24 Hours of Daytona and 12 Hours of Sebring that make up the informal Triple Crown of endurance racing.[2] Run since 1923, it is the oldest active endurance racing event in the world.[4]  \\nUnlike fixed-distance races whose winner is determined by minimum time, the 24 Hours of Le Mans is won by the car that covers the greatest distance in 24 hours. The cars on this track are able to achieve speeds of 366\\xa0km/h (227\\xa0mph), and reached 407\\xa0km/h (253\\xa0mph) on the Mulsanne Straight in 1988\\xa0– instigating the addition of more chicanes to the track to reduce speed reached. Racing teams must balance the demands of speed with the cars\\' ability to run for 24 hours without mechanical failure.[5] The race is organized by the Automobile Club de l\\'Ouest (ACO). It is held on the Circuit de la Sarthe, composed of closed public roads and dedicated sections of a racing track.  \\nThe 24 Hours of Le Mans was frequently part of the World Sportscar Championship from 1953 until that series\\' final season in 1992. In 2011, it was a part of the Intercontinental Le Mans Cup. Since 2012, the race has been a part of the FIA World Endurance Championship.[6] In the World Endurance Championship\\'s super-season of May 2018 to June 2019, the 24 Hours of Le Mans was both the second and the last round of the season.[7]  \\nPurpose[edit]  \\nThis section does not cite any sources. Please help improve this section by adding citations to reliable sources. Unsourced material may be challenged and removed. (May 2020) (Learn how and when to remove this message)  \\nLaunched when Grand Prix motor racing was the dominant form of motorsport throughout Europe, Le Mans was designed to present a different test. Instead of focusing on the ability of a car company to build the fastest machines, the 24 Hours of Le Mans would concentrate on the ability of manufacturers to build sporty yet reliable cars. This encouraged innovation in producing reliable and fuel-efficient vehicles, because endurance racing requires cars that last and spend as little time in the pits as possible.  \\nAt the same time, the layout of the track required cars with better aerodynamics and stability at high speeds. While this was shared with Grand Prix racing, few tracks in Europe had straights of a length comparable to the Mulsanne. Additionally, because the road is public and thus not as meticulously maintained as permanent racing circuits, racing puts more strain on the parts, increasing the importance of reliability.  \\nThe oil crisis in the early 1970s led organizers to adopt a fuel economy formula known as Group C that limited the amount of fuel each car was allowed. Although it was later abandoned, fuel economy remains important as new fuel sources reduce the time spent during pit stops. Such technological innovations have had a trickle-down effect and can be incorporated into consumer cars. This has also led to faster and more exotic supercars as manufacturers seek to develop faster road cars in order to develop them into even faster GT cars.  \\nAdditionally, hybrid systems (flywheel, super-capacitor, battery coupled with both petrol and diesel) have been championed in the LMP category as rules have been changed to their benefit and to further push efficiency.  \\nRace[edit]  \\nThe race is held in mid June, meaning the shortest night and very hot conditions for drivers, particularly in closed vehicles with poor ventilation. Rainy weather is common. The race begins in mid-afternoon and finishes the following day at the same hour the race started the previous day.[8]  \\nModern competitors often cover well over 5,000\\xa0km. The record is 2010\\'s 5,410\\xa0km (3,360\\xa0mi), six times the length of the Indianapolis 500, or about 18 times longer than a Formula One Grand Prix.[9] Drivers and racing teams strive for speed and avoiding mechanical damage, as well as managing the cars\\' consumables, primarily fuel, tires, and braking materials. It also tests endurance, with drivers frequently racing for over two hours before a relief driver can take over during a pit stop while eating and resting. Current regulations mandate that three drivers share each competing vehicle.  \\nCompeting teams race in groups called \"classes\", or cars of similar specification, while competing simultaneously for outright placing amongst all classes. Originally, the race showcased cars as they were sold to the general public, then called \"Sports Cars\", in contrast with the specialised racing cars used in Grand Prix motor racing. Over time, the competing vehicles evolved away from their publicly available road car roots. Today, the race comprises two classes: the purpose-built Sports prototypes which are also known as Le Mans Prototypes (LMP) and are the highest level in sports car racing, and the production-based Grand Touring (GT) cars which are similar to sports cars sold to the public. These are further broken down into two sub-classes: constructors\\' prototypes, privateer prototypes, and two subclasses of GT cars.[10]  \\nCompeting teams have had a wide variety of organizations, ranging from competition departments of road car manufacturers (eager to prove the supremacy of their products) to professional motor racing teams (representing their commercial backers, some of which are also car manufacturers who want to win without paying for their own teams) to amateur teams (racing as much to compete in the famous race as to claim victory for their commercial partners).  \\nThe race was a part of the World Sportscar Championship in every season from its inception in 1953 until its demise in 1992 except the 1956, 1975–1979 and 1989–1990 seasons, and since 2012 the race has been the part of the FIA World Endurance Championship. However, Le Mans has always had a stronger reputation than the World Championship.  \\nThe race is also known as a leg of the informal Triple Crown of Motorsport which links Formula One, IndyCar, and Sports car racing to represent a career achievement for drivers. Additionally, it is seen as a leg of the Triple Crown of endurance racing, which links the three largest sports car races together, with 12 Hours of Sebring and 24 Hours of Daytona forming the other legs. Since 1998, the American Le Mans Series (now the IMSA Weathertech Sports Car Championship) has held an endurance race, along with the 12 hours of Sebring, every year called \"Petit Le Mans\", as a 10-hour American version. In 2014, the Weathertech Sports Car Championship (a merger of the races at Sebring; Petit Le Mans in Braselton, Georgia; the 6 Hours of Watkins Glen in Watkins Glen, New York; and the Rolex Sports Car Series\\' 24 Hours of Daytona) held all four major American endurance classics in preparation for teams to race at Le Mans.  \\nCars[edit]  \\nThe race has approximately 60 competitors. Each car was required to have at least two seats. However, recently cars only need to have space to accommodate a second seat in the cockpit rather than the seat itself. Two doors are allowed; open cockpit cars do not require doors. Since 2014, all cars in the premier LMP1 category must have a roof due to safety concerns, with open-cockpit cars only permitted in the slightly slower LMP2 category. Since 2017, all prototype cars, LMP1 or LMP2, must have closed cockpits.[11]  \\nAlthough all cars compete at the same time, as of 2021 there are separate classes. A prize is awarded to the winner of each class and the overall winner. The number of classes has varied over the years, but there are now three: Hypercar, LMP2, and LMGT3.  \\nSuccessor to the Le Mans Prototype 1 (LMP1) is the custom-built Hypercar (LMH or LMDh) class. It is the top class and debuted in 2021. The new technical regulations are intended to prevent cost escalations while enabling greater variety in technical approaches and car aesthetics.[12]  \\nThis is followed by the LMP2 class where teams are obliged to run one of four approved chassis—ORECA, Ligier, Dallara, or Multimatic/Riley—mated with a standard 4.2-litre Gibson V8 engine. LMP1 teams are subject to no such restrictions. Their extra power, lower weight, and more complex aerodynamics result in much quicker lap times; LMP1 cars also may use hybrid technology.[13]  \\nThe next class is LMGT3, which are similar to production-based sports cars.[12]  \\nGarage 56[edit]  \\nConcept cars intended to test new automotive technologies may participate in the race under the \"Garage 56\" banner. Such entries are classified in the race results, though are not expected to be competitive as their sole focus is to demonstrate experimental features.[14]  \\nThe program debuted in 2012 with the DeltaWing, an unusual rocket-shaped car fielded by All-American Racers and supported by Nissan. The DeltaWing concept showed promise, delivering nearly LMP2-level performance while only consuming 48% of the fuel, but retired after a collision with an LMP1 car six hours into the race.[15]  \\nIn 2013, Garage 56 was given to the Swiss-designed hydrogen-fueled GreenGT H2, which was to be the first car without an internal combustion engine to compete at Le Mans. However, the car was pronounced unfit to take part in the race by the team a few days before the race.[16] In 2016, the H2 went on to complete a single demonstration lap at Le Mans.[17]  \\nThe Nissan ZEOD RC, a hybrid electric car based on the DeltaWing\\'s design, took the Garage 56 slot in 2014. Despite an early retirement from the race after only 23 minutes due to a gearbox issue, the ZEOD RC achieved its goals of hitting a top speed of 300\\xa0km/h (186.41\\xa0mph), and completing the first ever lap of Le Mans using exclusively electric power at racing speed.[18][19]  \\nIn 2015, the Garage 56 program took a break as all applications that year were deemed unfit by the ACO.[16]  \\nFrederic Sausset, a quadruple amputee, drove a modified Morgan LMP2 in the 2016 race.[14][20]  \\nFinancial problems forced Welter Racing to cancel its 2017 Garage 56 run with the Green4U Panoz Racing GT-EV, a biomethane-fuel prototype featuring a 3-cylinder 1.2-liter engine fueled by biomethane stored in cryogenic tanks.[14] Welter Racing went on to develop the car with hopes of entering the car in 2018 and 2019, but ultimately did not compete due to complex issues with the car in 2018, and due to Don Panoz\\'s death suspending the program in 2019. The 2019 slot was also eyed by UK-based constructor Perrinn with the Project 424, an LMP1-based electric-powered car with an autonomous driving mode;[21] however, this did not come to pass, and Garage 56 was left empty in both 2018 and 2019 due to the ACO deeming none of the applications sufficiently mature.[22][23]  \\n2020 saw Frederic Sausset attempting to return to Garage 56 under the SRT41 banner by fielding a specially modified Oreca 07 LMP2 car with a lineup of three disabled drivers; however, the attempt was cancelled due to the COVID-19 pandemic.[22][24] The SRT41 program was delayed to 2021, which saw Garage 56 successfully making a return for the first time in five years. Two of the drivers, paralyzed from the waist down, became the first disabled teammates to compete in the history of the race.[25]  \\nIn 2022, Garage 56 was once again empty.[26]  \\nFor 2023, a modified NASCAR Cup Series Next Gen[27] Chevrolet Camaro ZL1 stock car fielded by Hendrick Motorsports was the Garage 56 entry, with seven-times Cup champion Jimmie Johnson, 2009 Formula One world champion and NASCAR driver Jenson Button, and 2010 Le Mans overall and LMP1 winner Mike Rockenfeller driving the car. The car marked NASCAR\\'s 75th anniversary, which coincided with the race\\'s centenary.[28][29][30] Chad Knaus, Johnson\\'s crew chief during each of his Cup Series championships, was project manager, while the car bore #24 in honor of Hendrick vice chairman and former driver Jeff Gordon.[31]  \\nDrivers[edit]  \\nInitially, there were no rules on the number of car drivers or how long they could drive. Although almost all teams used two drivers in the early decades, some Le Mans drivers such as Pierre Levegh and Eddie Hall attempted to run the race solo, hoping to save time by not having to change drivers. This practice was later banned. Until the 1980s, there were teams in which only two drivers competed, but by the end of the decade, the rules were changed to stipulate that at least three drivers must drive each car.  \\nBy the 1990s, due to the speeds of the cars and the strain it puts on drivers, additional rules to reduce driver fatigue mandated that drivers could not drive for over 240 minutes (over 4 hours) and that no one driver could run for over 840 minutes (14 hours) total. With careful management of driver stints, this makes it possible to complete the race with only two drivers (as Jeroen Bleekemolen and Cooper MacNeil did in 2014), although the vast majority of teams still continue to use three drivers.[32][33]  \\nIn 2017, the driving time rules were further changed. If necessary, officials may require a drive time limit of 80 minutes of consecutive time behind the wheel and a minimum 30-minute rest break. The rule applies only if the air temperature is at least 32\\xa0°C (89.6\\xa0°F).[34]  \\nTraditions and unique rules[edit]  \\nAlthough it has been a part of the World Sportscar Championship for most of its existence, the race has had different regulations for safety and competition reasons partly due to its length. For many decades, cars had to run at least an hour into the race before they could refill fluids for the car, such as oil or coolant, except for fuel. This was an attempt by the ACO to help increase efficiency and reliability. Those who could not last the first hour without replacing lost fluids risked disqualification.  \\nAnother rule unique to Le Mans is that cars must be switched off while refueling in the pits. Not only is this safer and less of a fire hazard, but it is also another test of reliability, demanding a guaranteed ability to restart many times under race conditions. Another element of this rule is that mechanics are not allowed to work on the car while it is being refuelled (other than helping a driver in or out of the car), which has led teams to adapt innovative ways to decrease the time of these lengthy pit stops. Drivers can get out of the car and be replaced by another driver during refuelling. Those rules are also applied in the FIA World Endurance Championship.  \\nThere are various long-standing traditions at Le Mans, including the waving of the French tricolor to start the race. This is usually followed by a fly-over featuring jets trailing blue, white, and red smoke. A similar flag tradition is track marshals waving safety flags during the race\\'s final lap, congratulating the winners and other finishers.  \\nLe Mans was the venue for the first televised instance of a winning driver celebrating by spraying champagne instead of drinking it.[35] When Dan Gurney won the 1967 race with co-driver A. J. Foyt, the two drivers mounted the victory podium, and Gurney was handed a magnum of champagne. Looking down, he saw Ford CEO Henry Ford II, team owner Carroll Shelby and their wives, as well as several journalists who had predicted disaster for the high-profile duo. Gurney shook the bottle and sprayed everyone nearby. Gurney autographed and gave the bottle of champagne to Life photographer Flip Schulke, who used it as a lamp for years before returning it to Gurney.[36][37]  \\nSchedule[edit]  \\nThe first race was held on 26–27 May 1923 and has since been run annually in June with exceptions in 1956, when the race was held in July; 1968, when it was held in September due to nationwide political turmoil in May; 2020, when it was moved to 19–20 September due to the COVID-19 outbreak; and 2021, when it was moved to 21–22 August. The race has been cancelled ten times—in 1936 (a labour strike during the Great Depression) and between 1940 and 1948 (World War II).  \\nThe race usually takes place on the second weekend of June, with qualifying and practice taking place on the Wednesday and Thursday before the race, following a car inspection on Monday and Tuesday. Currently, these sessions are held in the evening, with two separate two-hour sessions held each night. Friday serves as a day of rest, and a parade of all the drivers through Le Mans is held.  \\nTest days held at the end of April or beginning of May served as a pre-qualification weeding out the slowest cars. However, in 2005 the exorbitant cost of transporting cars to and from Le Mans led organizers to move the test day to the first weekend of June. Pre-qualification was eliminated in 2000, meaning that all competitors invited to the test would be allowed into the race.  \\nSince 2001 the Le Mans Legend races have also been part of the schedule, usually running exhibition races during qualifying days, a few hours prior to the sessions for the Le Mans entrants.  \\nFrom its inception, until 2008, the race started at 16:00 local time on Saturday, and consequently from 2009 to 2019, 2022 and come 2025 & hereafter it started at 15:00 local time, with the race returning to its original start time of 16:00 in 2021, 2023 and 2024 respectively.  \\nThe only exceptions were as follows:  \\nClassification[edit]  \\nInitially, the car that covered the greatest distance from its starting position was the winner. This is known to have caught out the Ford team in 1966. With a dominant 1–2 lead, the two cars slowed to allow for a photo opportunity at the finish line, with Ken Miles slightly ahead of Bruce McLaren. However, since McLaren\\'s car had started much farther back on the grid than Miles\\'s, McLaren\\'s car had covered the greatest distance over the 24 hours. With the margin of victory determined to be eight metres, McLaren and his co-driver, Chris Amon, were declared the winners. The decision cost Miles and Denny Hulme a victory. Miles had already won the other two endurance races at Sebring and Daytona. With a win at Le Mans, he would have become the first man to win all three and the first to win them all in the same year.  \\nThe \"greatest distance\" rule was modified with the introduction of a rolling start in 1971. Now, the car that completes the greatest distance as of the final lap\\'s completion—where \"greatest distance\" is measured by the start/finish line for all competitors—wins. When two cars finish the same number of laps, their finishing order is determined by the faster overall completion time. This rule was used in the 2011 24 Hours of Le Mans to determine the race winner. The top two finishers completed 355 laps, with only 13 seconds difference between them.[38]  \\nAlthough \"greatest distance run\" determines the provisional order of finishers, additional requirements must be met for a car to be classified.[39]  \\nA car must complete the last lap of the race and complete the entire circuit faster than a prescribed maximum lap time. Ambiguity in this classification requirement has led to dramatic scenes where damaged cars have waited in the pits or on the edge of the track close to the finish line, restarted their engines, and crawled across the line to be listed amongst classified finishers.[citation needed] The practice of intentionally \"waiting for the final lap\" in this manner has been prohibited by rule in recent years. Cars must complete 70 percent of the distance covered by the overall winner to be classified. Even if it finishes the last lap of the race, a car failing to complete this number of laps is not deemed worthy of classification because of poor reliability or speed.  \\nAll classification requirements hold except in exceptional circumstances, as determined by the race stewards.[39]  \\nLe Mans start[edit]  \\nFurther information: Standing start  \\nThe race traditionally began with what became known as the Le Mans start, in which cars were lined up along the length of the pits. Until 1962, cars lined up by engine capacity. Beginning in 1963, qualifying times determined the lineup. The starting drivers stood on the opposite side of the front stretch. When the French flag dropped to signify the start, the drivers ran across the track, entered and started their cars without assistance, and drove away. This became a safety issue in the late 1960s when some drivers ignored their safety harnesses, then a recent invention. This led to drivers running the first few laps either improperly harnessed due to attempting to do it while driving or sometimes not even harnessed at all, leading to several deaths when cars were involved in accidents due to the bunched field at the start.  \\nThis starting method inspired Porsche to locate the ignition key switch to the left of the steering wheel. In a left-hand drive car, this allowed the driver to use his left hand to start the engine and his right hand to put the transmission into gear, which in turn shaves off a few tenths of a second.  \\nStirling Moss developed another method for speeding up the start. His car was waiting with first gear already engaged. He switched the starter on when he jumped in without depressing the clutch. The starter motor immediately jerked the car forward, but the engine did not start due to low RPM. After a few seconds of motion, he pushed the clutch down, allowing the engine to speed up and start while the car was moving.  \\nFeeling this type of start was unsafe, in the 1969 race, Jacky Ickx opposed it by walking across the track while his competitors ran. Although he was nearly hit by a faster competitor\\'s car while walking, Ickx took the time to fasten his safety belts before pulling away. Privateer John Woolfe died in an accident on the first lap of that race; Ickx won.  \\nThe traditional Le Mans start was changed for 1970. Cars were still lined up along the pit wall, but the drivers were already inside and strapped in. At the dropping of the French tricolor, the drivers started their engines and drove away.  \\nSince 1971, a rolling start (sometimes known as an Indianapolis start) begins the race. While the cars do still start out lined up against the pit wall, when the green flag is waved the cars pull away one by one to begin a formation lap behind the safety car; when that car returns to pits, the starter waves the French flag to start the race.[40]  \\nCircuit[edit]  \\nMain article: Circuit de la Sarthe  \\nThis section needs additional citations for verification. Please help improve this article by adding citations to reliable sources in this section. Unsourced material may be challenged and removed.Find sources:\\xa0\"24 Hours of Le Mans\"\\xa0–\\xa0news\\xa0· newspapers\\xa0· books\\xa0· scholar\\xa0· JSTOR (July 2022) (Learn how and when to remove this message)  \\nThe circuit on which the 24 Hours of Le Mans is run is named the Circuit de la Sarthe, after the department that Le Mans is within. It consists of both permanent track and public roads temporarily closed for the race. Since 1923, the track has been extensively modified, mostly for safety reasons, and now is 13.626\\xa0km (8.467\\xa0mi) in length. Although it initially entered the town of Le Mans, the track was cut short to better protect spectators. This led to the creation of the Dunlop Curve and Tertre Rouge corners before rejoining the old circuit on the Mulsanne Straight. Another major change was on the Mulsanne itself in 1990 when the FIA decreed that it would no longer sanction any circuit that had a straight longer than 2\\xa0km (1.2\\xa0mi). To comply with this, two chicanes were added to the 6-kilometre-long (3.7\\xa0mi) straight, dividing it into three pieces about 2\\xa0km each. The addition of the chicanes was further influenced by the fact that the speed of WM P88-Peugeot, driven by French driver Roger Dorchy, had been timed at 407\\xa0km/h (253\\xa0mph) during the 1988 race. This was the record speed before the addition of the chicanes.[41]  \\nDue to the shorter length of the straights, the speed record at Le Mans now, after the introduction of the chicanes, is 366\\xa0km/h (227\\xa0mph). Typically race cars achieve top speed of just under 320\\xa0km/h (200\\xa0mph) at the current track (with chicanes).[41]  \\nThe public sections of the track differ from the permanent circuit, especially in comparison with the Bugatti Circuit which is inside the Circuit de la Sarthe. Due to heavy traffic, the public roads are not as smooth or well kept. They also offer less grip because of the lack of soft-tyre rubber laid down from racing cars, though this only affects the first few laps of the race. The roads are closed only within a few hours of the practice sessions and the race before being opened again almost as soon as the race is finished. Workers have to assemble and dismantle safety barriers every year for the public sections.  \\nHistory[edit]  \\nFor a list of individual race reports, see Category:24 Hours of Le Mans races.  \\n1923–1939[edit]  \\nThe 24 Hours of Le Mans was first run on 26 and 27 May 1923, through public roads around Le Mans. Originally planned to be a three-year event awarded the Rudge-Whitworth Triennial Cup, with a winner being declared by the car which could go the farthest distance over three consecutive 24-hour races, this idea was abandoned in 1928. Overall winners were declared for every year depending on who covered the farthest distance by the time 24 hours were up. The early races were dominated by French, British, and Italian drivers, teams, and cars, with Bugatti, Bentley, and Alfa Romeo being the top brands. Innovations in car design began appearing at the track in the late 1930s, with Bugatti and Alfa Romeo running highly aerodynamic bodywork to run down the Mulsanne Straight at faster speeds. The race was cancelled in 1936 due to general strikes in France, and the outbreak of World War II in 1939 resulted in a ten-year hiatus.  \\n1949–1969[edit]  \\nFollowing the reconstruction of circuit facilities, the race was resumed in 1949[40] with renewed interest from major automobile manufacturers. 1949 was also Ferrari\\'s first victory, the 166MM of Luigi Chinetti and Peter Mitchell-Thomson.[40] After the formation of the World Sportscar Championship in 1953, of which Le Mans was a part, Ferrari, Aston Martin, Mercedes-Benz, Jaguar and many others began sending multiple cars backed by their respective factories to compete for overall wins against their competitors. This competitiveness sometimes resulted in tragedy, as in the 1955 Le Mans disaster during the 1955 race in which Pierre Levegh\\'s car crashed into a crowd of spectators, killing more than 80\\xa0people. The incident led to the widespread introduction of safety measures, not only at the circuit but elsewhere in the motorsport world. The entire pit complex was razed and rebuilt further back following the accident, allowing the pit straight to be widened. However, there was still no barrier between the track and the pit lane. Safety standards improved, but the cars got faster. The move from open-cockpit roadsters to closed-cockpit coupés resulted in speeds of over 320\\xa0km/h (200\\xa0mph) on the Mulsanne. Ford entered the picture with the GT40, finally ending Ferrari\\'s dominance with four straight wins (1966–1969) before the 1960s ended and the cars and the race changed substantially.  \\n1970–1980[edit]  \\nFor the new decade, the race took a turn towards more extreme speeds and automotive designs. These extreme speeds led to the replacement of the typical standing Le Mans start with a rolling Indianapolis start. Although production-based cars still raced, they were now in the lower classes while purpose-built sportscars became the norm. The Porsche 917, 935, and 936 were dominant throughout the decade, but a resurgence by French manufacturers Matra-Simca and Renault saw the first victories for the nation since the 1950 race. This decade is also remembered for strong performances from many privateer constructors, with two scoring the only victories for a privateer in the decade. John Wyer\\'s Mirage won in 1975, while Jean Rondeau\\'s self-titled chassis took 1980.  \\n1981–1993[edit]  \\nThe rest of the 1980s was known for the dominance by Porsche under the new Group C race car formula that encouraged fuel efficiency. Originally running the effective 956, it was later replaced by the 962. Both chassis were affordable enough for privateers to purchase them en masse, leading to the two model types winning six years in a row. Jaguar and Mercedes-Benz returned to sports car racing, with Jaguar being the first to break Porsche\\'s dominance with victories in 1988 and 1990 (with the XJR-9 and Jaguar XJR-12 respectively). Mercedes-Benz won in 1989, with what was seen as the latest incarnation of the elegant \"Silver Arrows\", the Sauber C9, while an influx of Japanese manufacturer interest saw prototypes from Nissan and Toyota. In qualifying for the 1988 race, a WM Peugeot\\xa0– built for speed, not meant to (and it did not) endure 24 hours\\xa0– set the never surpassed speed trap record of 407\\xa0km/h (253\\xa0mph)[a] in the Ligne Droite des Hunaudières, famous for its 6\\xa0km (3.7\\xa0mi) long straight.[41][42] Mazda would be the first Japanese manufacturer to succeed, with their unique rotary-powered 787B winning in 1991.  \\nIn 1992 and 1993, Peugeot dominated the race with its Peugeot 905 as the Group C formula and World Sportscar Championship were fading in participation.  \\nThe circuit would also undergo one of its most notable changes in 1990, when the 5\\xa0km long Mulsanne was modified[40] to include two chicanes in order to stop speeds of more than 400\\xa0km/h (250\\xa0mph) from being reached again. This began the ACO\\'s trend to slow the cars on various portions of the track. However, speeds over 320\\xa0km/h (200\\xa0mph) are still regularly reached at various points on a lap.  \\n1994–1999[edit]  \\nFollowing the demise of the World Sportscar Championship, Le Mans saw a resurgence of production-based grand tourer cars. Thanks to a loophole in the rules, Porsche succeeded in convincing the ACO that a Dauer 962 Le Mans supercar was a production car, allowing Porsche to race their Porsche 962 for one final time, dominating the field. Although the ACO attempted to close the loophole for 1995, newcomer McLaren would win the race in their supercar\\'s first appearance thanks to the reliability of the BMW V12 powered F1 GTR, beating faster yet more trouble-prone prototypes. The trend would continue through the 1990s as more exotic supercars were built in order to skirt the ACO\\'s rules regarding production-based race cars, leading to Porsche, Mercedes-Benz, Toyota, Nissan, Panoz, and Lotus entering the GT categories. This culminated in the 1999 event, in which these GT cars were faced with the Le Mans Prototypes of BMW, Audi, Toyota and Ferrari. BMW would survive with the victory, their first and only overall Le Mans win to date. At the same time, Mercedes left sportscar racing indefinitely following three catastrophic though non-fatal crashes stemming from severe aerodynamic flaws with their CLR.  \\nThis strong manufacturer influence led the ACO to lend the Le Mans name to a sports car series in the United States in 1999, known as the American Le Mans Series, which ran until the end of the 2013 season after which it merged with Grand-Am to form the United SportsCar Championship.  \\n2000–2005[edit]  \\nMany major automobile manufacturers withdrew from sports car racing after 1999 due to the high cost. Only Cadillac and Audi remained, and Audi easily dominated with the R8. Cadillac pulled out three years later, and attempts by Panoz, Chrysler, and MG to beat Audi all fell short. After three victories in a row, Audi provided engine, team staff, and drivers to Bentley, a corporate partner, which had returned in 2001. In 2003, the factory Bentley Speed 8s beat privateer Audis. The Chevrolet Corvette Racing Team and their C5-R won several times in the GTS class, finishing 1st and 2nd in 2001, 2002, and 2004. They finished 2nd and 3rd in 2003 behind Ferrari.  \\n2006–2013[edit]  \\nAt the end of 2005, after five overall victories for the R8, and six to its V8 turbo engine, Audi took on a new challenge by introducing a diesel engined prototype known as the R10 TDI. Although not the first diesel to race, it was the first to win at Le Mans. This era saw other alternative fuel sources used, including bio-ethanol. At the same time, Peugeot decided to follow Audi\\'s lead and pursue a diesel entry in 2007 with their 908 HDi FAP.  \\nIn the 2008 race between the Audi R10 TDI and the Peugeot 908 HDi FAP, the Audi won by a margin of fewer than 10 minutes. For the 2009 24 Hours of Le Mans, Peugeot introduced a new energy-recovery system similar to the KERS used in Formula One.[43] Aston Martin entered the LMP1 category, but still raced in GT1 with private teams. Audi returned with the new R15 TDI, but Peugeot prevailed in its first overall win since 1993.  \\nThe 2010 running reaffirmed the race as a test of endurance and reliability. Peugeot chose overall speed in adjusting their cars and engines to adhere to the 2010 regulations, while Audi chose reliability. All four Peugeots had retired at the end of the race, three due to engine failure, while Audi finished 1–2–3.  \\nThe 2011 and 2012 races were marred by a series of accidents. In 2011, the Audi driven by Allan McNish crashed heavily in the first hour, barrel rolling into a tire wall shortly after the Dunlop Bridge. At night, the defending race-winning Audi driven by Mike Rockenfeller crashed similarly between the Mulsanne and Indianapolis corners. Neither driver was injured, nor were any spectators. The third Audi entry was driven by Marcel Fässler, André Lotterer, and Benoît Tréluyer won the race. The 2012 race saw two factory Toyotas replace Peugeot, which had withdrawn earlier, but one flipped at Mulsanne Corner. Driver Anthony Davidson suffered two broken vertebrae but could exit the car himself. Shortly after sunset, the other Toyota retired with mechanical difficulties, giving Audi another victory.  \\nIn 2011, the race became the premier round of the Intercontinental Le Mans Cup, attempting to make a world championship for endurance racing again. In 2012, the race became the centerpiece of the FIA World Endurance Championship, the successor to the ILMC. The 2012 event was the first time the race was won by a hybrid electric vehicle, which was the Audi R18 e-tron quattro.  \\n2014–2020[edit]  \\nRegulations were changed for 2014, notably with a requirement that all LMP1 cars must be closed-cockpit, some changes to the hybrid system, and the introduction of the slow zone system.[44]  \\nPorsche returned to Le Mans in 2014 with a new factory LMP1 program, and Nissan returned to run an LMP1 program in 2015. Audi withdrew from racing at the 24 Hours of Le Mans in 2016 and Nissan after only one attempt in 2015.  \\nPorsche won the race in 2015, 2016, and 2017 with its hybrid 919, and remains the most successful manufacturer at Le Mans, with 19 overall victories.  \\nIn 2017, changes were made to the LMP2 regulations on cockpit and chassis, meaning all prototype cars must be closed-cockpit.  \\nIn 2018, Toyota won their first Le Mans with Fernando Alonso, Sébastien Buemi and Kazuki Nakajima driving. Toyota won the race again in 2019, 2020, 2021, and 2022.  \\n2020 also saw the race held behind closed doors for the first time due to the COVID-19 pandemic.  \\n2021–present[edit]  \\n2021 saw the introduction of the Hypercar class, a class which allows for Le Mans Hypercars and from 2023 onwards also LMDh cars to participate. 2021 saw the race once again being postponed, this time to August. For 2021 and 2022, non-hybrid LMP1 cars were allowed to participate as \"grandfathered\" LMP1 cars, although only Alpine would make use of this.[45] Other entries in the hypercar class were Toyota and privateer team Glickenhaus. The new Hypercar regulations allowed manufacturers more freedom with the design, leading to cars such as the wingless Peugeot 9X8 (entering) in 2022 and many other unique designs which will be added. The LMP2 regulations were extended to 2024 with the next generation LMP2 cars, which are also used as chassis for the LMDh cars, is said to be introduced in 2025. 2025 will likely also see the introduction of hydrogen powered prototypes which will race for the overall victory.[46] The former LMGTE class was also replaced by LMGT3 in 2024.  \\nInnovations[edit]  \\nLe Mans has seen many innovations in automotive design to counteract the circuit\\'s difficulties. These have either been dictated by rules or have been attempts by manufacturers to outwit the competition. Some innovations were incorporated into the everyday automobile.  \\nAerodynamics[edit]  \\nOne of the keys to Le Mans is top speed due to the long straights that dominate the circuit. This has meant cars have attempted to achieve the maximum speeds possible instead of relying on downforce for the turns. While early competitors\\' cars were street cars with their bodywork removed to reduce weight, innovators like Bugatti developed cars that saw the beginnings of aerodynamics. Nicknamed tanks due to their similarity to military tanks in World War I, these cars used simple curves to cover all the car\\'s mechanical elements and increase top speed. Once Le Mans returned after World War II, most manufacturers would adopt closed bodies streamlined for better aerodynamics. A notable example of the changes brought about by aerodynamics are the 1950 entries by Briggs Cunningham. Cunningham entered two 1950 Cadillac Coupe de Villes, one nearly stock and the other completely rebodied in a streamlined aluminum shape developed by Grumman Aircraft Engineering Corporation that looked so unusual that it was nicknamed \"Le Monstre\" by the French press. The smoothing of body shapes and fairing-in of various parts of the machine brought about by the continual search for reduction of aerodynamic drag led to a separation from Grand Prix cars, which rarely had large bodywork.  \\nAs the years went on, bodywork became all-enveloping, while at the same time lighter. The larger bodywork with spoilers was able to provide more downforce for the turns without increasing the drag, allowing cars to maintain high speeds. Extended bodywork would usually concentrate on the car\\'s rear, usually being termed long tail. The bodywork also began to cover the cockpit for less drag. However, open cockpits would come and go over the years as rules varied. Aerodynamics reached its peak in 1989 before the Mulsanne Straight was modified. During the 1988 race, the crew of a Peugeot powered WM prototype taped over the engine openings, allowing Roger Dorchy to set a recorded speed of 407\\xa0km/h (253\\xa0mph) down the Mulsanne. However, the car was almost undrivable elsewhere on the circuit. The engine was soon destroyed from a lack of cooling.[citation needed] However, for the 1989 event, the Mercedes-Benz C9 reached 400\\xa0km/h (249\\xa0mph) under qualifying conditions.[47]  \\nEngines[edit]  \\nA wide variety of engines have competed at Le Mans in attempts to achieve greater speed and have better fuel economy and spend less time in the pits. Engine sizes have also varied greatly, with the smallest engines being a mere 569 cc (Simca Cinq) and the largest upwards of 8,000 cc (SRT Viper GTS-R). Supercharging was an early innovation for increasing output, first being raced in 1929, while turbocharging would not appear until 1974.  \\nThe first car to enter without an engine run by pistons would be in 1963, when Rover partnered with British Racing Motors to run a gas turbine with mixed success, repeating in 1965. The American Howmet Corporation would attempt to rerun a turbine in 1968 with even less success. Although the engines offered great power, they were hot and not fuel-efficient.  \\nAnother non-piston engine that would appear would be a Wankel engine, otherwise known as the rotary engine. Run entirely by Mazda since its introduction in 1970, the compact engine would also suffer from fuel economy problems like the turbine had, yet would see the success that the turbine lacked. After many years of development, Mazda finally succeeded in being the only winner of the race not to have a piston-powered engine, taking the 1991 event with the 787B.  \\nAlternative fuel sources would also play a part in more normal engine designs, with the first non-gasoline car appearing in 1949. The Delettrez Special would be powered by a diesel engine. In contrast, a second diesel would appear in the form of the M.A.P. the following year. Although diesel would appear at other times over the race existence, it would not be until 2006 when a prominent manufacturer, Audi, would invest in diesel and finally succeed, with the R10 TDI.  \\nEthanol fuel appeared in 1980 in a modified Porsche 911, leading to a class win. Alternative biological fuel sources returned again in 2004 with Team Nasamax\\'s DM139-Judd.[48] In 2008, biofuels (10% ethanol for petrol engines and biodiesel for diesel engines) were allowed. Audi was the first to use next-generation 10% BTL biodiesel developed by Shell and manufactured from biomass.[49]  \\nBeginning in 2009, new regulations allowed hybrid vehicles with either KERS or TERS (Kinetic/Thermal Energy Recovery System) setups. However, only electrical (i.e., batteries) energy storage was allowed, ruling out flywheel-based energy recovery.[50] Cars with KERS were allowed to race in 2009 under specific classification rules. Since 2010, they have competed for points and the championship. In 2012 the first KERS-equipped car won; the Audi R18 e-tron with a flywheel hybrid system by Williams Hybrid Power activated and drove the front wheels. This was only allowed in certain zones after the car had accelerated to at least 120\\xa0km/h to cancel out the acceleration advantage that all-wheel-drive cars could gain out of corners. In the same year, Toyota also started with a hybrid car, the TS030, which used KERS to power its rear wheels, meaning its usage was not restricted.  \\nIn 2025, the Automobile Club de l’Ouest is planning to introduce a hydrogen-electric prototype class. This class will be a one-design class with a chassis provided by Red Bull Advanced Technologies-Oreca and a powertrain supplied by GreenGT. The development of the hydrogen fuel cells powering the cars will be left to the teams themselves. According to the ACO\\'s president Pierre Fillon, there is also a possibility of the cars being powered by a hydrogen combustion engine. The performance of the class is expected to be competitive with the top Hypercar class.[51]  \\nBrakes[edit]  \\nWith increased speeds around the track, brakes become a key issue for teams attempting to safely bring their cars down to a slow enough speed to make the Mulsanne Corner turn. Disc brakes were first seen in 1953 when the Jaguar C-Type raced at Le Mans. In 1955 the Mercedes-Benz 300 SLR introduced the air brake using a large opening hood on the rear of the car. Ford used a quick change brake rotor in 1966 to achieve their first victory at Le Mans.[52]  \\nIn the 1980s, anti-lock braking systems became standard on most Group C cars as a safety measure, making it less likely that cars lose control at high speeds. By the late 1990s, reinforced carbon-carbon brakes were adopted for better stopping power.  \\nWinners[edit]  \\nFor a list of winning drivers, teams, and cars, see List of 24 Hours of Le Mans winners.  \\nOver the years, many manufacturers have managed to take the overall win, while even more have taken class wins. The most successful marque in the history of the race is Porsche, which has taken nineteen overall victories, including seven in a row from 1981 to 1987 and 107 class victories. Audi is next with thirteen wins,[53][54] and Ferrari follows with eleven, also including six in a row from 1960 to 1965. Since 2000 Audi has dominated the event, winning 13 times in 15 years of participation.[55] Audi and Team Joest have had two hat-tricks, the first being in 2000, 2001, and 2002. Jaguar has seven wins. In contrast, Bentley, Alfa Romeo, and Ford all won four races in a row, with Bentley recording two additional victories in other years. In 2018, Toyota became only the second Japanese marque to win, following Mazda in 1991. Mazda is also the only company to win with a rotary engine. After Porsche\\'s total of 107 class victories, Ferrari has 37, and Aston Martin, Audi, and Chevrolet each have 14.  \\nThree drivers stand apart for their number of victories. Initially, Jacky Ickx held the record at six, scoring victories between 1969 and 1982, earning him honorary citizenship to the town of Le Mans. His frequent racing partner, Derek Bell, trailing by a single win, with five. However, Dane Tom Kristensen has beaten this record with nine wins between 1997 and 2013, including six in a row. Three-time winner Woolf Barnato (1928 to 1930), Luis Fontés (1935), American racing legend A. J. Foyt (1967), Nico Hülkenberg (2015), and Fernando Alonso (2018–2019) are the only drivers to have won every Le Mans in which they participated.  \\nHenri Pescarolo won the race four times, and holds the record for the most Le Mans appearances at 33. Japan\\'s Yojiro Terada was active as a driver until 2008, and holds the record for the most Le Mans starts without an overall win. Claude Ballot-Léna holds the most class victories other than Kristensen with seven wins in GT class cars between 1970 and 1986. Graham Hill is the only driver to win the so-called Triple Crown of Motorsport, winning the Indianapolis 500 (1966), Monaco Grand Prix (1963, 1964, 1965, 1968, 1969), and the 24 Hours of Le Mans (1972).[56][57]  \\nAccidents[edit]  \\nSee also: List of 24 Hours of Le Mans fatal accidents  \\nLe Mans has seen many fatal accidents due partly to the very high-speed nature of all variants of the track throughout history. The largest one was in 1955 when 83 spectators and driver Pierre Levegh were killed. In the wake of the disaster, many races were cancelled, including the Grand Prix races in Germany, Spain, and Switzerland (the latter as a part of a blanket ban on motorsport round-track races that was maintained until 2018).[58] The accident led to safety regulations in all motorsports for both driver and spectator protection.  \\nAlmost all decades in which Le Mans has been run have seen their fair share of horrific accidents, such as in 1972 when Swede Jo Bonnier was catapulted into a forest surrounding the circuit after hitting a privately entered Ferrari near the Indianapolis section; Bonnier was killed instantly. The 1980s was a decade where some of the race\\'s worst-ever accidents occurred. Although Armco barriers had been installed along the straight in 1969, there were still no chicanes on the Mulsanne Straight. It was here that almost all of the worst accidents occurred during that time. The prototypes, most of which were equipped with very powerful turbocharged engines in those days, were capable of doing more than 390–400\\xa0km/h (240–250\\xa0mph) before reaching the kink and would still be doing the same kind of speeds at the end of the 5.8-kilometre (3.6\\xa0mi) straight—and even through the kink, which was a flat-out bend for all the cars on the track. In 1981, Belgian Thierry Boutsen crashed horrifically on the Mulsanne Straight in his WM-Peugeot, killing a marshal. In the same race, Frenchman Jean-Louis Lafosse was also killed on the Mulsanne Straight when his Rondeau suffered a suspension failure, steered very suddenly to the right, and slammed into the Armco barrier on the driver\\'s side at extreme speeds. The 1984 race saw British privateer John Sheldon crashing at more than 320\\xa0km/h (200\\xa0mph) at the Mulsanne Kink; his Aston Martin V8 powered Nimrod tore through the Armco barriers into the trees. The resulting explosion was so violent that the woods next to the track caught fire. Although Sheldon survived with severe burns, a track marshal was killed; two others were also severely injured. Sheldon\\'s teammate, American Drake Olson in the second Nimrod-Aston Martin, who was following him down the straight, crashed heavily after running over Sheldon\\'s bodywork; he went into severe shock but survived with minor injuries. The field was under the safety car for over an hour while the crash site was cleared, and the destroyed Armco barriers were replaced.  \\nIn 1985, a similar accident befell Briton Dudley Wood in a Porsche 962 during practice. The impact of the car against the Armco, considering Wood was doing more than 370\\xa0km/h (230\\xa0mph), was so hard that it cracked the engine block. Wood survived without injury. Also, in 1985, John Nielsen flipped his Sauber-Mercedes while going over the Mulsanne hump at more than 350\\xa0km/h (220\\xa0mph). The car landed on its roof and was destroyed, but Nielsen escaped without injury. In 1986, Jo Gartner drove a Porsche 962C into the Mulsanne barriers and was killed instantly after the car rolled multiple times, vaulted some Armco barriers, and knocked down a telegraph pole. Moreover, in 1987, American Price Cobb crashed a works Porsche 962C after slipping on oil during Wednesday practice. The fuel tank exploded and the car burned to the ground, but Cobb escaped without injury.  \\nGartner\\'s fatal accident remained the most recent death in the race until Allan Simonsen\\'s crash in 2013. However, there was one fatality during a practice session in 1997 (Sebastien Enjolras).[59]  \\nIn 1999, the Mercedes-Benz CLRs suffered from aerodynamic instability leading to cars getting airborne and flipping backwards, no less than three times. After initially happening on Thursday to the #4 car, Mercedes rebuild the chassis on Friday and claimed to have solved the problem, only for it to occur again at warmup on Saturday. Mark Webber was the unlucky driver whose car flipped on both occasions. The last and most damaging accident occurred during the race itself when Peter Dumbreck\\'s CLR #5 became airborne, flying over the safety fencing and landing in the woods several metres away. No drivers were severely hurt in any of the three accidents. However, Mercedes-Benz withdrew its remaining entry and ended its entire sportscar programme to focus on F1 and the upcoming new DTM.  \\nIn 2011, two horrific accidents occurred to two of the three factory Audis in the LMP1 class. Near the end of the first hour, the No. 3 car driven by Allan McNish collided with one of the Ferrari GT cars, resulting in McNish\\'s car smashing into the tyre wall and being thrown into the air at the Dunlop chicanes, resulting in pieces of bodywork flying over and nearly hitting many photographers on the other side of the barrier. In the eleventh hour of the race, another accident occurred to the No. 1 car driven by Mike Rockenfeller when he had contact with another Ferrari GT car. In the runup to Indianapolis corner, Rockenfeller\\'s Audi was sent into the outside barrier at over 270\\xa0km/h (170\\xa0mph). Only the main cockpit safety cell of the car remained, along with major damage being done to the barriers that needed to be repaired before the race was resumed. Audi had switched to a closed-cockpit car starting in 2011, a decision credited for the fact that neither driver was injured. The 2014 regulations required all cars to be closed-cockpit due to the 2011 accident.  \\nIn 2012, Anthony Davidson, driving for the returning Toyota team in a Toyota TS030 Hybrid, collided with a Ferrari 458 GT2 of Piergiuseppe Perazzini, and became airborne before crashing into the tyre barrier of the Mulsanne Corner at high speed. The Ferrari also ended up in the barrier, flipping and coming to a halt on its roof. Davidson suffered broken vertebrae.[60][61]  \\nIn 2013, Dane Allan Simonsen died after crashing into the barriers at Tertre Rouge.[62] When the car collided with the guard rail, a mature tree had been touching the barrier, thereby preventing the guard rail from performing its safety function.[63]  \\nCoverage[edit]  \\nMotors TV covered the Le Mans 24 Hours in its entirety in 2006 and 2007, including coverage of the scrutineering, qualifying, driver parade, warmup, and race. In the United States, FOX owned SPEED Channel, followed by Fox Sports 1 and Fox Sports 2 aired complete race coverage live either on-air or online through a combination of coverage from the French host broadcaster and its own pit reporting crew for several years. That deal ended after the 2017 season. A United States television deal was not done for the 2018–19 WEC Super Season because of a renegotiation of its European contract.  \\nIn 2008, Eurosport secured a multi-year deal to show the entire race, including the qualifying and the motorcycle race. Every hour of the 2008 race was broadcast in segments on the main channel and Eurosport 2. However, a couple of hours were missed in recent years due to scheduling clashes with other sporting events.[64][non-primary source needed] In addition, Eurosport provided live streaming on its website to subscribers. Since 2009, Eurosport and Eurosport 2 have covered all the action, and beginning in 2018, Eurosport gained United States broadcast rights for the World Endurance Championship for the race only on Motor Trend, a channel also owned by Eurosport\\'s parent company. Qualifying and practices aired on a direct-to-consumer streaming platform from Motor Trend magazine. In Australia in 2012, Ten Sport showed the race live and in full online.[65]  \\nThe race is also broadcast (in English) on the radio by Radio Le Mans.  \\nVintage racing[edit]  \\nMain article: Le Mans Legend  \\nSince 2001, the ACO has allowed the \"Le Mans Legend\" event to participate on the full Circuit de la Sarthe. These exhibition races involve classic cars that had previously run at Le Mans or are similar to those. Each year, a particular era of cars may participate, with the featured era changing from year to year. Though most drivers in this event are amateurs, some noted professional drivers have appeared to race cars they had previously run, such as Stirling Moss and Derek Bell.  \\nMain article: Le Mans Classic  \\nStarting in 2002, the \"Le Mans Classic\" has been held as a biennial event on the full 13\\xa0km (8.1\\xa0mi) circuit in July. The races take place over a full 24-hour day/night cycle, with starts on set times allowing cars from the same era to compete simultaneously. A team typically consists of a car in each class. The team with the most points accumulated over five or six classes is declared the overall winner. The classes are based on the era in which the cars would have competed. The exact class requirements are re-evaluated for every event since the age for the youngest entries is shifted by two years for each event. In the first event, five classes ran more short races; later events have featured six classes running fewer but longer races. Drivers are required to have an FIA International Competition license. This event also includes a large Concours d\\'Elegance and auction.  \\nSee also[edit]  \\n24 Hours of Le Mans (motorcycle race) Petit Le Mans 24 Hours of LeMons Le Mans 24 Hours video games List of 24 Hours of Le Mans winners List of 24 Hours of Le Mans records Triple Crown of Motorsport Radio Le Mans Musée des 24 Heures du Mans FIA World Endurance Championship European Le Mans Series Asian Le Mans Series  \\nNotes[edit]  \\n^ Peugeot later restated this as 405 km/h, for marketing purposes, when it released an unrelated car branded the 405[41]  \\nReferences[edit]  \\n^ \"Weekly auto agenda: Le Mans\". The Independent. 11 June 2010. Archived from the original on 6 February 2011. Retrieved 22 April 2011. ^ a b Walker, Kate (14 June 2018). \"Fernando Alonso Takes Another Shot at a Motorsport Triple Crown\". The New York Times. Archived from the original on 27 September 2019. Retrieved 5 November 2018. ^ \"Top 10 most prestigious races in the world\". us.motorsport.com. 20 May 2014. Archived from the original on 6 November 2018. Retrieved 12 June 2023. ^ Hargreaves, Eilidh (14 June 2019). \"An insider\\'s guide to the Le Mans 24 hours: how to experience the ultimate endurance race in style\". The Daily Telegraph. Archived from the original on 11 January 2022. ^ \"FIA WEC 86th 24 Heures du Mans Race – Provisional Classification\" (PDF). Automobile Club de l\\'Ouest. 17 June 2018. Archived from the original (PDF) on 16 July 2018. Retrieved 8 July 2018. ^ \"Past seasons\". fiawec.com. Archived from the original on 4 April 2019. Retrieved 4 April 2019. ^ \"Calendar\". fiawec.com. Archived from the original on 4 April 2019. Retrieved 4 April 2019. ^ \"Schedule\". lemans.org. Archived from the original on 7 August 2011. Retrieved 22 April 2011. ^ \"Le Mans 24 Hour – Michelin set new records at Le Mans\". Yahoo Sport/Eurosport. 23 June 2010. Archived from the original on 9 November 2012. Retrieved 22 April 2011. ^ \"Two major car families\". lemans.org. Archived from the original on 7 August 2011. Retrieved 22 April 2011. ^ \"LE MANS: Inside The 2014 LMP1 Regulations\". Auto-racing.speedtv.com. 27 November 2012. Archived from the original on 10 July 2013. Retrieved 5 August 2013. ^ a b \"Classes - FIA World Endurance Championship\". www.fiawec.com. Archived from the original on 6 March 2019. Retrieved 24 October 2023. ^ \"Differences between LMP1 and LMP2\". www.fiawec.com. Archived from the original on 20 April 2021. Retrieved 20 April 2021. ^ a b c Walker, Kate (16 June 2017). \"Le Mans Innovation Rolls Out of Garage 56\". The New York Times. Archived from the original on 23 August 2021. Retrieved 13 April 2022. ^ Perkins, Chris (23 April 2021). \"DeltaWing: The Story of the 21st Century\\'s Most Daring Race Car\". Road & Track. Archived from the original on 28 May 2022. Retrieved 11 June 2022. ^ a b \"24 Hours of Le Mans - Garage 56 the spirit of Le Mans\". 24h-lemans.com. Archived from the original on 9 July 2021. Retrieved 11 June 2022. ^ \"GreenGT\\'s experimental hydrogen prototype could race this season\". www.autosport.com. 14 February 2019. Archived from the original on 11 June 2022. Retrieved 11 June 2022. ^ \"One-Two Finish For Audi At Le Mans After Porsche, Toyota Suffer Woes\". Motor Authority. 16 June 2014. Archived from the original on 17 August 2022. Retrieved 11 June 2022. ^ \"Nissan ZEOD RC hits 300km/h on Mulsanne Straight at Le Mans\". Global Nissan Newsroom. 12 June 2014. ^ ten Caat, Marcel (11 June 2015). \"ACO Confirms Garage 56 Entries for 2016, 2017\". Sportscar365. Archived from the original on 14 April 2022. Retrieved 13 April 2022. ^ Dagys, John (23 August 2017). \"Perrinn LMP1 Project Falls Through, Shifts Focus to Garage 56 Entry – Sportscar365\". sportscar365.com. Archived from the original on 26 August 2022. Retrieved 11 June 2022. ^ a b Watkins, Gary (9 February 2018). \"No \\'Garage 56\\' entry at Le Mans in 2018\". Motorsport.com. Motorsport Network. Archived from the original on 26 August 2022. Retrieved 13 April 2022. ^ \"The 2019 24 Hours of Le Mans\\xa0: interview with Pierre Fillon\". 24h-lemans.com. Archived from the original on 26 August 2022. Retrieved 11 June 2022. ^ Goodwin, Graham (14 April 2020). \"Association SRT41 Garage 56 Effort Withdraws From 2020 Le Mans 24 Hours\". DailySportsCar. Archived from the original on 14 April 2022. Retrieved 13 April 2022. ^ Smith, Luke (19 August 2021). \"Two Disabled Drivers Team Up at Le Mans\". The New York Times. ISSN\\xa00362-4331. Archived from the original on 23 August 2021. Retrieved 11 June 2022. ^ \"PROVISIONAL ENTRY LIST 24 HOURS OF LE MANS RACE\" (PDF). ACO - Automobile Club de l\\'Ouest. Archived (PDF) from the original on 3 June 2022. Retrieved 11 June 2022. ^ \"Full specs revealed for NASCAR Garage 56 Camaro that will race 24 Hours of Le Mans\". NBC Sports. 17 February 2023. Archived from the original on 17 May 2023. Retrieved 17 May 2023. ^ \"NASCAR, Hendrick Motorsports announce pursuit of Garage 56 entry at Le Mans\". NASCAR. 17 March 2022. Archived from the original on 26 March 2022. Retrieved 13 April 2022. ^ \"Jimmie Johnson headlines three-driver Garage 56 entry for Le Mans\". NASCAR. 29 January 2023. Archived from the original on 25 March 2023. Retrieved 17 May 2023. ^ Cornilleau, Arnaud (6 April 2023). \"Why is there a NASCAR on the 2023 24 Hours of Le Mans grid?\". 24 Hours of Le Mans. Archived from the original on 19 March 2024. Retrieved 19 March 2024. ^ \"Garage 56 project\\'s Le Mans invite official; team will compete using No. 24\". National Association for Stock Car Auto Racing. 27 February 2023. Archived from the original on 7 June 2023. Retrieved 20 March 2024. ^ \"ACO – Automobile Club de l\\'Ouest\". www.24h-lemans.com. Archived from the original on 9 March 2016. Retrieved 8 June 2018. ^ \"Iron Man Rotation for Macneil and Bleekemolen\". racer.com. Archived from the original on 17 June 2015. Retrieved 8 June 2015. ^ \"An eye on the clock\\xa0: Maximum driving time allowed\". Archived from the original on 16 June 2019. Retrieved 16 June 2019. ^ G. Harding, A Wine Miscellany, p. 82, Clarkson Potter Publishing, New York 2005 ISBN\\xa00-307-34635-8 ^ Young, Eoin (November 2013). \"Dan Gurney\\'s 1967 Champagne Week\" (PDF). Victory Lane: 42–44. Archived (PDF) from the original on 30 March 2015. Retrieved 21 June 2014. ^ \"Spraying the Champagne\". Dan Gurney\\'s All-American Racing. Archived from the original on 11 August 2014. Retrieved 21 June 2014. ^ Fredstar88 (12 June 2011), Final Lap of 24 Hours of Le Mans 2011, archived from the original on 29 October 2021, retrieved 2 July 2016{{citation}}: CS1 maint: numeric names: authors list (link) ^ a b \"Regulation | FIA World Endurance Championship\". www.fiawec.com. Archived from the original on 2 July 2016. Retrieved 2 July 2016. ^ a b c d \"24 key dates for the 24 Hours\". ACO. Archived from the original on 22 April 2012. Retrieved 20 April 2012. ^ a b c d Kristensen, Stefan (2 March 2022). \"What\\'s the Speed Record on the Mulsanne Straight?\". Motorsport Explained. Archived from the original on 26 August 2022. Retrieved 29 July 2022. …Peugeot had a new car coming out called the 405, and they decided it would be cool if the speed record coincided with the name of their new car. ^ \"THE RECORDS TO BE BEATEN\". 24h-lemans.com. Archived from the original on 1 June 2014. Retrieved 11 June 2014. ^ \"908 HY to close Le Mans Series in hybrid style\". AutoBlog. ^ Dagys, John (20 December 2013). \"New Safety Car Procedure, Slow Zones for Le Mans Revealed\". SportsCar365. Archived from the original on 14 July 2014. Retrieved 20 December 2013. ^ Dagys, John (15 October 2021). \"LMP1s Set to Be Grandfathered Through 2022 – Sportscar365\". sportscar365.com. Archived from the original on 4 December 2021. Retrieved 12 June 2022. ^ \"Hydrogen cars to be able to fight for outright Le Mans 24 Hours win\". www.autosport.com. 20 August 2021. Archived from the original on 12 June 2022. Retrieved 12 June 2022. ^ \"Mulsanne\\'s Corner: Maximum Speeds at Le Mans, 1961–1989\". www.mulsannescorner.com. Archived from the original on 21 November 2020. Retrieved 8 June 2018. ^ \"Mulsannescorner.com, \"2004 Nasamax DM139\"\". Archived from the original on 15 September 2008. Retrieved 6 August 2008. ^ \"Audi R10 TDI on next generation Biofuel at Le Mans\". Audi Motorsport. 30 May 2008. Archived from the original on 19 November 2008. Retrieved 6 August 2008. ^ \"Le Mans 2009 – 2001 regulations released\". Racecar engineering. 19 November 2008. Archived from the original on 28 December 2008. Retrieved 11 October 2010. ^ \"\"In 2025, a hydrogen-powered car may well challenge the other prototypes\"\". 24h-lemans.com. Archived from the original on 10 June 2022. Retrieved 15 July 2022. ^ \"The Le Mans Committee – Victory in 1966\". Ford vs. Ferrari. Ford. Archived from the original on 25 March 2020. Retrieved 25 March 2020. ^ \"Audi wins 13th title at Le Mans\". ESPN. Associated Press. 15 June 2014. Archived from the original on 16 June 2014. Retrieved 16 June 2014. ^ Baldwin, Alan (15 June 2014). \"Audi win Le Mans for 13th time\". Reuters. Reuters UK. Archived from the original on 19 August 2016. Retrieved 16 June 2014. ^ \"Audi Wins Le Mans For 13th Time Ahead of Toyota And Porsche\". HuffPost. Huffington Post UK. 15 June 2014. Archived from the original on 23 June 2014. Retrieved 16 June 2014. ^ Dan Knutson (3 June 2003). \"Points Race Stays Tight; Montoya Joins Elite Company With Victory\". Archived from the original on 6 November 2007. Retrieved 3 December 2007. ^ Henri Boulanger. \"Monaco Grand Prix Glitz Draws Rising Stars\". IntakeInfo.com. Archived from the original on 11 December 2007. Retrieved 5 December 2007. ^ Swiss Traffic Law (German) ^ \"Mark Cole\\'s Le Mans 2013\". Dailysportscar.com. 15 July 2013. Retrieved 5 August 2013. ^ \"Davidson sustains broken back following airborne crash at Le Mans\". Autosport. Haymarket Press. 16 June 2012. Archived from the original on 24 June 2012. Retrieved 16 June 2012. ^ \"Anthony Davidson breaks back after Le Mans 24 Hour accident\". BBC Sport. BBC. 17 June 2012. Archived from the original on 19 June 2012. Retrieved 18 June 2012. ^ \"Driver killed during Le Mans 24-Hours\". En.espnf1.com. 22 June 2013. Archived from the original on 26 July 2013. Retrieved 5 August 2013. ^ \"Race Car Driver Deaths: The Medical Causes of Racing Deaths w Examples\". parathyroid.com. 23 June 2013. Archived from the original on 8 October 2013. Retrieved 8 June 2018. ^ \"Eurosport\". Archived from the original on 13 October 2010. Retrieved 11 October 2010. ^ \"TEN to stream Le Mans online\". TV Tonight. Archived from the original on 19 June 2012. Retrieved 15 June 2011.  \\nAdditional references[edit]  \\n\"Le Mans 1965\" in Automobile Historique, no. 48, May 2005 (in French). \"24 heures du Mans 1973\" in Automobile Historique, no. 49, June/July 2005 (in French).  \\nExternal links[edit]  \\nWikimedia Commons has media related to 24 Heures du Mans.  \\nLe Mans official website Racing Sports Cars—historical photos and results Le Mans History—The History of Le Mans 24 Hours race 24h of Le Mans History and database  \\nRaces by year1920s1930s1940s1950s1960s1970s1980s1990s2000s2010s2020sRelated topicsRelated listsIn mediaVideo games  \\nvte  \\n24 Hours of Le Mans  \\nCircuit de la Sarthe  \\nLe Mans Sarthe  \\n1923 1924 1925 1926 1927 1928 1929  \\n1930 1931 1932 1933 1934 1935 1936 1937 1938 1939  \\n1940–1948: not held 1949  \\n1950 1951 1952 1953 1954 1955 1956 1957 1958 1959  \\n1960 1961 1962 1963 1964 1965 1966 1967 1968 1969  \\n1970 1971 1972 1973 1974 1975 1976 1977 1978 1979  \\n1980 1981 1982 1983 1984 1985 1986 1987 1988 1989  \\n1990 1991 1992 1993 1994 1995 1996 1997 1998 1999  \\n2000 2001 2002 2003 2004 2005 2006 2007 2008 2009  \\n2010 2011 2012 2013 2014 2015 2016 2017 2018 2019  \\n2020 2021 2022 2023 2024 2025  \\nAutomobile Club de l\\'Ouest Le Mans Prototype Le Mans Hypercar LMDh LM GTE LMGT3 Triple Crown of Motorsport 24 Hours of Le Mans (motorcycle race) Le Mans Classic Le Mans Legend Le Mans start Dunlop Bridge Mulsanne Straight 1955 Le Mans disaster Radio Le Mans 24 Hours of LeMons 24 Hours of Le Mans Virtual (2020 2022 2023) Le Mans Virtual Series (2022–23)  \\nList of winners List of records List of female participants List of Le Mans Prototypes List of fatal accidents  \\nLe Mans (film) Michel Vaillant (film) 24 heures d\\'amant \"The Race\" (The Goodies) Truth in 24 Truth in 24 II Ford v Ferrari Gran Turismo (film) Le Mans Racing\\xa0[fr] Le Mans 1955 (film) Deadliest Crash: The Le Mans 1955 Disaster  \\nLeMans WEC Le Mans Le Mans 24 Test Drive Le Mans/Le Mans 24 Hours Gran Turismo Race Driver: Grid Forza Project CARS iRacing rFactor 2 Le Mans Ultimate  \\nNine-timeSix-timeFive-timeFour-timeThree-timeTwo-timeOne-time  \\nvte  \\nWinners of the 24 Hours of Le Mans  \\nTom Kristensen  \\nJacky Ickx  \\nDerek Bell Frank Biela Emanuele Pirro  \\nSébastien Buemi Yannick Dalmas Olivier Gendebien Henri Pescarolo  \\nWoolf Barnato Rinaldo Capello Luigi Chinetti Marcel Fässler Brendon Hartley Hurley Haywood Phil Hill Al Holbert André Lotterer Klaus Ludwig Allan McNish Kazuki Nakajima Benoît Tréluyer Marco Werner  \\nFernando Alonso Earl Bamber Timo Bernhard Tim Birkin Ivor Bueb Romain Dumas Ron Flockhart Jean-Pierre Jaussaud Gérard Larrousse JJ Lehto Manuel Reuter André Rossignol Raymond Sommer Hans-Joachim Stuck Gijs van Lennep Jean-Pierre Wimille Alexander Wurz  \\nAïello Alboreto Amon Ara Attwood Baldi Bandini Barilla Barth Benjafield Benoist Bianchi Bloch Blundell Bouchut D. Brabham G. Brabham Brundle Calado Chaboud Clement Cobb Conway Davis de Courcelles Dickens Duff Dumfries Duval Étancelin Fontés Foyt Frère Fuoco Gachot Gené Giovinazzi González Gregory Guichet Gurney Hamilton Hawthorn Hélary Herbert Herrmann G. Hill Hindmarsh Hirakawa Howe Hülkenberg Jani Johansson Jones Kidston Kobayashi Krages Lagache Lammers Lang Léonard Lieb López Marko Martini Mass McLaren Mitchell-Thomson Molina J. Nielsen N. Nielsen Nuvolari Oliver Ortelli Pier Guidi Pironi Riess Rindt Rockenfeller Rodríguez Rolt Rondeau J. Rosier L. Rosier Rubin Salvadori Sanderson Scarfiotti Schuppan Sekiya Shelby Smith Tandy Trémoulet Trintignant Vaccarella Veyron Walker Wallace Warwick Weidler Whitehead B. Whittington D. Whittington Winkelhock  \\nCurrent (2024)Former  \\nvte  \\nFIA World Endurance Championship races (2012–present)  \\nQatar 1812 km 6 Hours of Imola 6 Hours of Spa-Francorchamps 24 Hours of Le Mans 6 Hours of São Paulo Lone Star Le Mans 6 Hours of Fuji 8 Hours of Bahrain  \\n4 Hours of Silverstone 4 Hours of Shanghai 6 Hours of Mexico 6 Hours of Monza 6 Hours of Nürburgring 6 Hours of Portimão 1000 Miles of Sebring 12 Hours of Sebring  \\nList of FIA World Endurance Championship races  \\n24 hours12 hours10 hours9 hours8 hours6 hours4 Hours2 hours1000 miles1000 kmOther  \\nvte  \\nAutomobile endurance races  \\n24 Hours of Le Mans 24 Hours of Daytona Nürburgring 24 Hours Spa 24 Hours Dubai 24 Hour Fuji 24 Hours 24 Hours of Zolder 24 Hours of Portimão 24 Hours of Barcelona - Trofeo Fermí Vélez\\xa0[es] 2CV 24 Hour Race Longest Day of Nelson 24H Silverstone – European Touring Car Edition 24 Hours of Chamonix\\xa0[fr] Willhire 24 Hour Bathurst 24 Hour Tokachi 24 Hours  \\n12 Hours of Kuwait 12 Hours of Sebring Bathurst 12 Hour Gulf 12 Hours Sepang 12 Hours Coppa Florio 12 Hours of Sicily 12 Hours at the Point 12 Hours of Brno 12 Hours of Reims Rothmans 12 hours  \\nPetit Le Mans Qatar 1812 km  \\nKyalami 9 Hours  \\n8 Hours of Bahrain Indianapolis 8 Hour California 8 Hours 1000 Miles of Sebring  \\n6 Hours of Abu Dhabi 6 Hours of Bogotá 6 Hours of Fuji 6 Hours of Imola 6 Hours of Jeddah 6 Hours of Rome 6 Hours of São Paulo 6 Hours of Spa-Francorchamps 6 Hours of Watkins Glen Bathurst 6 Hour 6 Hours of Austin Monterey 6 Hours 6 Hours of Indianapolis (IMSA) 6 Hours of Perth 6 Hours of Atlanta 6 Hours of Donington 6 Hours of Mexico 6 Hours of Monza 6 Hours of Nürburgring 6 Hours of Portimão 6 Hours of Zhuhai Riverside 6 Hours Mid-Ohio 6 Hours Mosport 6 Hours  \\n4 Hours of Abu Dhabi 4 Hours of Barcelona 4 Hours of Dubai 4 Hours of Imola 4 Hours of Le Castellet 4 Hours of Mugello 4 Hours of Portimão 4 Hours of Sepang 4 Hours of Spa-Francorchamps 4 Hours of Aragón 4 Hours of Estoril 4 Hours of Red Bull Ring 4 Hours of Shanghai 4 Hours of Silverstone  \\nTCR European Endurance  \\nMil Milhas Brasil  \\nMille Miglia  \\n1006 km Palanga 1000 km Paul Ricard Bathurst 1000 Baja 1000 Sepang 1000 km Suzuka 1000 km 1000 km Brands Hatch 1000 km Buenos Aires 1000 km Istanbul 1000 km Jarama 1000 km Le Mans (Bugatti) 1000 km Mosport 1000 km Okayama 1000 km Paris Race of a Thousand Years  \\n25 Hours of Spa 25 Hours of Thunderhill Carrera Panamericana Charge of the Headlight Brigade Targa Florio TCR Spa 500 Laps or 23 Hours The 2904  \\nDefunct races are indicated in italics  \\nCurrent championshipsFormer championshipsCurrent racesFIA WEC (2024)ELMS (2024)AsLMS (2023–24)Former racesFIA WECELMSAsLMSILMCCurrent car classesFormer car classes  \\nvte  \\nAutomobile Club de l\\'Ouest  \\nFIA World Endurance Championship European Le Mans Series Asian Le Mans Series Le Mans Cup  \\nWorld Sportscar Championship American Le Mans Series European Le Mans Series (2001) Intercontinental Le Mans Cup Japan Le Mans Challenge  \\nQatar 1812 km 6 Hours of Imola 6 Hours of Spa-Francorchamps 24 Hours of Le Mans 6 Hours of São Paulo Lone Star Le Mans 6 Hours of Fuji 8 Hours of Bahrain  \\n4 Hours of Barcelona 4 Hours of Le Castellet 4 Hours of Imola 4 Hours of Spa-Francorchamps 4 Hours of Mugello 4 Hours of Portimão  \\n4 Hours of Sepang 4 Hours of Dubai 4 Hours of Abu Dhabi  \\n12 Hours of Sebring 1000 Miles of Sebring 6 Hours of Mexico 6 Hours of Monza 6 Hours of Nürburgring 6 Hours of Portimão 4 Hours of Silverstone 4 Hours of Shanghai  \\nPetit Le Mans Mil Milhas Brasil 6 Hours of Donington 1000 km Istanbul 1000 km Jarama 1000 km Monza 1000 km Nürburgring 1000 km Valencia 4 Hours of Algarve 4 Hours of Aragón 4 Hours of Estoril 4 Hours of Red Bull Ring 4 Hours of Silverstone 3 Hours of Hungaroring  \\n1000 km Okayama 4 Hours of Buriram 4 Hours of Fuji 4 Hours of Shanghai 4 Hours of The Bend 4 Hours of Zhuhai 3 Hours of Inje  \\nPetit Le Mans 6 Hours of Imola 6 Hours of Silverstone 6 Hours of Zhuhai 1000 km of Spa-Francorchamps  \\nLMDh Le Mans Hypercar LMGT3 LMP2 LMP3  \\nLe Mans Prototype (list) Le Mans Prototype Challenge LMGT classes  \\nInternationalNational  \\nAuthority control databases  \\nVIAFFAST  \\nGermanyUnited StatesFranceBnF dataCzech Republic  \\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=24_Hours_of_Le_Mans&oldid=1256860368\"  \\nCategories:  \\n24 Hours of Le Mans1923 establishments in FranceSartheRecurring sporting events established in 1923Group CWorld Sportscar Championship racesTourist attractions in SartheEndurance motor racingSport in Le Mans  \\nHidden categories:  \\nPages using gadget WikiMiniAtlasCS1 maint: numeric names: authors listArticles with short descriptionShort description matches WikidataArticles needing additional references from June 2021All articles needing additional referencesUse dmy dates from June 2022Short description is different from WikidataCoordinates on WikidataArticles containing French-language textArticles needing additional references from May 2020All articles with unsourced statementsArticles with unsourced statements from July 2010Articles needing additional references from July 2022Articles with unsourced statements from February 2015All pages needing factual verificationWikipedia articles needing factual verification from July 2021Articles with French-language sources (fr)Commons link from Wikidata  \\nThis page was last edited on 11 November 2024, at 22:47\\xa0(UTC). Text is available under the Creative Commons Attribution-ShareAlike 4.0 License; additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.  \\nPrivacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url=\"https://en.wikipedia.org/wiki/24_Hours_of_Le_Mans\"\n",
    "header_to_split_on=[\n",
    "    (\"h1\",\"Header 1\"),(\"h2\",\"Header 2\"),(\"h3\",\"Header 3\"),(\"h4\",\"Header 4\")\n",
    "]\n",
    "html_splitter=HTMLHeaderTextSplitter(headers_to_split_on)\n",
    "html_header_splits=html_splitter.split_text_from_url(url)\n",
    "html_header_splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'openapi': '3.1.0', 'info': {'title': 'LangSmith', 'version': '0.1.0'}, 'paths': {'/api/v1/sessions/{session_id}': {'get': {'tags': ['tracer-sessions'], 'summary': 'Read Tracer Session', 'description': 'Get a specific session.'}}}}\n",
      "{'paths': {'/api/v1/sessions/{session_id}': {'get': {'operationId': 'read_tracer_session_api_v1_sessions__session_id__get', 'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}}\n",
      "{'paths': {'/api/v1/sessions/{session_id}': {'get': {'parameters': [{'name': 'session_id', 'in': 'path', 'required': True, 'schema': {'type': 'string', 'format': 'uuid', 'title': 'Session Id'}}, {'name': 'include_stats', 'in': 'query', 'required': False, 'schema': {'type': 'boolean', 'default': False, 'title': 'Include Stats'}}, {'name': 'accept', 'in': 'header', 'required': False, 'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Accept'}}]}}}}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "page_content='{\"openapi\": \"3.1.0\", \"info\": {\"title\": \"LangSmith\", \"version\": \"0.1.0\"}, \"paths\": {\"/api/v1/sessions/{session_id}\": {\"get\": {\"tags\": [\"tracer-sessions\"], \"summary\": \"Read Tracer Session\", \"description\": \"Get a specific session.\"}}}}'\n",
      "page_content='{\"paths\": {\"/api/v1/sessions/{session_id}\": {\"get\": {\"operationId\": \"read_tracer_session_api_v1_sessions__session_id__get\", \"security\": [{\"API Key\": []}, {\"Tenant ID\": []}, {\"Bearer Auth\": []}]}}}}'\n",
      "page_content='{\"paths\": {\"/api/v1/sessions/{session_id}\": {\"get\": {\"parameters\": [{\"name\": \"session_id\", \"in\": \"path\", \"required\": true, \"schema\": {\"type\": \"string\", \"format\": \"uuid\", \"title\": \"Session Id\"}}, {\"name\": \"include_stats\", \"in\": \"query\", \"required\": false, \"schema\": {\"type\": \"boolean\", \"default\": false, \"title\": \"Include Stats\"}}, {\"name\": \"accept\", \"in\": \"header\", \"required\": false, \"schema\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Accept\"}}]}}}}'\n"
     ]
    }
   ],
   "source": [
    "# Split json text data using HTMLHeaderTextSplitter\n",
    "import json\n",
    "import requests\n",
    "json_data=requests.get(\"https://api.smith.langchain.com/openapi.json\").json()\n",
    "\n",
    "from langchain_text_splitters import RecursiveJsonSplitter\n",
    "json_splitter=RecursiveJsonSplitter(max_chunk_size=300)\n",
    "json_text=json_splitter.split_json(json_data)\n",
    "\n",
    "for chunk in json_text[:3]:\n",
    "    print(chunk)\n",
    "print(\"-\"*100)\n",
    "# For documents data or text data, etc from json splitters\n",
    "docs=json_splitter.create_documents([json_data])\n",
    "for doc in docs[:3]:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Techniques to convert chunks to vectors using OpenAI, OLLama, Hugging Face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OPENAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing required libraries to load env variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the api key from .env file\n",
    "os.environ[\"OPENAI_EMD_KEY\"]=os.getenv(\"OPENAI_EMD_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x0000023D5DB75070>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x0000023D5DB76C00>, model='text-embedding-3-large', dimensions=1024, deployment='text-embedding-ada-002', openai_api_version=None, openai_api_base=None, openai_api_type=None, openai_proxy=None, embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=None, disallowed_special=None, chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, http_async_client=None, check_embedding_ctx_length=True)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading best embedding model of OpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings=OpenAIEmbeddings(model=\"text-embedding-3-large\",dimensions=1024)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.017282424494624138,\n",
       " 0.06568903475999832,\n",
       " -0.009165221825242043,\n",
       " -0.015364352613687515,\n",
       " 0.010509850457310677,\n",
       " -0.020861508324742317,\n",
       " -0.014612942934036255,\n",
       " 0.03895466774702072,\n",
       " -0.038282353430986404,\n",
       " -0.0013322693994268775,\n",
       " -0.016867171972990036,\n",
       " 0.012546566314995289,\n",
       " -0.023511217907071114,\n",
       " 0.002398826414719224,\n",
       " 0.03045187145471573,\n",
       " -0.00654023140668869,\n",
       " 0.025587480515241623,\n",
       " 0.049197569489479065,\n",
       " -0.03337841480970383,\n",
       " -0.05077948421239853,\n",
       " -0.035276710987091064,\n",
       " -0.004664178472012281,\n",
       " -0.03124282881617546,\n",
       " -0.013733002357184887,\n",
       " 0.012981592677533627,\n",
       " -0.011389791034162045,\n",
       " -0.01171606034040451,\n",
       " 0.03846031799912453,\n",
       " 0.0007668581674806774,\n",
       " 0.028256963938474655,\n",
       " 0.008245733566582203,\n",
       " 0.00039980438305065036,\n",
       " 0.03549422696232796,\n",
       " 0.01853807084262371,\n",
       " 0.03177672624588013,\n",
       " -0.004535648040473461,\n",
       " 0.05793765187263489,\n",
       " 0.005049770697951317,\n",
       " -0.030847350135445595,\n",
       " -0.0020676127169281244,\n",
       " 1.8798762539518066e-05,\n",
       " 0.012457583099603653,\n",
       " -0.019398236647248268,\n",
       " 0.020723091438412666,\n",
       " -0.02724849246442318,\n",
       " -0.07858164608478546,\n",
       " 0.07047432661056519,\n",
       " -0.03175695240497589,\n",
       " -0.010292337276041508,\n",
       " -0.020386934280395508,\n",
       " 0.0215140487998724,\n",
       " -0.012447696179151535,\n",
       " 0.011646851897239685,\n",
       " -0.032963160425424576,\n",
       " -0.008903217501938343,\n",
       " 0.008730195462703705,\n",
       " 0.02752532809972763,\n",
       " -0.053152356296777725,\n",
       " 0.018033836036920547,\n",
       " 0.009061409160494804,\n",
       " 0.007261980324983597,\n",
       " 0.012388374656438828,\n",
       " -0.006950540468096733,\n",
       " -0.01270475797355175,\n",
       " -0.02023863047361374,\n",
       " 0.04061567783355713,\n",
       " 0.001683256821706891,\n",
       " 0.04271171614527702,\n",
       " 0.014998534694314003,\n",
       " 0.06545174866914749,\n",
       " 0.013347410596907139,\n",
       " 0.009610136039555073,\n",
       " -0.0604291670024395,\n",
       " 0.03946878761053085,\n",
       " 0.06331616640090942,\n",
       " -0.003188548143953085,\n",
       " 0.025093132629990578,\n",
       " 0.019744280725717545,\n",
       " -0.027920806780457497,\n",
       " 0.023095963522791862,\n",
       " 0.0531919039785862,\n",
       " -0.02070331759750843,\n",
       " 0.016264067962765694,\n",
       " 0.019319141283631325,\n",
       " 0.0772765651345253,\n",
       " 0.021573370322585106,\n",
       " -0.06078509986400604,\n",
       " -0.08732172846794128,\n",
       " -0.03755071759223938,\n",
       " 0.01816236600279808,\n",
       " -0.06331616640090942,\n",
       " 0.005249981768429279,\n",
       " -0.05698850005865097,\n",
       " -0.06485853344202042,\n",
       " -0.015354465693235397,\n",
       " -0.03242926672101021,\n",
       " -0.005848143249750137,\n",
       " 0.016293728724122047,\n",
       " -0.031025314703583717,\n",
       " 0.047694750130176544,\n",
       " 0.017262650653719902,\n",
       " -0.044491369277238846,\n",
       " -0.0062189046293497086,\n",
       " -0.039132632315158844,\n",
       " -0.02531064674258232,\n",
       " 0.022146815434098244,\n",
       " 0.0004977472126483917,\n",
       " 0.007009862456470728,\n",
       " 0.0016313502565026283,\n",
       " 0.08439518511295319,\n",
       " 0.0017092101043090224,\n",
       " -0.032449040561914444,\n",
       " 0.0012191871646791697,\n",
       " -0.025468837469816208,\n",
       " -0.011528207920491695,\n",
       " -0.011775382794439793,\n",
       " -0.00037694076308980584,\n",
       " 0.008250677026808262,\n",
       " 0.006209017708897591,\n",
       " -0.04828796535730362,\n",
       " -0.008319886401295662,\n",
       " -0.023372799158096313,\n",
       " 0.026615725830197334,\n",
       " -0.0647398829460144,\n",
       " 0.03683885559439659,\n",
       " 0.03260723128914833,\n",
       " 0.011814930476248264,\n",
       " 0.05469472333788872,\n",
       " 0.057383980602025986,\n",
       " -0.018221687525510788,\n",
       " 0.030056392773985863,\n",
       " -0.006169470027089119,\n",
       " -0.013545149937272072,\n",
       " 0.035830382257699966,\n",
       " 0.030807802453637123,\n",
       " 0.002260408829897642,\n",
       " -0.006737970747053623,\n",
       " 0.0758923888206482,\n",
       " 0.08044039458036423,\n",
       " 0.01221040915697813,\n",
       " -0.07581329345703125,\n",
       " -0.057344432920217514,\n",
       " -0.033338867127895355,\n",
       " -0.021059248596429825,\n",
       " -0.008483021520078182,\n",
       " -0.028731537982821465,\n",
       " -0.0049879769794642925,\n",
       " 0.05900544300675392,\n",
       " 0.01901264488697052,\n",
       " -0.04417498782277107,\n",
       " -0.08518614619970322,\n",
       " -0.02776261419057846,\n",
       " -2.699606557143852e-05,\n",
       " -0.01550277043133974,\n",
       " 0.04607328400015831,\n",
       " -0.060864195227622986,\n",
       " 0.03203378617763519,\n",
       " 0.007904632948338985,\n",
       " -0.030155261978507042,\n",
       " 0.021988622844219208,\n",
       " 0.0441354401409626,\n",
       " -0.03391231223940849,\n",
       " -0.00019912977586500347,\n",
       " 9.276759374188259e-05,\n",
       " 0.0336947962641716,\n",
       " 0.04615237936377525,\n",
       " -0.019319141283631325,\n",
       " -0.03735297545790672,\n",
       " -0.055604323744773865,\n",
       " 0.03339818865060806,\n",
       " 0.026853013783693314,\n",
       " 0.00624856585636735,\n",
       " 0.033536605536937714,\n",
       " 0.023234382271766663,\n",
       " -0.04880208894610405,\n",
       " 0.018805019557476044,\n",
       " -0.011023973114788532,\n",
       " -0.03784732520580292,\n",
       " -0.014355882070958614,\n",
       " 0.07514098286628723,\n",
       " -0.015878476202487946,\n",
       " 0.023847375065088272,\n",
       " 0.01929936744272709,\n",
       " 0.026200473308563232,\n",
       " -0.00826056394726038,\n",
       " -0.017420843243598938,\n",
       " 0.05406195670366287,\n",
       " 0.011735835112631321,\n",
       " 0.03632473200559616,\n",
       " -0.04540096968412399,\n",
       " 0.015008421614766121,\n",
       " -0.04045748710632324,\n",
       " 0.0009707769495435059,\n",
       " -0.0019885171204805374,\n",
       " 0.02376827783882618,\n",
       " -0.002578027779236436,\n",
       " -0.023175060749053955,\n",
       " 0.06383028626441956,\n",
       " 0.013189218938350677,\n",
       " 0.011172276921570301,\n",
       " 0.03586992993950844,\n",
       " -0.08415789902210236,\n",
       " -0.010796572081744671,\n",
       " -0.03278519585728645,\n",
       " -0.011567756533622742,\n",
       " 0.0633557140827179,\n",
       " -0.017865756526589394,\n",
       " 0.006436418276280165,\n",
       " -0.008265507407486439,\n",
       " -0.023175060749053955,\n",
       " 0.02639821358025074,\n",
       " -0.09072284400463104,\n",
       " -0.01058894582092762,\n",
       " -0.08787539601325989,\n",
       " 0.012022556737065315,\n",
       " 0.02691233530640602,\n",
       " -0.06299977749586105,\n",
       " 0.06873422116041183,\n",
       " -0.024974489584565163,\n",
       " -0.021672241389751434,\n",
       " -0.0563952811062336,\n",
       " 0.10195444524288177,\n",
       " 0.05121450871229172,\n",
       " -0.03859873488545418,\n",
       " -0.06331616640090942,\n",
       " 0.007667345926165581,\n",
       " -0.008146864362061024,\n",
       " -0.05034445598721504,\n",
       " -0.041762564331293106,\n",
       " 0.012467470951378345,\n",
       " 0.012556453235447407,\n",
       " -0.039508335292339325,\n",
       " 0.07858164608478546,\n",
       " 0.033714570105075836,\n",
       " -0.0021899640560150146,\n",
       " -0.016293728724122047,\n",
       " 0.046666502952575684,\n",
       " -0.04749700799584389,\n",
       " -0.011587530374526978,\n",
       " 0.061615604907274246,\n",
       " -0.017845982685685158,\n",
       " 0.03761003911495209,\n",
       " -0.022482972592115402,\n",
       " -0.04354222118854523,\n",
       " 0.01962563768029213,\n",
       " 0.03322022408246994,\n",
       " -0.005091790109872818,\n",
       " 0.024776749312877655,\n",
       " -0.019595976918935776,\n",
       " 0.021118570119142532,\n",
       " -0.0037965967785567045,\n",
       " -0.017865756526589394,\n",
       " -0.009793044999241829,\n",
       " 0.0015905664768069983,\n",
       " -0.03426824137568474,\n",
       " 0.023985791951417923,\n",
       " 0.0575026236474514,\n",
       " 0.019645411521196365,\n",
       " 0.011528207920491695,\n",
       " -0.048169322311878204,\n",
       " 0.009852366521954536,\n",
       " 0.029067695140838623,\n",
       " -0.007756328675895929,\n",
       " -5.113417864777148e-05,\n",
       " -0.04682469367980957,\n",
       " 0.0023086077999323606,\n",
       " 0.03846031799912453,\n",
       " -0.022838903591036797,\n",
       " -0.03215242922306061,\n",
       " -0.004441721830517054,\n",
       " 0.012556453235447407,\n",
       " 0.06675682961940765,\n",
       " 0.0018043721793219447,\n",
       " 0.045005492866039276,\n",
       " 0.01449429988861084,\n",
       " 0.009278922341763973,\n",
       " -0.04488684982061386,\n",
       " -0.042988549917936325,\n",
       " 0.050660841166973114,\n",
       " -0.04583599790930748,\n",
       " -0.011231599375605583,\n",
       " -0.030333226546645164,\n",
       " 0.0020700846798717976,\n",
       " 0.017401069402694702,\n",
       " 0.000587965827435255,\n",
       " -0.006159583106637001,\n",
       " -0.014612942934036255,\n",
       " 0.001293957349844277,\n",
       " -0.04409589245915413,\n",
       " -0.027782388031482697,\n",
       " -0.03278519585728645,\n",
       " 0.01308046281337738,\n",
       " 0.008473134599626064,\n",
       " 0.016619998961687088,\n",
       " -0.05354783684015274,\n",
       " 0.01633327640593052,\n",
       " 0.02258184179663658,\n",
       " -0.04192075878381729,\n",
       " 0.0371750108897686,\n",
       " -0.00516594247892499,\n",
       " -0.022522520273923874,\n",
       " 0.006490796338766813,\n",
       " -0.06493762880563736,\n",
       " -0.01388130709528923,\n",
       " -0.005403229501098394,\n",
       " -0.004743274301290512,\n",
       " 0.016293728724122047,\n",
       " 0.016619998961687088,\n",
       " 0.00532907759770751,\n",
       " 0.015868589282035828,\n",
       " -0.00268925609998405,\n",
       " -0.023966018110513687,\n",
       " -0.018290895968675613,\n",
       " -0.01759880781173706,\n",
       " -0.029957521706819534,\n",
       " 0.009901801124215126,\n",
       " 0.003564252983778715,\n",
       " 0.005497155711054802,\n",
       " -0.011370016261935234,\n",
       " -0.0010474009905010462,\n",
       " 0.06268339604139328,\n",
       " -0.030985767021775246,\n",
       " -0.06802236288785934,\n",
       " 0.06256475299596786,\n",
       " -0.053389642387628555,\n",
       " -0.008908160962164402,\n",
       " -0.0036903119180351496,\n",
       " -0.0019415538990870118,\n",
       " 0.016966043040156364,\n",
       " -0.04417498782277107,\n",
       " -0.010069879703223705,\n",
       " -0.013653906993567944,\n",
       " -0.042039401829242706,\n",
       " -0.026655273512005806,\n",
       " 0.023511217907071114,\n",
       " -0.012744305655360222,\n",
       " -0.03952810913324356,\n",
       " -0.06173424795269966,\n",
       " 0.005309303291141987,\n",
       " -0.02677391842007637,\n",
       " 0.0046493480913341045,\n",
       " -0.047180626541376114,\n",
       " 0.012922271154820919,\n",
       " -0.06165515258908272,\n",
       " 0.011567756533622742,\n",
       " -0.019408123567700386,\n",
       " 0.09491492062807083,\n",
       " 0.036739982664585114,\n",
       " -0.013752777129411697,\n",
       " -0.0007989908335730433,\n",
       " 0.001256881165318191,\n",
       " -0.021138343960046768,\n",
       " 0.02179088443517685,\n",
       " -0.020169420167803764,\n",
       " -0.0019242517882958055,\n",
       " -0.03604789823293686,\n",
       " -0.06169470027089119,\n",
       " 0.010242901742458344,\n",
       " -0.022324780002236366,\n",
       " 0.028177866712212563,\n",
       " -0.05477381870150566,\n",
       " -0.012912384234368801,\n",
       " -0.0009639796917326748,\n",
       " 0.03310157731175423,\n",
       " -0.014514073729515076,\n",
       " -0.054378341883420944,\n",
       " 0.05255913734436035,\n",
       " -0.0060261087492108345,\n",
       " 0.07094890624284744,\n",
       " 0.028593121096491814,\n",
       " 0.01801406219601631,\n",
       " 0.03942923992872238,\n",
       " 0.0062683396972715855,\n",
       " 0.024816296994686127,\n",
       " -0.04824841767549515,\n",
       " -0.056118447333574295,\n",
       " 0.03025413118302822,\n",
       " 0.0016214632196351886,\n",
       " 0.02414398267865181,\n",
       " 0.025725899264216423,\n",
       " -0.03863828256726265,\n",
       " -0.016056440770626068,\n",
       " -0.005146168638020754,\n",
       " 0.026892561465501785,\n",
       " 0.019022531807422638,\n",
       " 0.009466774761676788,\n",
       " 0.042513974010944366,\n",
       " -0.01063838042318821,\n",
       " -0.00955081358551979,\n",
       " 0.017668018117547035,\n",
       " 0.02202817238867283,\n",
       " -0.06379073858261108,\n",
       " -0.02503381110727787,\n",
       " -0.0540224090218544,\n",
       " -0.0008873556507751346,\n",
       " 0.0215140487998724,\n",
       " -0.013475941494107246,\n",
       " -0.01581915281713009,\n",
       " -0.005259868688881397,\n",
       " 0.00567017775028944,\n",
       " -0.027881259098649025,\n",
       " 0.03984449431300163,\n",
       " 0.017401069402694702,\n",
       " 0.01512706559151411,\n",
       " -0.03151966258883476,\n",
       " -0.015878476202487946,\n",
       " -0.022740032523870468,\n",
       " -0.035078972578048706,\n",
       " 0.022225910797715187,\n",
       " 0.052638232707977295,\n",
       " -0.04306764528155327,\n",
       " -0.015314918011426926,\n",
       " 2.1685680621885695e-05,\n",
       " 0.00826056394726038,\n",
       " 0.018429314717650414,\n",
       " 0.020545125007629395,\n",
       " -0.019684959203004837,\n",
       " -0.007647572085261345,\n",
       " -0.021296536549925804,\n",
       " -0.03387276455760002,\n",
       " -0.002050310606136918,\n",
       " 0.0026991430204361677,\n",
       " 0.06347435712814331,\n",
       " -0.0017994287190958858,\n",
       " -0.05817493796348572,\n",
       " -0.0008731431444175541,\n",
       " 0.012240069918334484,\n",
       " 0.055604323744773865,\n",
       " 0.0008768507395870984,\n",
       " -0.0625252053141594,\n",
       " -0.04271171614527702,\n",
       " -0.00837920792400837,\n",
       " 0.04911847040057182,\n",
       " 0.045440517365932465,\n",
       " -0.09784146398305893,\n",
       " -0.019408123567700386,\n",
       " -0.026991430670022964,\n",
       " -0.0009886970510706306,\n",
       " -0.01971461996436119,\n",
       " 0.004053658340126276,\n",
       " 0.0026941995602101088,\n",
       " -0.01026267558336258,\n",
       " 0.0002609233488328755,\n",
       " -0.005947012919932604,\n",
       " -0.0604291670024395,\n",
       " 0.0328642912209034,\n",
       " 0.024875618517398834,\n",
       " -0.03203378617763519,\n",
       " 0.012516905553638935,\n",
       " -0.04401679337024689,\n",
       " -0.0018513352843001485,\n",
       " 0.029799330979585648,\n",
       " -0.11990918219089508,\n",
       " -0.05046309903264046,\n",
       " -0.016442032530903816,\n",
       " -0.04132753983139992,\n",
       " -0.00022122098016552627,\n",
       " 0.011330468580126762,\n",
       " 0.028573347255587578,\n",
       " -0.044451821595430374,\n",
       " -0.018953323364257812,\n",
       " 0.008389094844460487,\n",
       " 0.03039254993200302,\n",
       " 0.047734297811985016,\n",
       " 0.05718624219298363,\n",
       " -0.06430485844612122,\n",
       " -0.006525401026010513,\n",
       " -0.07193759828805923,\n",
       " 0.004938541911542416,\n",
       " -0.003322022268548608,\n",
       " -0.06394892930984497,\n",
       " -0.056593023240566254,\n",
       " 0.05845177173614502,\n",
       " 0.05354783684015274,\n",
       " 0.006718196906149387,\n",
       " 0.04263262078166008,\n",
       " -0.004387343302369118,\n",
       " 0.002367929555475712,\n",
       " -0.049197569489479065,\n",
       " 0.05801674723625183,\n",
       " 0.002830145414918661,\n",
       " 0.022107267752289772,\n",
       " 0.025073358789086342,\n",
       " -0.041999854147434235,\n",
       " -0.010776798240840435,\n",
       " 0.022423651069402695,\n",
       " 0.03124282881617546,\n",
       " 0.02461855858564377,\n",
       " -0.022522520273923874,\n",
       " 0.05354783684015274,\n",
       " -0.011172276921570301,\n",
       " 0.017480164766311646,\n",
       " -0.029542269185185432,\n",
       " -0.07043477892875671,\n",
       " -0.043858602643013,\n",
       " -0.03086712397634983,\n",
       " 0.01033188495784998,\n",
       " -0.018716035410761833,\n",
       " 0.011617191135883331,\n",
       " 0.020920829847455025,\n",
       " 0.027050752192735672,\n",
       " -0.009807875379920006,\n",
       " 0.019329028204083443,\n",
       " -0.015433561988174915,\n",
       " 0.03363547474145889,\n",
       " 0.025053584948182106,\n",
       " -0.013090349733829498,\n",
       " 0.006317774299532175,\n",
       " 0.008418755605816841,\n",
       " 0.043858602643013,\n",
       " -0.011281033977866173,\n",
       " -0.05101677030324936,\n",
       " 0.006629214156419039,\n",
       " -0.007904632948338985,\n",
       " 0.010292337276041508,\n",
       " 0.03339818865060806,\n",
       " 0.014069159515202045,\n",
       " -0.0067033665254712105,\n",
       " 0.04045748710632324,\n",
       " 0.011943461373448372,\n",
       " -0.01026267558336258,\n",
       " -0.020920829847455025,\n",
       " 0.04057613015174866,\n",
       " 0.03561287000775337,\n",
       " -0.012170861475169659,\n",
       " 0.020782412961125374,\n",
       " -0.010401093401014805,\n",
       " -0.016076214611530304,\n",
       " -0.03567219153046608,\n",
       " -0.040378388017416,\n",
       " -0.011538094840943813,\n",
       " -0.009442057460546494,\n",
       " -0.04144618287682533,\n",
       " 0.00917510874569416,\n",
       " -0.010193467140197754,\n",
       " 0.018577618524432182,\n",
       " -0.01848863624036312,\n",
       " 0.012675097212195396,\n",
       " -0.0077316113747656345,\n",
       " -0.02531064674258232,\n",
       " 0.02052535116672516,\n",
       " 0.0019279593834653497,\n",
       " -0.04057613015174866,\n",
       " 0.02475697547197342,\n",
       " 0.008038107305765152,\n",
       " 0.062327466905117035,\n",
       " 0.03610721975564957,\n",
       " -0.03298293426632881,\n",
       " -0.03331909328699112,\n",
       " -0.006599553395062685,\n",
       " 0.00013679551193490624,\n",
       " 0.0031490002293139696,\n",
       " 0.03185582160949707,\n",
       " 0.002244342351332307,\n",
       " 0.0013372128596529365,\n",
       " 0.01575983129441738,\n",
       " -0.011429338715970516,\n",
       " 0.01221040915697813,\n",
       " -0.06386983394622803,\n",
       " 0.010292337276041508,\n",
       " -0.03464394807815552,\n",
       " 0.030570514500141144,\n",
       " -0.054615627974271774,\n",
       " -0.017055025324225426,\n",
       " -8.342132059624419e-05,\n",
       " -0.018567731603980064,\n",
       " -0.037392523139715195,\n",
       " 0.001011560671031475,\n",
       " 0.0176482442766428,\n",
       " -0.0073311892338097095,\n",
       " 0.008690647780895233,\n",
       " -0.027821935713291168,\n",
       " -0.016738642007112503,\n",
       " -0.0010696466779336333,\n",
       " -0.04112980142235756,\n",
       " 0.04215804487466812,\n",
       " 0.030175035819411278,\n",
       " -0.04899982735514641,\n",
       " -0.03407050296664238,\n",
       " -0.011370016261935234,\n",
       " -0.00624856585636735,\n",
       " -0.022186363115906715,\n",
       " -0.04069477319717407,\n",
       " 0.03349705785512924,\n",
       " 0.050423551350831985,\n",
       " 0.01891377568244934,\n",
       " -0.002215917455032468,\n",
       " -0.040378388017416,\n",
       " -0.0379461944103241,\n",
       " 0.0030995653942227364,\n",
       " 0.05872860923409462,\n",
       " 0.02451968751847744,\n",
       " -0.002325909910723567,\n",
       " 0.030056392773985863,\n",
       " -0.023689182475209236,\n",
       " -0.03519761562347412,\n",
       " 0.032310619950294495,\n",
       " 0.011439225636422634,\n",
       " 0.038143932819366455,\n",
       " -0.003087206743657589,\n",
       " -0.027169397100806236,\n",
       " -0.04112980142235756,\n",
       " 0.03735297545790672,\n",
       " -0.014345995150506496,\n",
       " -0.05425969883799553,\n",
       " 0.002102217171341181,\n",
       " 0.02691233530640602,\n",
       " 0.028395380824804306,\n",
       " -0.01134035550057888,\n",
       " -0.004036355763673782,\n",
       " -0.06102238595485687,\n",
       " -0.007281754165887833,\n",
       " 0.05481336638331413,\n",
       " 0.0011771675199270248,\n",
       " 0.014533847570419312,\n",
       " 0.01028245035558939,\n",
       " -0.028672216460108757,\n",
       " 0.02885018102824688,\n",
       " -0.025152454152703285,\n",
       " 0.006134865339845419,\n",
       " 0.03076825477182865,\n",
       " 0.014395429752767086,\n",
       " 0.01096465066075325,\n",
       " -0.01571039669215679,\n",
       " -0.033338867127895355,\n",
       " 0.02268071100115776,\n",
       " 0.0020404236856848,\n",
       " -0.006372152827680111,\n",
       " 0.032172203063964844,\n",
       " 0.0019576202612370253,\n",
       " 0.0026447647251188755,\n",
       " -0.013792324811220169,\n",
       " -0.018033836036920547,\n",
       " 0.016669433563947678,\n",
       " -0.019022531807422638,\n",
       " -0.0018871756037697196,\n",
       " 0.031737178564071655,\n",
       " -0.0002009835880016908,\n",
       " 0.005655347369611263,\n",
       " -0.020643996074795723,\n",
       " 0.03140101954340935,\n",
       " -0.01011437177658081,\n",
       " -0.029858652502298355,\n",
       " 0.10432732105255127,\n",
       " -0.0013829400995746255,\n",
       " -0.017865756526589394,\n",
       " -0.010598832741379738,\n",
       " 0.012546566314995289,\n",
       " 0.04714107885956764,\n",
       " -0.005467494949698448,\n",
       " 0.021573370322585106,\n",
       " 0.019704733043909073,\n",
       " 0.02319483458995819,\n",
       " 0.003826257772743702,\n",
       " 0.0026818409096449614,\n",
       " -0.02851402387022972,\n",
       " 0.029621364548802376,\n",
       " 0.04283035919070244,\n",
       " -0.015473109669983387,\n",
       " -0.0004325549816712737,\n",
       " 0.013545149937272072,\n",
       " 0.004968203138560057,\n",
       " 0.002203558571636677,\n",
       " -0.05509020388126373,\n",
       " 0.04923711717128754,\n",
       " -0.020268291234970093,\n",
       " -0.02677391842007637,\n",
       " -0.04283035919070244,\n",
       " -0.024499913677573204,\n",
       " 0.05422015115618706,\n",
       " 0.010648268274962902,\n",
       " -0.054655175656080246,\n",
       " -0.06268339604139328,\n",
       " -0.0032874178141355515,\n",
       " 0.016303615644574165,\n",
       " -0.006935710087418556,\n",
       " -0.015107291750609875,\n",
       " 0.030807802453637123,\n",
       " 0.031460341066122055,\n",
       " 0.002193671651184559,\n",
       " -0.03590947762131691,\n",
       " -0.007617911323904991,\n",
       " -0.004646876361221075,\n",
       " 0.01145899947732687,\n",
       " -0.003119339467957616,\n",
       " -0.0030328284483402967,\n",
       " 0.004063545260578394,\n",
       " 0.037194784730672836,\n",
       " -0.01613553613424301,\n",
       " -0.00470372661948204,\n",
       " 0.013772550970315933,\n",
       " -0.002390175359323621,\n",
       " 0.022186363115906715,\n",
       " 0.03511852025985718,\n",
       " 0.017055025324225426,\n",
       " 0.016580451279878616,\n",
       " 0.0020676127169281244,\n",
       " 0.034703269600868225,\n",
       " -0.017994286492466927,\n",
       " -0.03844054415822029,\n",
       " -0.05872860923409462,\n",
       " 0.00967440102249384,\n",
       " 0.0023790523409843445,\n",
       " 0.0008922991110011935,\n",
       " 0.0012241306249052286,\n",
       " -0.03448575362563133,\n",
       " 0.011419451795518398,\n",
       " -0.03316090255975723,\n",
       " 0.017579033970832825,\n",
       " 0.02536996826529503,\n",
       " 0.007697007153183222,\n",
       " 0.014810682274401188,\n",
       " 0.008156751282513142,\n",
       " 0.06940653920173645,\n",
       " -0.01512706559151411,\n",
       " 0.0355733223259449,\n",
       " 0.00612992187961936,\n",
       " 0.01774711348116398,\n",
       " 0.003885579528287053,\n",
       " -0.0164321456104517,\n",
       " 0.007608024403452873,\n",
       " 0.07423137873411179,\n",
       " 0.015829041600227356,\n",
       " -0.04136708751320839,\n",
       " -0.011676512658596039,\n",
       " -0.021949075162410736,\n",
       " -0.01731208711862564,\n",
       " -0.0163233894854784,\n",
       " 0.00724714994430542,\n",
       " 0.0015843871515244246,\n",
       " 0.019160950556397438,\n",
       " -0.011745722033083439,\n",
       " 0.0008292697020806372,\n",
       " 0.03205356001853943,\n",
       " 0.006940653547644615,\n",
       " -0.04488684982061386,\n",
       " -0.04781339317560196,\n",
       " -0.010786685161292553,\n",
       " 0.0033516832627356052,\n",
       " -0.03628518432378769,\n",
       " 0.05975685268640518,\n",
       " -0.05232185125350952,\n",
       " -0.017895417287945747,\n",
       " -0.037432070821523666,\n",
       " -0.02121743932366371,\n",
       " -0.04725972190499306,\n",
       " -0.0025483667850494385,\n",
       " -0.03130215033888817,\n",
       " -0.002674425719305873,\n",
       " -0.004125338513404131,\n",
       " 0.05493200942873955,\n",
       " 0.037194784730672836,\n",
       " 0.014553621411323547,\n",
       " -0.01830078288912773,\n",
       " -0.02687278762459755,\n",
       " 0.02066376991569996,\n",
       " 0.040497034788131714,\n",
       " 0.006604496855288744,\n",
       " -0.05105631798505783,\n",
       " 0.037194784730672836,\n",
       " -0.02536996826529503,\n",
       " 0.009254205040633678,\n",
       " -0.024539461359381676,\n",
       " 0.030847350135445595,\n",
       " 0.047180626541376114,\n",
       " -0.0012976649450138211,\n",
       " 0.029344530776143074,\n",
       " -0.027307813987135887,\n",
       " 0.006817066576331854,\n",
       " 0.006337548606097698,\n",
       " 0.05342919006943703,\n",
       " 0.03310157731175423,\n",
       " -0.009056465700268745,\n",
       " 0.06999975442886353,\n",
       " 0.008082598447799683,\n",
       " -0.007148280274122953,\n",
       " -0.00521043362095952,\n",
       " 0.017509825527668,\n",
       " -0.020386934280395508,\n",
       " -0.049197569489479065,\n",
       " -0.02418353036046028,\n",
       " -0.04255352169275284,\n",
       " 0.01962563768029213,\n",
       " 0.01674852892756462,\n",
       " -0.01897309720516205,\n",
       " -0.005220320541411638,\n",
       " 0.03203378617763519,\n",
       " -0.013970290310680866,\n",
       " 0.018656713888049126,\n",
       " 0.03365524858236313,\n",
       " -0.04512413591146469,\n",
       " -0.05849131941795349,\n",
       " 0.030293678864836693,\n",
       " 0.015868589282035828,\n",
       " -0.01512706559151411,\n",
       " -0.01821180060505867,\n",
       " 0.013762664049863815,\n",
       " 0.017391182482242584,\n",
       " 0.02851402387022972,\n",
       " -0.022502746433019638,\n",
       " 0.036739982664585114,\n",
       " -0.025567706674337387,\n",
       " 0.016224520280957222,\n",
       " 0.01411859504878521,\n",
       " -0.055169299244880676,\n",
       " -0.01689683273434639,\n",
       " 0.0009880791185423732,\n",
       " 0.020643996074795723,\n",
       " 0.013871420174837112,\n",
       " 0.01830078288912773,\n",
       " 0.04433317855000496,\n",
       " -0.01694626919925213,\n",
       " -0.010509850457310677,\n",
       " 0.044689107686281204,\n",
       " -0.0009293752955272794,\n",
       " 0.023353025317192078,\n",
       " -0.00462215906009078,\n",
       " 0.0032355112489312887,\n",
       " -0.00300069572404027,\n",
       " -0.02183043211698532,\n",
       " -0.012625661678612232,\n",
       " 0.022285232320427895,\n",
       " -0.04184165969491005,\n",
       " 0.01021324098110199,\n",
       " -0.0068615577183663845,\n",
       " -0.029917974025011063,\n",
       " 0.0328642912209034,\n",
       " 0.02339257299900055,\n",
       " 0.023451894521713257,\n",
       " -0.02503381110727787,\n",
       " 0.009427227079868317,\n",
       " -0.04686424136161804,\n",
       " -0.01028245035558939,\n",
       " 0.022245684638619423,\n",
       " -0.005309303291141987,\n",
       " 0.06272294372320175,\n",
       " 0.019595976918935776,\n",
       " -0.01849852316081524,\n",
       " 0.027327587828040123,\n",
       " -0.0003815752861555666,\n",
       " -0.0046888962388038635,\n",
       " -0.013001366518437862,\n",
       " -0.03476259112358093,\n",
       " 0.003774351207539439,\n",
       " 0.026477308943867683,\n",
       " -0.005773990880697966,\n",
       " 0.0002244651404907927,\n",
       " -0.018033836036920547,\n",
       " 0.003559309523552656,\n",
       " 0.017242876812815666,\n",
       " 0.011429338715970516,\n",
       " 0.02847447618842125,\n",
       " -0.01843920163810253,\n",
       " 0.0002564433088991791,\n",
       " -0.015651075169444084,\n",
       " 0.02220613695681095,\n",
       " 0.04144618287682533,\n",
       " 0.0098325926810503,\n",
       " -0.03887556865811348,\n",
       " 0.052915070205926895,\n",
       " -0.0060656568966805935,\n",
       " -0.05212411284446716,\n",
       " -0.011014086194336414,\n",
       " -0.029581816866993904,\n",
       " 0.004960787948220968,\n",
       " -0.05255913734436035,\n",
       " -0.03246881440281868,\n",
       " -0.06303932517766953,\n",
       " 0.0043601542711257935,\n",
       " -0.03327954560518265,\n",
       " 0.005408172961324453,\n",
       " -0.014879891648888588,\n",
       " 0.019833264872431755,\n",
       " 0.01995190791785717,\n",
       " 0.017302200198173523,\n",
       " 0.021019700914621353,\n",
       " 0.010974537581205368,\n",
       " -0.005675121210515499,\n",
       " -0.04109025001525879,\n",
       " -0.03929082304239273,\n",
       " -0.037570491433143616,\n",
       " 0.0001233554066857323,\n",
       " -0.001366873737424612,\n",
       " 0.03958743065595627,\n",
       " 0.011320581659674644,\n",
       " -0.010559285059571266,\n",
       " 0.024163756519556046,\n",
       " 0.011854478158056736,\n",
       " 0.035039424896240234,\n",
       " -0.005299416370689869,\n",
       " -0.02319483458995819,\n",
       " -0.01938834972679615,\n",
       " 0.0270112045109272,\n",
       " -0.0265959519892931,\n",
       " 0.011271147057414055,\n",
       " 0.010341771878302097,\n",
       " 0.0013199106324464083,\n",
       " 0.016728755086660385,\n",
       " -0.011963235214352608,\n",
       " -0.01906207948923111,\n",
       " 0.0018402124987915158,\n",
       " -0.06568903475999832,\n",
       " -0.03203378617763519,\n",
       " -0.0012791268527507782,\n",
       " 0.027070526033639908,\n",
       " -0.06576813012361526,\n",
       " -0.022463198751211166,\n",
       " 0.013307862915098667,\n",
       " 0.05576251819729805,\n",
       " 0.009867196902632713,\n",
       " -0.0019291952485218644,\n",
       " -0.023847375065088272,\n",
       " 0.055604323744773865,\n",
       " 0.027584649622440338,\n",
       " 0.028691990301012993,\n",
       " -0.02135585807263851,\n",
       " 0.02475697547197342,\n",
       " 0.010242901742458344,\n",
       " 0.09072284400463104,\n",
       " -0.0368981771171093,\n",
       " 0.004478797782212496,\n",
       " 0.06248565763235092,\n",
       " 0.03590947762131691,\n",
       " -0.013377072289586067,\n",
       " -0.009491492062807083,\n",
       " -0.004179717041552067,\n",
       " -0.019872812554240227,\n",
       " -0.01915106363594532,\n",
       " 0.016125649213790894,\n",
       " 0.005680064670741558,\n",
       " -0.03434733673930168,\n",
       " 0.017163781449198723,\n",
       " -0.007677232846617699,\n",
       " 0.025211775675415993,\n",
       " -0.0013359769945964217,\n",
       " -0.01990247331559658,\n",
       " -0.02734736166894436,\n",
       " -0.013011254370212555,\n",
       " -0.02926543354988098,\n",
       " -0.026319116353988647,\n",
       " 0.01232905313372612,\n",
       " 0.026180699467658997,\n",
       " -0.015740057453513145,\n",
       " 0.0009615079616196454,\n",
       " 0.005363681819289923,\n",
       " -0.032172203063964844,\n",
       " 0.03163830563426018,\n",
       " -0.011419451795518398,\n",
       " -0.02697165682911873,\n",
       " -0.014316334389150143,\n",
       " 0.0006451248773373663,\n",
       " -0.004115451592952013,\n",
       " 0.013327636756002903,\n",
       " -0.001541131641715765,\n",
       " -0.04785294085741043,\n",
       " -0.0037718794774264097,\n",
       " -0.046468764543533325,\n",
       " 0.0010770618682727218,\n",
       " -0.00046530558029189706,\n",
       " -0.03096599318087101,\n",
       " -0.002642292995005846,\n",
       " -0.004627102520316839,\n",
       " -0.02188975363969803,\n",
       " 0.01575983129441738,\n",
       " 0.010025388561189175,\n",
       " -0.04567780718207359,\n",
       " -0.017717452719807625,\n",
       " -0.012309279292821884,\n",
       " -0.007355906534940004,\n",
       " -0.020643996074795723,\n",
       " -0.011814930476248264,\n",
       " 0.0352964885532856,\n",
       " 0.03505919873714447,\n",
       " -0.007009862456470728,\n",
       " 0.030886897817254066,\n",
       " -0.01906207948923111,\n",
       " -0.0017351633869111538,\n",
       " -0.007286697626113892,\n",
       " -0.006950540468096733,\n",
       " 0.025211775675415993,\n",
       " 0.0004699401033576578,\n",
       " -0.0012006490724161267,\n",
       " 0.005299416370689869,\n",
       " 0.03802528977394104,\n",
       " -0.0030254132580012083,\n",
       " -0.00662427069619298,\n",
       " 0.0304914191365242,\n",
       " 0.0015201218193396926,\n",
       " -0.03157898411154747,\n",
       " -0.055881161242723465,\n",
       " -0.007850254885852337,\n",
       " -0.025290872901678085,\n",
       " 0.01058894582092762,\n",
       " -0.03124282881617546,\n",
       " -0.011824817396700382,\n",
       " 0.0037644642870873213,\n",
       " 0.0033146070782095194,\n",
       " 0.013475941494107246,\n",
       " -0.032172203063964844,\n",
       " 0.01934880204498768,\n",
       " ...]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing the embedding\n",
    "text=\"I am testing my OpenAIEmbeddings from my API\"\n",
    "query_result=embeddings.embed_query(text)\n",
    "query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "-0.017282424494624138\n"
     ]
    }
   ],
   "source": [
    "print(len(query_result))\n",
    "print(query_result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'speech.txt'}, page_content='Scuderia Ferrari (Italian: [skudeˈriːa ferˈraːri]) currently racing under Scuderia Ferrari HP is the racing division of luxury Italian auto manufacturer Ferrari and the racing team that competes in Formula One racing. The team is also known by the nickname \"The Prancing Horse\" (Italian: il Cavallino Rampante or simply il Cavallino), in reference to their logo. It is the oldest surviving and most successful Formula One team, having competed in every world championship since 1950.')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text Loaders to read contents in txt file\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "text_doc=TextLoader('speech.txt',encoding = 'UTF-8').load()\n",
    "text_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'speech.txt'}, page_content='Scuderia Ferrari (Italian: [skudeˈriːa ferˈraːri]) currently racing under Scuderia Ferrari HP is the racing division of luxury Italian auto manufacturer Ferrari and the racing team that competes in Formula One racing. The team is also known by the nickname \"The Prancing Horse\" (Italian: il Cavallino Rampante or simply il Cavallino), in reference to their logo. It is the oldest surviving and most successful Formula One team, having competed in every world championship since 1950.')]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split text by characters using RecursiveCharacterTextSplitter\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=700,chunk_overlap=50)\n",
    "final_text_docs=text_splitter.split_documents(text_doc)\n",
    "final_text_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing the Embeddings Vectors in Vector StoreDBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.chroma.Chroma at 0x23d5eb09a30>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector embedding and storing it into Vector storeDB(Chroma)\n",
    "from langchain_community.vectorstores import Chroma\n",
    "db=Chroma.from_documents(final_text_docs,embeddings)\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'speech.txt'}, page_content='Scuderia Ferrari (Italian: [skudeˈriːa ferˈraːri]) currently racing under Scuderia Ferrari HP is the racing division of luxury Italian auto manufacturer Ferrari and the racing team that competes in Formula One racing. The team is also known by the nickname \"The Prancing Horse\" (Italian: il Cavallino Rampante or simply il Cavallino), in reference to their logo. It is the oldest surviving and most successful Formula One team, having competed in every world championship since 1950.'), Document(metadata={'source': 'speech.txt'}, page_content='Scuderia Ferrari (Italian: [skudeˈriːa ferˈraːri]) currently racing under Scuderia Ferrari HP is the racing division of luxury Italian auto manufacturer Ferrari and the racing team that competes in Formula One racing. The team is also known by the nickname \"The Prancing Horse\" (Italian: il Cavallino Rampante or simply il Cavallino), in reference to their logo. It is the oldest surviving and most successful Formula One team, having competed in every world championship since 1950.'), Document(metadata={'source': 'speech.txt'}, page_content='Scuderia Ferrari (Italian: [skudeˈriːa ferˈraːri]) currently racing under Scuderia Ferrari HP is the racing division of luxury Italian auto manufacturer Ferrari and the racing team that competes in Formula One racing. The team is also known by the nickname \"The Prancing Horse\" (Italian: il Cavallino Rampante or simply il Cavallino), in reference to their logo. It is the oldest surviving and most successful Formula One team, having competed in every world championship since 1950.')]\n"
     ]
    }
   ],
   "source": [
    "# To retrieve from chromadb\n",
    "query=\"Italian auto manufacturer Ferrari\"\n",
    "retrieved_res=db.similarity_search(query)\n",
    "print(retrieved_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLLAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "embeddings=(OllamaEmbeddings(model=\"mxbai-embed-large\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6928829550743103,\n",
       " -0.06529523432254791,\n",
       " 0.6625701189041138,\n",
       " 0.009048640727996826,\n",
       " -1.0707876682281494,\n",
       " -0.30808326601982117,\n",
       " 0.3649643659591675,\n",
       " 0.29894670844078064,\n",
       " 0.1590316891670227,\n",
       " 1.0068645477294922,\n",
       " 0.046925753355026245,\n",
       " 0.18990951776504517,\n",
       " 0.0908103883266449,\n",
       " 0.24835142493247986,\n",
       " -0.2849648594856262,\n",
       " -0.2917434573173523,\n",
       " -0.5408878326416016,\n",
       " -0.5953996181488037,\n",
       " -0.3173350393772125,\n",
       " 0.17620515823364258,\n",
       " 0.27307000756263733,\n",
       " 0.2589612901210785,\n",
       " -1.2641451358795166,\n",
       " 0.04168955236673355,\n",
       " -0.5112680196762085,\n",
       " 0.8599085211753845,\n",
       " -0.053098492324352264,\n",
       " 0.24467432498931885,\n",
       " 1.6036608219146729,\n",
       " 1.0155749320983887,\n",
       " 0.2424660325050354,\n",
       " 0.07851175963878632,\n",
       " 0.46443408727645874,\n",
       " -0.4050128757953644,\n",
       " -0.17650337517261505,\n",
       " -0.1626066118478775,\n",
       " 0.9058332443237305,\n",
       " -0.20042863488197327,\n",
       " -0.4880538582801819,\n",
       " -0.7561136484146118,\n",
       " 0.6609728932380676,\n",
       " -0.30094245076179504,\n",
       " 1.0008721351623535,\n",
       " -0.45461252331733704,\n",
       " -1.2260957956314087,\n",
       " -0.4703350365161896,\n",
       " -0.06782424449920654,\n",
       " -0.9876907467842102,\n",
       " -0.20436476171016693,\n",
       " -0.7801885008811951,\n",
       " 0.01277325488626957,\n",
       " -0.25742626190185547,\n",
       " 0.7926899790763855,\n",
       " -0.5462605357170105,\n",
       " -0.6599300503730774,\n",
       " -0.0241874810308218,\n",
       " 0.1459287703037262,\n",
       " -0.10290978848934174,\n",
       " -0.5008261203765869,\n",
       " 0.6504529118537903,\n",
       " 0.5900042653083801,\n",
       " 0.5930038094520569,\n",
       " -0.07561354339122772,\n",
       " -0.5938535928726196,\n",
       " 0.24748986959457397,\n",
       " 0.39156055450439453,\n",
       " -0.28558042645454407,\n",
       " 0.6074264645576477,\n",
       " 0.15804263949394226,\n",
       " 0.22843226790428162,\n",
       " 0.16375622153282166,\n",
       " 0.5237948894500732,\n",
       " -0.14244025945663452,\n",
       " -0.6713329553604126,\n",
       " -0.678502082824707,\n",
       " -0.16423378884792328,\n",
       " -0.07497679442167282,\n",
       " -0.04058883711695671,\n",
       " -0.4979531764984131,\n",
       " 0.515695333480835,\n",
       " 0.342298299074173,\n",
       " 0.1700260043144226,\n",
       " 0.46876898407936096,\n",
       " 0.19220249354839325,\n",
       " -0.5339032411575317,\n",
       " -0.08031594753265381,\n",
       " 0.635128915309906,\n",
       " 0.08925025910139084,\n",
       " -0.6849572658538818,\n",
       " -0.12454241514205933,\n",
       " 0.8903695344924927,\n",
       " 0.6772334575653076,\n",
       " -0.09403163194656372,\n",
       " -0.204971045255661,\n",
       " 0.691667914390564,\n",
       " 0.743285596370697,\n",
       " -0.5997474789619446,\n",
       " -0.567778468132019,\n",
       " 0.26131272315979004,\n",
       " 0.335130512714386,\n",
       " 0.954265832901001,\n",
       " 0.8828777074813843,\n",
       " -0.43600916862487793,\n",
       " 0.7679190039634705,\n",
       " -1.2539823055267334,\n",
       " 0.09292349964380264,\n",
       " 0.26277512311935425,\n",
       " 0.1658509373664856,\n",
       " 0.23680096864700317,\n",
       " -0.11231319606304169,\n",
       " 0.3140532672405243,\n",
       " 0.20847079157829285,\n",
       " -0.03398782014846802,\n",
       " -0.0327879935503006,\n",
       " -0.3478364646434784,\n",
       " 0.19723892211914062,\n",
       " -0.3413926661014557,\n",
       " 0.42385321855545044,\n",
       " -1.0491561889648438,\n",
       " -0.3636355996131897,\n",
       " -0.1778380274772644,\n",
       " 1.2325315475463867,\n",
       " 0.044296327978372574,\n",
       " -0.1941690742969513,\n",
       " 0.5929419994354248,\n",
       " -0.03396247327327728,\n",
       " -0.46796518564224243,\n",
       " 0.5430546402931213,\n",
       " -1.0851271152496338,\n",
       " -0.018037747591733932,\n",
       " -0.4329034686088562,\n",
       " 0.11216498911380768,\n",
       " 0.6837943196296692,\n",
       " 0.7910101413726807,\n",
       " 0.27427276968955994,\n",
       " 0.030950341373682022,\n",
       " 0.28169068694114685,\n",
       " 0.16842734813690186,\n",
       " 0.012360148131847382,\n",
       " -0.4565297067165375,\n",
       " 0.680753767490387,\n",
       " 0.2472740262746811,\n",
       " -0.36427006125450134,\n",
       " 1.5776902437210083,\n",
       " 0.10030399262905121,\n",
       " -0.11988982558250427,\n",
       " -0.3807959258556366,\n",
       " -0.11689561605453491,\n",
       " -0.7752901315689087,\n",
       " 1.0201191902160645,\n",
       " -1.0200753211975098,\n",
       " -0.13619576394557953,\n",
       " -0.4540281593799591,\n",
       " 0.39554867148399353,\n",
       " -0.4499714970588684,\n",
       " -0.11285854876041412,\n",
       " -0.11459659785032272,\n",
       " 0.04149676114320755,\n",
       " 0.07223858684301376,\n",
       " -0.029192376881837845,\n",
       " -0.07975789159536362,\n",
       " -0.41910308599472046,\n",
       " -0.17851127684116364,\n",
       " 0.9032151699066162,\n",
       " -0.7256681323051453,\n",
       " 0.8021360635757446,\n",
       " -0.10268613696098328,\n",
       " -0.4977898597717285,\n",
       " 0.3115226626396179,\n",
       " -0.3080974817276001,\n",
       " 0.2177414894104004,\n",
       " 0.23702484369277954,\n",
       " -0.7719177603721619,\n",
       " -0.008635304868221283,\n",
       " 0.23938703536987305,\n",
       " 0.5109649896621704,\n",
       " -0.376091867685318,\n",
       " -0.8510912656784058,\n",
       " 0.3990112841129303,\n",
       " 0.07795271277427673,\n",
       " -0.40561723709106445,\n",
       " 0.173055961728096,\n",
       " 0.7380349040031433,\n",
       " 0.3216111958026886,\n",
       " 0.3724444806575775,\n",
       " 0.20646408200263977,\n",
       " 0.6096164584159851,\n",
       " -0.5504611730575562,\n",
       " -0.35111021995544434,\n",
       " -0.44569915533065796,\n",
       " -0.23517628014087677,\n",
       " 0.6368837356567383,\n",
       " -0.16774573922157288,\n",
       " 0.11204946786165237,\n",
       " -0.19497032463550568,\n",
       " 0.42944762110710144,\n",
       " -1.1700040102005005,\n",
       " 0.2491387128829956,\n",
       " -0.49791765213012695,\n",
       " -0.8013676404953003,\n",
       " 0.17778660356998444,\n",
       " -0.09607663750648499,\n",
       " -0.25526106357574463,\n",
       " 0.8174792528152466,\n",
       " -0.6239621043205261,\n",
       " -0.3282570242881775,\n",
       " 0.4237368702888489,\n",
       " 0.23782794177532196,\n",
       " -0.6435256004333496,\n",
       " -0.0293230302631855,\n",
       " 0.321888267993927,\n",
       " 0.6710727214813232,\n",
       " -1.2580540180206299,\n",
       " -0.10309338569641113,\n",
       " 0.4159923791885376,\n",
       " 0.20456713438034058,\n",
       " -0.4231882393360138,\n",
       " 1.0908678770065308,\n",
       " 0.56252121925354,\n",
       " 0.6164219975471497,\n",
       " -0.2814285457134247,\n",
       " -0.05341522395610809,\n",
       " 0.17528289556503296,\n",
       " 0.7397996187210083,\n",
       " 0.18969976902008057,\n",
       " -0.8482723236083984,\n",
       " 0.006339815445244312,\n",
       " 1.253334641456604,\n",
       " -0.5337637662887573,\n",
       " -0.19492267072200775,\n",
       " -0.42900970578193665,\n",
       " 0.6954783201217651,\n",
       " -0.2497352957725525,\n",
       " 1.2707569599151611,\n",
       " 0.5305090546607971,\n",
       " 0.11149046570062637,\n",
       " 0.7687221765518188,\n",
       " 0.9034101963043213,\n",
       " 0.09569104015827179,\n",
       " 0.45137977600097656,\n",
       " 0.05437552556395531,\n",
       " 0.5231698751449585,\n",
       " 1.2103111743927002,\n",
       " 0.43734821677207947,\n",
       " -0.3397822082042694,\n",
       " 0.6468088626861572,\n",
       " 0.08713474124670029,\n",
       " -0.4879677891731262,\n",
       " -0.5170198678970337,\n",
       " 0.9241337776184082,\n",
       " 0.5326758623123169,\n",
       " 0.6217066645622253,\n",
       " 0.3179479241371155,\n",
       " -0.025921247899532318,\n",
       " -0.8357537388801575,\n",
       " -0.07351282238960266,\n",
       " 0.047241419553756714,\n",
       " 0.6002267599105835,\n",
       " -0.7235223650932312,\n",
       " -0.8908314108848572,\n",
       " -0.027780607342720032,\n",
       " 0.2528676986694336,\n",
       " -0.1399339884519577,\n",
       " -0.2356162667274475,\n",
       " -0.08587837219238281,\n",
       " 0.5010141134262085,\n",
       " -0.01204895880073309,\n",
       " 0.39374107122421265,\n",
       " 0.024932673200964928,\n",
       " -0.6851661205291748,\n",
       " -0.5881220102310181,\n",
       " -0.6530356407165527,\n",
       " -1.6532049179077148,\n",
       " 0.03790217638015747,\n",
       " -0.6801989674568176,\n",
       " -0.010880982503294945,\n",
       " 1.0312564373016357,\n",
       " -0.9851172566413879,\n",
       " 0.3654058575630188,\n",
       " -0.33100026845932007,\n",
       " -0.4035220444202423,\n",
       " -0.007806563749909401,\n",
       " -0.4626574218273163,\n",
       " 0.8925723433494568,\n",
       " 0.41973763704299927,\n",
       " 0.5274638533592224,\n",
       " -0.33002999424934387,\n",
       " 0.39540526270866394,\n",
       " -0.028544951230287552,\n",
       " 0.9103661179542542,\n",
       " -0.9355774521827698,\n",
       " -0.08943797647953033,\n",
       " -0.25549307465553284,\n",
       " -0.9324826598167419,\n",
       " 0.5734741687774658,\n",
       " -0.5013591647148132,\n",
       " -0.1918104887008667,\n",
       " -0.40823811292648315,\n",
       " -0.9095866680145264,\n",
       " -0.7756189107894897,\n",
       " -0.3953400254249573,\n",
       " 0.13237811625003815,\n",
       " -0.42940554022789,\n",
       " -0.49733203649520874,\n",
       " -0.0785900354385376,\n",
       " 0.9046053290367126,\n",
       " 0.4363870322704315,\n",
       " -0.5861510038375854,\n",
       " 0.09612561762332916,\n",
       " 0.3232564330101013,\n",
       " -1.3952016830444336,\n",
       " 0.8316314816474915,\n",
       " -0.29407545924186707,\n",
       " -0.29420214891433716,\n",
       " -0.6181437373161316,\n",
       " 0.6686819791793823,\n",
       " 0.20712605118751526,\n",
       " 0.3254779279232025,\n",
       " -0.0756111592054367,\n",
       " -0.544449508190155,\n",
       " 0.26399338245391846,\n",
       " -0.3528605103492737,\n",
       " 0.4675556421279907,\n",
       " -0.031072212383151054,\n",
       " -0.17016316950321198,\n",
       " 0.1368306577205658,\n",
       " 0.3973311483860016,\n",
       " -1.137610673904419,\n",
       " 0.549504280090332,\n",
       " -0.13116313517093658,\n",
       " -0.9637028574943542,\n",
       " -0.2607403099536896,\n",
       " -0.3622399568557739,\n",
       " 0.7007115483283997,\n",
       " 0.35038450360298157,\n",
       " -0.06340514123439789,\n",
       " -0.4125869870185852,\n",
       " -0.7160501480102539,\n",
       " 0.03716542571783066,\n",
       " 0.8220567107200623,\n",
       " 0.19867604970932007,\n",
       " -0.4239119291305542,\n",
       " -0.2426455020904541,\n",
       " 0.8089736104011536,\n",
       " -0.047431182116270065,\n",
       " -0.2651195526123047,\n",
       " 0.46170634031295776,\n",
       " -0.32648757100105286,\n",
       " -0.2869998812675476,\n",
       " 0.18233714997768402,\n",
       " -0.17091292142868042,\n",
       " 0.6536192893981934,\n",
       " -0.0021339356899261475,\n",
       " 0.8456662893295288,\n",
       " 0.04270081967115402,\n",
       " 0.8697019219398499,\n",
       " -0.1237807422876358,\n",
       " 0.11565204709768295,\n",
       " 0.7898802161216736,\n",
       " 0.019739411771297455,\n",
       " -0.24778026342391968,\n",
       " 1.0362255573272705,\n",
       " 0.09502727538347244,\n",
       " 0.1224328875541687,\n",
       " -0.06784886121749878,\n",
       " -0.8882842659950256,\n",
       " 0.25423991680145264,\n",
       " 0.05959778279066086,\n",
       " 0.3905565142631531,\n",
       " -0.7154267430305481,\n",
       " 0.9328923225402832,\n",
       " -0.5149588584899902,\n",
       " -0.6423326134681702,\n",
       " 0.11646191775798798,\n",
       " -0.1409451812505722,\n",
       " -0.460191935300827,\n",
       " 1.0846433639526367,\n",
       " 0.3887283205986023,\n",
       " 0.5216883420944214,\n",
       " -0.5864498019218445,\n",
       " -0.1906604915857315,\n",
       " -0.2446567565202713,\n",
       " 0.4122326076030731,\n",
       " 1.3499866724014282,\n",
       " 0.055970676243305206,\n",
       " 0.9385755062103271,\n",
       " 0.08526981621980667,\n",
       " -0.11323318630456924,\n",
       " -0.762502133846283,\n",
       " -0.5494060516357422,\n",
       " -0.2620367109775543,\n",
       " -1.0121324062347412,\n",
       " 0.021961882710456848,\n",
       " 0.02843371406197548,\n",
       " -0.37001606822013855,\n",
       " -0.8370866179466248,\n",
       " 0.5685593485832214,\n",
       " 0.48279517889022827,\n",
       " 0.3895829916000366,\n",
       " -0.22076906263828278,\n",
       " 0.3271675407886505,\n",
       " -0.24442610144615173,\n",
       " -0.1721634566783905,\n",
       " 0.7338504195213318,\n",
       " 0.1903781294822693,\n",
       " 0.4609540104866028,\n",
       " -0.38875970244407654,\n",
       " 0.7196633815765381,\n",
       " -0.07777310162782669,\n",
       " 0.5882090926170349,\n",
       " -0.8462657928466797,\n",
       " 0.6783276200294495,\n",
       " 0.14380651712417603,\n",
       " 0.154899463057518,\n",
       " 0.2817367613315582,\n",
       " -0.692537784576416,\n",
       " -1.486437439918518,\n",
       " 0.46699613332748413,\n",
       " 0.026504945009946823,\n",
       " 0.12860627472400665,\n",
       " -0.6194354891777039,\n",
       " -0.6560589671134949,\n",
       " -0.14870917797088623,\n",
       " 0.7810815572738647,\n",
       " -0.1090787723660469,\n",
       " -0.39837923645973206,\n",
       " 0.8740729093551636,\n",
       " -0.9180505871772766,\n",
       " 0.5137952566146851,\n",
       " 0.7941297292709351,\n",
       " -0.6261817216873169,\n",
       " 0.10077720880508423,\n",
       " -0.3627089560031891,\n",
       " -0.33034148812294006,\n",
       " -0.10139478743076324,\n",
       " 0.32948756217956543,\n",
       " 1.0560846328735352,\n",
       " -0.12718656659126282,\n",
       " 0.9514178037643433,\n",
       " -0.4457857310771942,\n",
       " 0.49794936180114746,\n",
       " 0.6738860011100769,\n",
       " -0.3710571825504303,\n",
       " -0.5125545859336853,\n",
       " -0.0867200642824173,\n",
       " -0.15604686737060547,\n",
       " 0.1504383683204651,\n",
       " 0.15487924218177795,\n",
       " -0.6713876128196716,\n",
       " -0.15871365368366241,\n",
       " 0.5784831047058105,\n",
       " -0.9837976694107056,\n",
       " 0.35268405079841614,\n",
       " -0.5951939821243286,\n",
       " -0.23490683734416962,\n",
       " -1.1191377639770508,\n",
       " -0.3592030704021454,\n",
       " 0.1698189228773117,\n",
       " 0.4174216389656067,\n",
       " -0.4125017821788788,\n",
       " 0.6009918451309204,\n",
       " -0.15192732214927673,\n",
       " 0.5225716233253479,\n",
       " -0.3663552403450012,\n",
       " -1.387790560722351,\n",
       " 0.5051639080047607,\n",
       " 0.21395264565944672,\n",
       " -0.4616175889968872,\n",
       " 0.15925514698028564,\n",
       " 0.15777480602264404,\n",
       " -0.05599004775285721,\n",
       " 0.4460706114768982,\n",
       " -0.12715324759483337,\n",
       " -0.038512539118528366,\n",
       " 0.3110790252685547,\n",
       " -0.05940995365381241,\n",
       " 0.6688319444656372,\n",
       " 0.3603922724723816,\n",
       " -0.1551794856786728,\n",
       " -0.01743382215499878,\n",
       " 0.1304527223110199,\n",
       " 0.13853362202644348,\n",
       " 0.44187331199645996,\n",
       " 0.10113467276096344,\n",
       " -0.8503260612487793,\n",
       " -1.3320318460464478,\n",
       " 0.22993221879005432,\n",
       " -0.8562227487564087,\n",
       " 0.04724840447306633,\n",
       " -0.13068106770515442,\n",
       " 0.12171532213687897,\n",
       " 0.659697413444519,\n",
       " 0.02125852182507515,\n",
       " 0.014212913811206818,\n",
       " -0.186147078871727,\n",
       " -0.4275071918964386,\n",
       " -1.1162307262420654,\n",
       " -1.2036010026931763,\n",
       " -0.04108339548110962,\n",
       " 0.6367707252502441,\n",
       " 0.7135906219482422,\n",
       " -0.16745293140411377,\n",
       " -0.3193378448486328,\n",
       " 0.17030589282512665,\n",
       " -0.09701845794916153,\n",
       " -0.7867746949195862,\n",
       " -0.5713353753089905,\n",
       " -0.396583616733551,\n",
       " 0.4808749556541443,\n",
       " 0.4968833923339844,\n",
       " 0.35245558619499207,\n",
       " 0.30149587988853455,\n",
       " -0.15526972711086273,\n",
       " -0.5087197422981262,\n",
       " 0.5619254112243652,\n",
       " -0.08369842171669006,\n",
       " 0.2979722023010254,\n",
       " -0.08791138976812363,\n",
       " -0.27992501854896545,\n",
       " 0.8676225543022156,\n",
       " 0.655746579170227,\n",
       " -0.6463995575904846,\n",
       " -0.07242223620414734,\n",
       " 0.757957935333252,\n",
       " -0.3485868573188782,\n",
       " 0.5361430048942566,\n",
       " -0.27236950397491455,\n",
       " -1.0438041687011719,\n",
       " -0.2740476131439209,\n",
       " -1.1463587284088135,\n",
       " -0.10928353667259216,\n",
       " -0.6508183479309082,\n",
       " -0.016947761178016663,\n",
       " -0.8057773113250732,\n",
       " -0.3452708125114441,\n",
       " 0.18852849304676056,\n",
       " -0.27610886096954346,\n",
       " 0.3619377017021179,\n",
       " -0.6402956247329712,\n",
       " 0.037994787096977234,\n",
       " -1.0227115154266357,\n",
       " 0.4284322261810303,\n",
       " -0.08417976647615433,\n",
       " 0.44593629240989685,\n",
       " -0.6199295520782471,\n",
       " 0.12500235438346863,\n",
       " -0.16249990463256836,\n",
       " 1.024916648864746,\n",
       " -0.15541639924049377,\n",
       " 0.05003981292247772,\n",
       " 0.10367871820926666,\n",
       " 0.3626921772956848,\n",
       " 0.32579267024993896,\n",
       " 0.8177805542945862,\n",
       " -0.7082575559616089,\n",
       " -0.8029688596725464,\n",
       " 0.1516185700893402,\n",
       " 0.7766737937927246,\n",
       " -0.5615871548652649,\n",
       " 0.39076855778694153,\n",
       " -0.4753434658050537,\n",
       " 0.42555490136146545,\n",
       " -0.38563117384910583,\n",
       " -0.4055590331554413,\n",
       " -0.3119371235370636,\n",
       " -0.5129725933074951,\n",
       " -0.6000078916549683,\n",
       " 0.3545994758605957,\n",
       " 0.9480492472648621,\n",
       " -0.2930458188056946,\n",
       " 0.46988269686698914,\n",
       " -0.3389410972595215,\n",
       " 0.7023411393165588,\n",
       " 1.0370428562164307,\n",
       " 0.39431390166282654,\n",
       " -1.2724676132202148,\n",
       " -0.3438799977302551,\n",
       " -0.5918343663215637,\n",
       " -1.3623653650283813,\n",
       " 0.7269412875175476,\n",
       " -0.21174336969852448,\n",
       " 0.31234219670295715,\n",
       " -0.03683812916278839,\n",
       " -0.6958498954772949,\n",
       " 0.7875607013702393,\n",
       " -0.3877486288547516,\n",
       " 0.3774808347225189,\n",
       " 1.1753971576690674,\n",
       " 0.1800263524055481,\n",
       " 0.15752048790454865,\n",
       " -0.8173618912696838,\n",
       " 0.2593260705471039,\n",
       " 0.41267985105514526,\n",
       " -0.08754164725542068,\n",
       " -0.028688963502645493,\n",
       " -0.2701203227043152,\n",
       " -0.5018000602722168,\n",
       " 0.23575584590435028,\n",
       " -0.48377490043640137,\n",
       " -0.5599057078361511,\n",
       " -0.8098723292350769,\n",
       " 0.4192957580089569,\n",
       " 0.745366096496582,\n",
       " 0.2242535799741745,\n",
       " 0.29286617040634155,\n",
       " -0.44359344244003296,\n",
       " -0.5260453820228577,\n",
       " -0.32436662912368774,\n",
       " 0.8304596543312073,\n",
       " 1.4530471563339233,\n",
       " 0.37136387825012207,\n",
       " 0.5015726685523987,\n",
       " -0.07814400643110275,\n",
       " -0.01929584890604019,\n",
       " 0.14651787281036377,\n",
       " -0.5083601474761963,\n",
       " -0.27754446864128113,\n",
       " -0.4962930679321289,\n",
       " 0.5257676839828491,\n",
       " 0.006565507501363754,\n",
       " -0.4739786386489868,\n",
       " 1.2938077449798584,\n",
       " 0.5469197630882263,\n",
       " -1.4991648197174072,\n",
       " -0.6805517673492432,\n",
       " -0.2158471792936325,\n",
       " -0.07232489436864853,\n",
       " -0.8807375431060791,\n",
       " -0.6762176156044006,\n",
       " -0.11785060912370682,\n",
       " 1.1236311197280884,\n",
       " -0.28390446305274963,\n",
       " 0.07418884336948395,\n",
       " 0.024612776935100555,\n",
       " -0.2599605917930603,\n",
       " -0.10251761972904205,\n",
       " -0.06190231442451477,\n",
       " -0.17834772169589996,\n",
       " -0.45640629529953003,\n",
       " 0.1937793642282486,\n",
       " 0.9126191735267639,\n",
       " -0.14263996481895447,\n",
       " 0.17117442190647125,\n",
       " -0.9630560874938965,\n",
       " -0.010013118386268616,\n",
       " 0.13429507613182068,\n",
       " 0.063853919506073,\n",
       " 0.9404769539833069,\n",
       " -0.03585004061460495,\n",
       " -0.05342353880405426,\n",
       " 0.7330052852630615,\n",
       " 0.2739381194114685,\n",
       " 0.8809753656387329,\n",
       " -0.7671988606452942,\n",
       " 0.3501265347003937,\n",
       " 0.8107833862304688,\n",
       " -0.7173596620559692,\n",
       " -0.4013587236404419,\n",
       " -0.023679230362176895,\n",
       " 0.2659706175327301,\n",
       " 0.13747641444206238,\n",
       " -0.1434250771999359,\n",
       " -0.7308801412582397,\n",
       " 0.10896028578281403,\n",
       " 0.48725464940071106,\n",
       " -0.3146977424621582,\n",
       " -0.4714360237121582,\n",
       " -0.4806664288043976,\n",
       " -0.09734082967042923,\n",
       " -0.6882697939872742,\n",
       " -0.5460475087165833,\n",
       " -0.3095146417617798,\n",
       " -0.1704925000667572,\n",
       " 0.021638259291648865,\n",
       " 0.6683304309844971,\n",
       " -0.04739602282643318,\n",
       " 0.5314345359802246,\n",
       " 0.07298168540000916,\n",
       " 0.7191572189331055,\n",
       " -0.17135372757911682,\n",
       " 0.4550143778324127,\n",
       " -0.5365459322929382,\n",
       " 0.20879217982292175,\n",
       " -0.7466931939125061,\n",
       " -0.0035934150218963623,\n",
       " -0.6739498376846313,\n",
       " -0.5448528528213501,\n",
       " -0.6434068083763123,\n",
       " 0.1940382719039917,\n",
       " -1.0580191612243652,\n",
       " -0.18771974742412567,\n",
       " 0.19311290979385376,\n",
       " 0.559346079826355,\n",
       " 0.20463398098945618,\n",
       " -0.12876877188682556,\n",
       " -0.6207664012908936,\n",
       " -0.39244544506073,\n",
       " 1.018733024597168,\n",
       " 0.21117796003818512,\n",
       " -0.7056617140769958,\n",
       " 0.8296574950218201,\n",
       " 0.12151757627725601,\n",
       " 0.24775010347366333,\n",
       " -0.14939868450164795,\n",
       " -0.3010859489440918,\n",
       " -0.13937783241271973,\n",
       " 0.13074631989002228,\n",
       " 0.6524198055267334,\n",
       " 0.7779066562652588,\n",
       " -0.023174360394477844,\n",
       " 0.21420004963874817,\n",
       " -0.2591742277145386,\n",
       " 0.26515066623687744,\n",
       " -0.7926283478736877,\n",
       " -0.08087999373674393,\n",
       " -0.6001523733139038,\n",
       " -0.46004292368888855,\n",
       " -0.24468994140625,\n",
       " 0.06607888638973236,\n",
       " -0.3347562551498413,\n",
       " 1.3361053466796875,\n",
       " 0.31032994389533997,\n",
       " 0.17891886830329895,\n",
       " 0.13739927113056183,\n",
       " 0.13707028329372406,\n",
       " 0.29648464918136597,\n",
       " 0.05570825934410095,\n",
       " -0.11062575876712799,\n",
       " 0.2677043080329895,\n",
       " 0.06693950295448303,\n",
       " -0.023607559502124786,\n",
       " -0.11100482195615768,\n",
       " 0.1847604215145111,\n",
       " -0.1090194433927536,\n",
       " -0.1339595466852188,\n",
       " 0.28131964802742004,\n",
       " -0.31015345454216003,\n",
       " -0.39053186774253845,\n",
       " 0.272000253200531,\n",
       " -0.40752214193344116,\n",
       " 0.4780896008014679,\n",
       " 1.0467407703399658,\n",
       " -0.46290209889411926,\n",
       " 0.06362137943506241,\n",
       " -1.1735892295837402,\n",
       " -0.8616599440574646,\n",
       " 0.4505365192890167,\n",
       " -0.741300106048584,\n",
       " -0.30637291073799133,\n",
       " 0.2822647988796234,\n",
       " -0.05673131346702576,\n",
       " 0.192682683467865,\n",
       " 0.1456216275691986,\n",
       " -0.9961807131767273,\n",
       " 0.4654240608215332,\n",
       " 1.2159684896469116,\n",
       " 0.21782447397708893,\n",
       " -0.4151592552661896,\n",
       " 0.0024509280920028687,\n",
       " 0.5895037055015564,\n",
       " -0.15881794691085815,\n",
       " -0.6131300926208496,\n",
       " -0.32734790444374084,\n",
       " 0.07163398712873459,\n",
       " 0.48753827810287476,\n",
       " 0.03072507679462433,\n",
       " -0.27276819944381714,\n",
       " -0.3462071418762207,\n",
       " -0.004854276776313782,\n",
       " 0.19930244982242584,\n",
       " -0.2984696626663208,\n",
       " -0.02998644858598709,\n",
       " -0.34770211577415466,\n",
       " -0.07780434936285019,\n",
       " 0.3941790461540222,\n",
       " 0.033903367817401886,\n",
       " 0.18667730689048767,\n",
       " -0.4151003062725067,\n",
       " 0.2901824116706848,\n",
       " -0.4556276500225067,\n",
       " 0.5280961990356445,\n",
       " -0.4192230701446533,\n",
       " -0.15654709935188293,\n",
       " -0.027136366814374924,\n",
       " -0.09240942448377609,\n",
       " -0.7791086435317993,\n",
       " 0.7451284527778625,\n",
       " 0.929246723651886,\n",
       " 0.12139721214771271,\n",
       " 0.7359004616737366,\n",
       " -0.4531381130218506,\n",
       " 0.010867815464735031,\n",
       " 0.40760987997055054,\n",
       " -0.06264537572860718,\n",
       " -0.23419132828712463,\n",
       " 1.159530758857727,\n",
       " 0.4680335521697998,\n",
       " -0.055652931332588196,\n",
       " -0.48760199546813965,\n",
       " -0.20945747196674347,\n",
       " 0.4061059355735779,\n",
       " -0.5859676599502563,\n",
       " -0.49741485714912415,\n",
       " -0.16097255051136017,\n",
       " -0.24646273255348206,\n",
       " 0.8408013582229614,\n",
       " -0.2638528347015381,\n",
       " -0.7909961938858032,\n",
       " -0.40323591232299805,\n",
       " -0.2038729190826416,\n",
       " -0.17040735483169556,\n",
       " 0.7139506340026855,\n",
       " -0.8534120917320251,\n",
       " -0.05454762652516365,\n",
       " -0.13655196130275726,\n",
       " -0.6335821747779846,\n",
       " 0.6164856553077698,\n",
       " -1.1430211067199707,\n",
       " -0.21859407424926758,\n",
       " -0.782650887966156,\n",
       " -0.12139879167079926,\n",
       " 0.6964854598045349,\n",
       " 0.7491365075111389,\n",
       " 0.5905581116676331,\n",
       " -0.17945188283920288,\n",
       " 1.2930238246917725,\n",
       " 0.2632060647010803,\n",
       " 0.020782604813575745,\n",
       " 0.31698280572891235,\n",
       " 0.32713234424591064,\n",
       " 0.8574146628379822,\n",
       " 0.2643161416053772,\n",
       " -0.5880823731422424,\n",
       " -0.0725991502404213,\n",
       " -0.31516242027282715,\n",
       " -0.3209269940853119,\n",
       " -0.8042119145393372,\n",
       " -0.5057405233383179,\n",
       " 0.25711590051651,\n",
       " 0.005479857325553894,\n",
       " -0.2659376561641693,\n",
       " 0.6764255166053772,\n",
       " -0.6092296838760376,\n",
       " 0.24248036742210388,\n",
       " -0.3991919457912445,\n",
       " 0.3223612904548645,\n",
       " -0.24315306544303894,\n",
       " -0.4507949948310852,\n",
       " 0.8138503432273865,\n",
       " -0.8625319600105286,\n",
       " -0.5951434373855591,\n",
       " 0.5954759120941162,\n",
       " 0.6582975387573242,\n",
       " 0.465009868144989,\n",
       " 0.038950007408857346,\n",
       " 1.1818625926971436,\n",
       " -0.2944786846637726,\n",
       " 0.5813227295875549,\n",
       " 0.7141729593276978,\n",
       " -0.1412554234266281,\n",
       " -0.3200750946998596,\n",
       " 0.1923425793647766,\n",
       " -0.48883697390556335,\n",
       " -0.5964657068252563,\n",
       " 0.7399722933769226,\n",
       " -0.8687461614608765,\n",
       " 0.3731105625629425,\n",
       " 0.4909788966178894,\n",
       " 0.008555188775062561,\n",
       " -0.3460381329059601,\n",
       " -0.01978044956922531,\n",
       " -0.014963813126087189,\n",
       " -0.3445613980293274,\n",
       " -0.4017603397369385,\n",
       " 0.4142001271247864,\n",
       " -0.5335109829902649,\n",
       " 0.7326738834381104,\n",
       " -0.03276481479406357,\n",
       " 0.49944180250167847,\n",
       " 0.06930910795927048,\n",
       " -0.9964637756347656,\n",
       " 0.3156639039516449,\n",
       " 0.24342289566993713,\n",
       " 0.3846820592880249,\n",
       " -1.059798002243042,\n",
       " 0.15527167916297913,\n",
       " -0.06300193071365356,\n",
       " -0.3982192873954773,\n",
       " -0.3640328645706177,\n",
       " -1.1124478578567505,\n",
       " -0.0897924080491066,\n",
       " 0.39252209663391113,\n",
       " -0.46574726700782776,\n",
       " -1.1656869649887085,\n",
       " 0.06311140209436417,\n",
       " 0.24773508310317993,\n",
       " 0.15669995546340942,\n",
       " 0.2978490889072418,\n",
       " -0.5781250596046448,\n",
       " 0.46499645709991455,\n",
       " 0.7958780527114868,\n",
       " 0.942966103553772,\n",
       " -0.4666745662689209,\n",
       " 0.8520214557647705,\n",
       " 0.0846681222319603,\n",
       " -0.031566888093948364,\n",
       " 0.542232096195221,\n",
       " -0.21499866247177124,\n",
       " 0.7112693190574646,\n",
       " 0.31495779752731323,\n",
       " -0.04247624799609184,\n",
       " -0.37034812569618225,\n",
       " 0.8877348303794861,\n",
       " -0.44127726554870605,\n",
       " -0.6065894961357117,\n",
       " 0.023224323987960815,\n",
       " 0.7546645998954773,\n",
       " -0.09707105159759521,\n",
       " -0.32772815227508545,\n",
       " -1.1098196506500244,\n",
       " -0.27209001779556274,\n",
       " -1.0114588737487793,\n",
       " -0.2320113629102707,\n",
       " -0.28254416584968567,\n",
       " 0.8747594952583313,\n",
       " 0.15139135718345642,\n",
       " 0.041182197630405426,\n",
       " -0.014415200799703598,\n",
       " -1.123056411743164,\n",
       " 4.0092997550964355,\n",
       " 1.277307391166687,\n",
       " 0.521327018737793,\n",
       " -0.3406869173049927,\n",
       " -0.40440472960472107,\n",
       " 0.3309361934661865,\n",
       " 0.4799351692199707,\n",
       " -0.0618676021695137,\n",
       " 0.7236433029174805,\n",
       " -0.21260690689086914,\n",
       " -0.2627624571323395,\n",
       " -0.7974912524223328,\n",
       " -0.43642786145210266,\n",
       " 0.5395719408988953,\n",
       " 0.2012576460838318,\n",
       " 0.6681215763092041,\n",
       " -1.19291090965271,\n",
       " -0.439333438873291,\n",
       " 0.5815192461013794,\n",
       " -1.0286674499511719,\n",
       " -1.0218002796173096,\n",
       " 0.3495195209980011,\n",
       " -0.17530176043510437,\n",
       " 0.27853673696517944,\n",
       " 0.16314563155174255,\n",
       " -0.1248372346162796,\n",
       " 0.9968729615211487,\n",
       " -0.5727090239524841,\n",
       " 0.07224598526954651,\n",
       " 0.26574981212615967,\n",
       " -0.23671531677246094,\n",
       " -0.5756771564483643,\n",
       " 0.6431458592414856,\n",
       " 0.1322539895772934,\n",
       " -0.10140303522348404,\n",
       " 0.11219184845685959,\n",
       " -0.03225203976035118,\n",
       " -0.18208910524845123,\n",
       " -0.24943700432777405,\n",
       " -0.6384496092796326,\n",
       " -0.0719698965549469,\n",
       " 0.20240814983844757,\n",
       " -0.33799824118614197,\n",
       " 0.1550617516040802,\n",
       " -0.3171554505825043,\n",
       " 0.12016092985868454,\n",
       " -0.32849833369255066,\n",
       " 0.4241383969783783,\n",
       " -0.5165507793426514,\n",
       " -0.6674260497093201,\n",
       " 1.1226317882537842,\n",
       " 0.027226969599723816,\n",
       " 0.13227836787700653,\n",
       " -0.5883148908615112,\n",
       " -0.7976993918418884,\n",
       " 0.5203560590744019,\n",
       " 0.23534046113491058,\n",
       " -0.4559337794780731,\n",
       " -0.29566046595573425,\n",
       " -0.1155196875333786,\n",
       " 0.20329144597053528,\n",
       " -0.8758511543273926,\n",
       " 0.07463458180427551,\n",
       " -0.03229376673698425,\n",
       " -0.40206921100616455,\n",
       " 0.5602020025253296,\n",
       " 0.20564857125282288,\n",
       " 0.8868333101272583,\n",
       " -0.4252309501171112,\n",
       " 0.11126925051212311,\n",
       " 0.12981973588466644,\n",
       " ...]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1=embeddings.embed_documents([\"Alpha is first letter of Greek alphabets\",\"Beta is second one\"])\n",
    "r1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(r1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2971070408821106,\n",
       " -0.09603878855705261,\n",
       " 0.32907047867774963,\n",
       " -0.16204790771007538,\n",
       " -1.4167752265930176,\n",
       " -0.2853044271469116,\n",
       " 1.1404540538787842,\n",
       " 0.4384717345237732,\n",
       " -0.1398947536945343,\n",
       " 0.5754501223564148,\n",
       " 0.22336529195308685,\n",
       " 0.3516661822795868,\n",
       " -0.6853501796722412,\n",
       " 0.18279340863227844,\n",
       " -1.2385733127593994,\n",
       " -0.06594858318567276,\n",
       " -0.15118825435638428,\n",
       " -0.010719601064920425,\n",
       " -0.5971776247024536,\n",
       " -0.18852975964546204,\n",
       " 1.051552653312683,\n",
       " 1.0377808809280396,\n",
       " -1.384584903717041,\n",
       " 0.4320550262928009,\n",
       " -0.07874493300914764,\n",
       " 0.1339009404182434,\n",
       " -0.5505450963973999,\n",
       " -0.6654351949691772,\n",
       " -0.06054915487766266,\n",
       " 0.9092860221862793,\n",
       " -0.5731201767921448,\n",
       " 0.39792633056640625,\n",
       " 0.4485471546649933,\n",
       " -0.7019790410995483,\n",
       " 0.027622103691101074,\n",
       " -0.6260785460472107,\n",
       " 0.7473986744880676,\n",
       " -0.6798529028892517,\n",
       " -0.08232481777667999,\n",
       " -1.033233404159546,\n",
       " 0.4757238030433655,\n",
       " 0.060763418674468994,\n",
       " -0.19816432893276215,\n",
       " -0.594415545463562,\n",
       " -0.7081314921379089,\n",
       " -0.0035319924354553223,\n",
       " -0.47417667508125305,\n",
       " -0.7243996262550354,\n",
       " -1.2673089504241943,\n",
       " -0.4447355270385742,\n",
       " -0.16017615795135498,\n",
       " -0.1744406521320343,\n",
       " 0.5390392541885376,\n",
       " -0.3339442014694214,\n",
       " -0.5668078660964966,\n",
       " 0.28423047065734863,\n",
       " 0.5300538539886475,\n",
       " -0.22773244976997375,\n",
       " -0.4699293076992035,\n",
       " 0.22339920699596405,\n",
       " 0.5124125480651855,\n",
       " 0.024878863245248795,\n",
       " 0.10938224196434021,\n",
       " -0.8006944060325623,\n",
       " -0.6248559951782227,\n",
       " -0.41787198185920715,\n",
       " 0.8383401036262512,\n",
       " -0.37195873260498047,\n",
       " 0.8503295183181763,\n",
       " 0.4123329222202301,\n",
       " 0.04145023971796036,\n",
       " 0.9348716139793396,\n",
       " 0.1269856095314026,\n",
       " -0.6700043678283691,\n",
       " -0.578904390335083,\n",
       " 0.3033343553543091,\n",
       " -0.5892308354377747,\n",
       " -0.35611316561698914,\n",
       " -0.8835482597351074,\n",
       " 0.6941637396812439,\n",
       " -0.17836423218250275,\n",
       " 0.48217836022377014,\n",
       " -0.07923813164234161,\n",
       " -0.37455618381500244,\n",
       " 0.040911003947257996,\n",
       " 0.26617953181266785,\n",
       " 0.3494986593723297,\n",
       " 0.1297944337129593,\n",
       " -0.00017408467829227448,\n",
       " 0.2512369155883789,\n",
       " 0.914344072341919,\n",
       " 0.41158178448677063,\n",
       " -0.006226152181625366,\n",
       " 0.5094165802001953,\n",
       " 1.2221447229385376,\n",
       " 0.23702092468738556,\n",
       " 0.3130340576171875,\n",
       " 0.29935187101364136,\n",
       " 0.587304949760437,\n",
       " 0.5397104620933533,\n",
       " 1.1343660354614258,\n",
       " 0.8334063291549683,\n",
       " -0.49924641847610474,\n",
       " 0.8573237061500549,\n",
       " -0.2700050473213196,\n",
       " 0.24338136613368988,\n",
       " -0.18029922246932983,\n",
       " 0.2984451949596405,\n",
       " 0.05508364737033844,\n",
       " -0.32435524463653564,\n",
       " 0.7179257869720459,\n",
       " -0.01990313082933426,\n",
       " 0.14775840938091278,\n",
       " -0.22133243083953857,\n",
       " -0.17227500677108765,\n",
       " 0.43436187505722046,\n",
       " 0.01575838215649128,\n",
       " 0.5256425738334656,\n",
       " -1.3196901082992554,\n",
       " -0.2241034358739853,\n",
       " 0.22981956601142883,\n",
       " 0.771293044090271,\n",
       " 0.14651991426944733,\n",
       " 0.9023057222366333,\n",
       " 0.4297167956829071,\n",
       " -0.35533806681632996,\n",
       " -0.2542744278907776,\n",
       " -0.0160472821444273,\n",
       " -1.3680806159973145,\n",
       " 0.5270659327507019,\n",
       " 0.08595602959394455,\n",
       " -0.1191035658121109,\n",
       " -0.20564976334571838,\n",
       " 0.3536272644996643,\n",
       " -0.6000258326530457,\n",
       " 0.10160521417856216,\n",
       " 0.34792399406433105,\n",
       " -0.0273420587182045,\n",
       " 0.6607237458229065,\n",
       " -0.4085593521595001,\n",
       " 0.6952886581420898,\n",
       " 0.192572221159935,\n",
       " -0.4309074282646179,\n",
       " 1.2718321084976196,\n",
       " -0.4134313464164734,\n",
       " -0.15468032658100128,\n",
       " 0.431101530790329,\n",
       " 1.126574993133545,\n",
       " -1.0863690376281738,\n",
       " 0.29317164421081543,\n",
       " -0.37680038809776306,\n",
       " -0.09985312074422836,\n",
       " -1.1939617395401,\n",
       " 0.3719090521335602,\n",
       " -1.0280590057373047,\n",
       " 0.2088949829339981,\n",
       " 0.7352283000946045,\n",
       " 0.02022252231836319,\n",
       " 0.4799434542655945,\n",
       " -0.11007485538721085,\n",
       " -0.5198677778244019,\n",
       " -0.09790164232254028,\n",
       " 0.6345643401145935,\n",
       " 1.0107421875,\n",
       " -0.08370181918144226,\n",
       " 1.1953182220458984,\n",
       " -0.3835675120353699,\n",
       " 0.0719822570681572,\n",
       " 0.4458559453487396,\n",
       " -0.8319264650344849,\n",
       " -0.1191481202840805,\n",
       " -0.5086542367935181,\n",
       " -0.11217381805181503,\n",
       " 0.5004875659942627,\n",
       " 0.3577044904232025,\n",
       " 0.5599154233932495,\n",
       " -0.3810245990753174,\n",
       " -0.539828360080719,\n",
       " 0.5481811761856079,\n",
       " 0.9353904724121094,\n",
       " 0.055357471108436584,\n",
       " -0.12904071807861328,\n",
       " 0.5960144996643066,\n",
       " -0.189520925283432,\n",
       " -0.008405640721321106,\n",
       " 0.6614399552345276,\n",
       " 0.13467468321323395,\n",
       " 0.22194918990135193,\n",
       " -0.559820294380188,\n",
       " -0.24378201365470886,\n",
       " -0.22375454008579254,\n",
       " 0.6184828281402588,\n",
       " 0.05944768339395523,\n",
       " 0.11044687777757645,\n",
       " -0.8617871999740601,\n",
       " 0.4184313118457794,\n",
       " -1.048586368560791,\n",
       " -0.20945020020008087,\n",
       " -0.37332630157470703,\n",
       " -0.9166147112846375,\n",
       " 0.012441106140613556,\n",
       " 1.2656474113464355,\n",
       " 0.6933639049530029,\n",
       " 0.6302912831306458,\n",
       " -0.2761003375053406,\n",
       " -0.5371663570404053,\n",
       " 0.6698123216629028,\n",
       " 0.17144855856895447,\n",
       " -0.3075765371322632,\n",
       " 0.14565525949001312,\n",
       " 0.8283974528312683,\n",
       " 0.04245816543698311,\n",
       " -0.7391824126243591,\n",
       " 1.582152009010315,\n",
       " 0.196063831448555,\n",
       " 0.025683268904685974,\n",
       " -0.8853544592857361,\n",
       " 1.0789270401000977,\n",
       " -1.1494101285934448,\n",
       " 0.31185585260391235,\n",
       " -0.20871669054031372,\n",
       " 0.9044915437698364,\n",
       " -0.22327840328216553,\n",
       " 1.4351017475128174,\n",
       " -0.4161614179611206,\n",
       " -0.29596853256225586,\n",
       " 0.8990635275840759,\n",
       " 0.388433039188385,\n",
       " -0.3665008246898651,\n",
       " 0.6686850786209106,\n",
       " -0.1901872605085373,\n",
       " 0.6280438899993896,\n",
       " -0.05049794912338257,\n",
       " 0.10550160706043243,\n",
       " 0.24003103375434875,\n",
       " 0.033671632409095764,\n",
       " 0.7836527824401855,\n",
       " 1.2752021551132202,\n",
       " 0.5163241624832153,\n",
       " 0.23511438071727753,\n",
       " 0.029151171445846558,\n",
       " -0.5095316767692566,\n",
       " 1.6542174816131592,\n",
       " -0.007892262190580368,\n",
       " 0.6462959051132202,\n",
       " 0.523607611656189,\n",
       " 0.2991268038749695,\n",
       " -0.25496384501457214,\n",
       " -0.3494642972946167,\n",
       " -0.14678075909614563,\n",
       " 0.7030184864997864,\n",
       " 0.7141664624214172,\n",
       " 0.5278893709182739,\n",
       " -0.40492579340934753,\n",
       " -1.15430748462677,\n",
       " -0.4512230157852173,\n",
       " 0.6828517913818359,\n",
       " 0.6065434217453003,\n",
       " -0.47768694162368774,\n",
       " -0.752713680267334,\n",
       " -0.37985727190971375,\n",
       " -0.5521315932273865,\n",
       " 0.737784743309021,\n",
       " -0.267713338136673,\n",
       " -0.25821393728256226,\n",
       " 0.02812778577208519,\n",
       " 1.0073567628860474,\n",
       " 0.3702399432659149,\n",
       " -0.4849456548690796,\n",
       " 0.06155835837125778,\n",
       " -0.8181813955307007,\n",
       " -0.544736921787262,\n",
       " -0.7484111189842224,\n",
       " -0.4931986927986145,\n",
       " -0.6779893040657043,\n",
       " -0.2004677951335907,\n",
       " 0.8047304153442383,\n",
       " -0.6489218473434448,\n",
       " 0.4162805676460266,\n",
       " -0.17219772934913635,\n",
       " -1.0458208322525024,\n",
       " -0.08868369460105896,\n",
       " -1.5938668251037598,\n",
       " 0.5836862325668335,\n",
       " 0.0024782419204711914,\n",
       " 1.3826813697814941,\n",
       " 0.24468545615673065,\n",
       " -0.3134138286113739,\n",
       " 0.3477127254009247,\n",
       " 0.9101320505142212,\n",
       " -0.7844515442848206,\n",
       " -0.041251182556152344,\n",
       " -0.25602948665618896,\n",
       " -0.8557756543159485,\n",
       " -0.4586470425128937,\n",
       " -0.3361177146434784,\n",
       " 0.09425284713506699,\n",
       " -0.4651916027069092,\n",
       " -0.9325015544891357,\n",
       " -1.6996456384658813,\n",
       " 0.07251032441854477,\n",
       " 0.380794495344162,\n",
       " -0.13380250334739685,\n",
       " 0.4304543137550354,\n",
       " -0.2454296350479126,\n",
       " 0.5130635499954224,\n",
       " 0.7226475477218628,\n",
       " -0.14437413215637207,\n",
       " 0.00954260304570198,\n",
       " 0.3230760097503662,\n",
       " -0.6571995615959167,\n",
       " 1.0075323581695557,\n",
       " -0.30295300483703613,\n",
       " -0.10649563372135162,\n",
       " -1.003115177154541,\n",
       " 0.7959198355674744,\n",
       " -0.028415333479642868,\n",
       " 0.6543276309967041,\n",
       " -0.2410244345664978,\n",
       " -0.3155810832977295,\n",
       " 0.3626037836074829,\n",
       " 0.09352230280637741,\n",
       " 0.2980421781539917,\n",
       " -0.7325550317764282,\n",
       " 0.21705690026283264,\n",
       " 0.6574815511703491,\n",
       " -0.5044498443603516,\n",
       " -1.5076605081558228,\n",
       " 0.3373548686504364,\n",
       " -0.42422065138816833,\n",
       " -0.47448182106018066,\n",
       " -0.12363734841346741,\n",
       " -0.602533221244812,\n",
       " 0.38142696022987366,\n",
       " -0.2903711199760437,\n",
       " 0.3783856928348541,\n",
       " 0.18909023702144623,\n",
       " -0.3083948791027069,\n",
       " 0.23644877970218658,\n",
       " 0.4539867639541626,\n",
       " 0.8076647520065308,\n",
       " -0.5125952959060669,\n",
       " -0.5166686177253723,\n",
       " 0.24997872114181519,\n",
       " -0.49263080954551697,\n",
       " -0.21549132466316223,\n",
       " 0.3386327922344208,\n",
       " -0.14283673465251923,\n",
       " -0.974320113658905,\n",
       " 0.4768936038017273,\n",
       " -0.37742435932159424,\n",
       " 0.49726247787475586,\n",
       " 0.07369231432676315,\n",
       " 0.454785019159317,\n",
       " 0.23980852961540222,\n",
       " 0.5771012902259827,\n",
       " -0.3012292981147766,\n",
       " 0.6070027351379395,\n",
       " 0.25343844294548035,\n",
       " 0.7609734535217285,\n",
       " -0.08775444328784943,\n",
       " 0.99739670753479,\n",
       " 0.07369878888130188,\n",
       " 0.13966430723667145,\n",
       " 0.8029108047485352,\n",
       " -0.7568010687828064,\n",
       " 0.1783997267484665,\n",
       " 0.44049927592277527,\n",
       " 0.45551982522010803,\n",
       " -0.2589845061302185,\n",
       " 0.3593235909938812,\n",
       " -0.09493689239025116,\n",
       " -0.7364561557769775,\n",
       " 0.14506398141384125,\n",
       " -0.6980090141296387,\n",
       " -0.009718112647533417,\n",
       " 1.014215111732483,\n",
       " -0.42524611949920654,\n",
       " 0.23601697385311127,\n",
       " -0.511679470539093,\n",
       " -0.20684275031089783,\n",
       " -0.14010727405548096,\n",
       " 0.05170052498579025,\n",
       " 0.01808527112007141,\n",
       " 0.8757526874542236,\n",
       " 0.7768825888633728,\n",
       " 0.3811037540435791,\n",
       " 0.04317879676818848,\n",
       " -0.9691568613052368,\n",
       " -0.7984653115272522,\n",
       " -0.05413241684436798,\n",
       " -0.4429943561553955,\n",
       " 0.6123734712600708,\n",
       " -0.2554555833339691,\n",
       " -0.45767921209335327,\n",
       " -0.48815861344337463,\n",
       " 0.8473020792007446,\n",
       " 0.07643996924161911,\n",
       " 0.7935864925384521,\n",
       " 0.07653023302555084,\n",
       " -0.29544052481651306,\n",
       " 0.6185922026634216,\n",
       " 0.02925923466682434,\n",
       " 1.0619232654571533,\n",
       " -0.28226128220558167,\n",
       " 0.6618822813034058,\n",
       " 0.09196662157773972,\n",
       " 1.0332322120666504,\n",
       " 0.19567513465881348,\n",
       " -0.0273616760969162,\n",
       " -0.9357953071594238,\n",
       " 0.38877320289611816,\n",
       " -0.6905195713043213,\n",
       " -0.003191438503563404,\n",
       " 0.2899852991104126,\n",
       " -0.3187856376171112,\n",
       " -1.3397839069366455,\n",
       " -0.1563549041748047,\n",
       " 0.15380936861038208,\n",
       " 0.4876920282840729,\n",
       " -0.4253969192504883,\n",
       " -0.18979009985923767,\n",
       " -0.43651869893074036,\n",
       " -0.2143217921257019,\n",
       " 0.7008454203605652,\n",
       " -0.26627832651138306,\n",
       " -0.3845144510269165,\n",
       " -0.31393757462501526,\n",
       " 0.399289608001709,\n",
       " 0.41180160641670227,\n",
       " 0.12812566757202148,\n",
       " 0.47497063875198364,\n",
       " -0.20355480909347534,\n",
       " -0.2405606210231781,\n",
       " -0.9296456575393677,\n",
       " 0.17829476296901703,\n",
       " 0.8530256152153015,\n",
       " 0.19717267155647278,\n",
       " 0.4017670750617981,\n",
       " -0.4192406237125397,\n",
       " 1.3669312000274658,\n",
       " 0.2749374508857727,\n",
       " -0.4151321351528168,\n",
       " -0.4369550943374634,\n",
       " -0.7813085913658142,\n",
       " -0.033560529351234436,\n",
       " -0.399253249168396,\n",
       " 0.39096784591674805,\n",
       " -0.525886058807373,\n",
       " 0.08018684387207031,\n",
       " 0.4303760826587677,\n",
       " -0.9340789914131165,\n",
       " -0.05221937596797943,\n",
       " 0.21097993850708008,\n",
       " 1.0044398307800293,\n",
       " -0.01723960041999817,\n",
       " -0.14150387048721313,\n",
       " -0.09473632276058197,\n",
       " 0.06408591568470001,\n",
       " -0.22661909461021423,\n",
       " 0.45291808247566223,\n",
       " -0.413330078125,\n",
       " 0.34960323572158813,\n",
       " -0.8659108877182007,\n",
       " -0.6136242747306824,\n",
       " 0.8511353135108948,\n",
       " -0.053326159715652466,\n",
       " -0.47924986481666565,\n",
       " 0.5611062049865723,\n",
       " 0.08456684648990631,\n",
       " -0.07595860958099365,\n",
       " 0.35391154885292053,\n",
       " -0.4721524715423584,\n",
       " 0.13033869862556458,\n",
       " 0.23277512192726135,\n",
       " -0.5647057890892029,\n",
       " 0.39531293511390686,\n",
       " 0.02094949409365654,\n",
       " -0.521271288394928,\n",
       " 0.3788713216781616,\n",
       " -0.4626217186450958,\n",
       " -0.00917624682188034,\n",
       " 0.29680708050727844,\n",
       " 0.006388302892446518,\n",
       " -0.5402069687843323,\n",
       " -0.5222830772399902,\n",
       " 1.0995266437530518,\n",
       " 0.034349847584962845,\n",
       " 0.03792855143547058,\n",
       " -0.10689885914325714,\n",
       " -0.36958420276641846,\n",
       " 0.28960609436035156,\n",
       " 0.46254584193229675,\n",
       " -0.645560622215271,\n",
       " -0.6343629360198975,\n",
       " -0.45856940746307373,\n",
       " -1.017085313796997,\n",
       " -0.41083723306655884,\n",
       " 0.48703163862228394,\n",
       " 0.5865126848220825,\n",
       " 0.4746171534061432,\n",
       " -0.14871355891227722,\n",
       " -0.5353794097900391,\n",
       " -0.2769428491592407,\n",
       " 0.18724769353866577,\n",
       " -0.5586224794387817,\n",
       " -0.7945634722709656,\n",
       " -0.03239816799759865,\n",
       " 0.335926353931427,\n",
       " 0.2346024513244629,\n",
       " -0.6191847920417786,\n",
       " 0.5889225602149963,\n",
       " 0.5975226163864136,\n",
       " -0.39599886536598206,\n",
       " 0.29815852642059326,\n",
       " 0.8574844002723694,\n",
       " 0.9579548835754395,\n",
       " -0.31763091683387756,\n",
       " 0.12456418573856354,\n",
       " 1.2890496253967285,\n",
       " 0.7476322650909424,\n",
       " -1.576560616493225,\n",
       " -0.005348481237888336,\n",
       " -0.007633151486515999,\n",
       " 0.04211026430130005,\n",
       " 0.6696959137916565,\n",
       " 0.9439305067062378,\n",
       " -0.5653986930847168,\n",
       " -0.8827661871910095,\n",
       " -0.4616377651691437,\n",
       " 0.3850756287574768,\n",
       " -0.7085360288619995,\n",
       " -0.17373843491077423,\n",
       " -0.6982162594795227,\n",
       " -0.5724926590919495,\n",
       " -1.0461455583572388,\n",
       " -0.08752772212028503,\n",
       " -0.3163983225822449,\n",
       " 0.011558832600712776,\n",
       " -0.1963920295238495,\n",
       " -0.8267203569412231,\n",
       " -0.11638392508029938,\n",
       " 0.6271565556526184,\n",
       " 0.23987719416618347,\n",
       " -0.42562639713287354,\n",
       " -0.2062489092350006,\n",
       " 0.5504133701324463,\n",
       " 0.6677663326263428,\n",
       " 0.12099678814411163,\n",
       " 0.8249065279960632,\n",
       " -1.066001534461975,\n",
       " 0.09990110993385315,\n",
       " -0.1571183055639267,\n",
       " 0.28705382347106934,\n",
       " -0.2604583203792572,\n",
       " -0.9011787176132202,\n",
       " 0.33483240008354187,\n",
       " 0.7830939292907715,\n",
       " -0.533722996711731,\n",
       " -0.2968660295009613,\n",
       " -0.6733461618423462,\n",
       " -0.3450636863708496,\n",
       " -0.366219699382782,\n",
       " -0.3166623115539551,\n",
       " -0.23163612186908722,\n",
       " -0.10904797166585922,\n",
       " -0.006373781710863113,\n",
       " -0.22942596673965454,\n",
       " 0.39383822679519653,\n",
       " -0.3816471993923187,\n",
       " -0.39869779348373413,\n",
       " 0.17434310913085938,\n",
       " 0.7483969330787659,\n",
       " 0.5454787015914917,\n",
       " -0.04349220171570778,\n",
       " -0.14517933130264282,\n",
       " -1.15272855758667,\n",
       " -0.16823416948318481,\n",
       " -1.4023683071136475,\n",
       " 0.08238199353218079,\n",
       " 0.46495258808135986,\n",
       " 0.11878649890422821,\n",
       " -0.49620330333709717,\n",
       " -0.12430407106876373,\n",
       " 1.1932154893875122,\n",
       " -0.2581038177013397,\n",
       " 0.22729773819446564,\n",
       " 0.7878231406211853,\n",
       " -0.1807229220867157,\n",
       " 0.16158217191696167,\n",
       " -0.8244182467460632,\n",
       " 0.4383954107761383,\n",
       " 0.4841262996196747,\n",
       " -0.5430416464805603,\n",
       " 0.010803308337926865,\n",
       " 0.20487605035305023,\n",
       " -0.6647897362709045,\n",
       " -0.09393003582954407,\n",
       " -0.9835507273674011,\n",
       " -0.8171203136444092,\n",
       " -0.5624582767486572,\n",
       " 0.6540696620941162,\n",
       " 0.9843660593032837,\n",
       " -0.33747783303260803,\n",
       " 0.6245842576026917,\n",
       " -0.4810280501842499,\n",
       " -0.13928702473640442,\n",
       " -0.40076783299446106,\n",
       " 0.9485387206077576,\n",
       " 0.44541293382644653,\n",
       " -0.4318305253982544,\n",
       " 0.745843231678009,\n",
       " -0.23827612400054932,\n",
       " -0.4625128507614136,\n",
       " 0.29676762223243713,\n",
       " -0.21059772372245789,\n",
       " -0.5217483639717102,\n",
       " -0.45197594165802,\n",
       " 0.4721618890762329,\n",
       " -0.1364886611700058,\n",
       " 0.4556199312210083,\n",
       " 0.5639135837554932,\n",
       " 0.08470463752746582,\n",
       " -0.9306031465530396,\n",
       " -0.5050882697105408,\n",
       " -0.4754195213317871,\n",
       " 0.5615406632423401,\n",
       " 0.25484734773635864,\n",
       " -0.2713729739189148,\n",
       " -0.06425610184669495,\n",
       " 0.7399497628211975,\n",
       " -0.03790370002388954,\n",
       " -0.7304397821426392,\n",
       " -0.2773234248161316,\n",
       " -0.4682830274105072,\n",
       " 0.9516133069992065,\n",
       " -0.02392461523413658,\n",
       " -0.06398549675941467,\n",
       " -0.03670022636651993,\n",
       " -0.006984639912843704,\n",
       " 0.5140828490257263,\n",
       " -0.20822569727897644,\n",
       " 0.026626337319612503,\n",
       " -1.111741542816162,\n",
       " 0.02189718186855316,\n",
       " -0.4925376772880554,\n",
       " 0.688676655292511,\n",
       " 0.9993840456008911,\n",
       " 0.07876738905906677,\n",
       " -0.050212398171424866,\n",
       " 0.32713788747787476,\n",
       " 0.4398813843727112,\n",
       " 0.8166965842247009,\n",
       " -0.2136729657649994,\n",
       " -0.5849210619926453,\n",
       " 0.696972131729126,\n",
       " -0.47065532207489014,\n",
       " -0.6049123406410217,\n",
       " 0.3453446626663208,\n",
       " -0.2540472447872162,\n",
       " -0.32868924736976624,\n",
       " 0.014546800404787064,\n",
       " -0.07328105717897415,\n",
       " 0.1782127171754837,\n",
       " -0.04754507541656494,\n",
       " 0.3566886782646179,\n",
       " -0.19155772030353546,\n",
       " 0.08929456770420074,\n",
       " 0.3128019869327545,\n",
       " -0.5145825743675232,\n",
       " -1.0336639881134033,\n",
       " -0.1696735918521881,\n",
       " -0.6910483837127686,\n",
       " 0.16854636371135712,\n",
       " 1.0237207412719727,\n",
       " -0.6721263527870178,\n",
       " -0.4266562759876251,\n",
       " 0.24828186631202698,\n",
       " 0.7380911111831665,\n",
       " -0.5146952867507935,\n",
       " 0.31976577639579773,\n",
       " -0.3386636972427368,\n",
       " 0.08588358759880066,\n",
       " -0.5323864817619324,\n",
       " 0.2504417300224304,\n",
       " -0.8317437171936035,\n",
       " 0.836293637752533,\n",
       " -1.126572847366333,\n",
       " -0.6099668741226196,\n",
       " -0.11616075783967972,\n",
       " 0.19461368024349213,\n",
       " -0.07909482717514038,\n",
       " 0.3745357394218445,\n",
       " -0.5066447257995605,\n",
       " 0.5353842377662659,\n",
       " -0.10801999270915985,\n",
       " -0.369649738073349,\n",
       " 0.48878026008605957,\n",
       " 0.8569427132606506,\n",
       " -0.23659957945346832,\n",
       " 0.7659550905227661,\n",
       " 0.9987520575523376,\n",
       " 0.16634024679660797,\n",
       " 0.22390243411064148,\n",
       " -0.05638084560632706,\n",
       " -0.4344328045845032,\n",
       " -0.6682109832763672,\n",
       " 0.3676088750362396,\n",
       " 0.6737698912620544,\n",
       " -0.3130391836166382,\n",
       " 0.25462043285369873,\n",
       " -0.43777549266815186,\n",
       " -0.05715009570121765,\n",
       " -0.6511556506156921,\n",
       " -0.31192517280578613,\n",
       " -0.01068018190562725,\n",
       " 0.4966682493686676,\n",
       " -0.5121203064918518,\n",
       " -0.3649238348007202,\n",
       " -0.09405970573425293,\n",
       " 0.9232296347618103,\n",
       " 0.7874403595924377,\n",
       " -0.015260644257068634,\n",
       " -0.03347325325012207,\n",
       " -0.5977815389633179,\n",
       " 0.024143461138010025,\n",
       " -0.27400508522987366,\n",
       " -0.1308385580778122,\n",
       " 0.6042205691337585,\n",
       " -0.014474913477897644,\n",
       " -0.15249326825141907,\n",
       " -0.7481713891029358,\n",
       " 0.1647043377161026,\n",
       " 0.5106604695320129,\n",
       " -0.1651763916015625,\n",
       " -0.08003777265548706,\n",
       " -1.0102052688598633,\n",
       " -1.3882439136505127,\n",
       " -0.3899550139904022,\n",
       " 0.0472184419631958,\n",
       " 0.0001821666955947876,\n",
       " 0.791396975517273,\n",
       " -0.7469674348831177,\n",
       " -0.49331122636795044,\n",
       " 0.12642553448677063,\n",
       " -0.8662129640579224,\n",
       " 0.359014630317688,\n",
       " -0.7201843857765198,\n",
       " -1.095800518989563,\n",
       " -0.3015691637992859,\n",
       " 0.25098419189453125,\n",
       " -0.3850677013397217,\n",
       " 0.24294573068618774,\n",
       " -0.973726212978363,\n",
       " 0.26476776599884033,\n",
       " -0.35291337966918945,\n",
       " -0.6071431636810303,\n",
       " -0.3969174325466156,\n",
       " 0.7617459297180176,\n",
       " 0.5800306797027588,\n",
       " 0.44548287987709045,\n",
       " 0.15429362654685974,\n",
       " -0.07532510161399841,\n",
       " -0.3410625159740448,\n",
       " 0.331287682056427,\n",
       " 0.15729059278964996,\n",
       " -0.6898953318595886,\n",
       " 0.3641980290412903,\n",
       " -0.20053476095199585,\n",
       " 0.2738836109638214,\n",
       " -0.13070592284202576,\n",
       " -0.6915210485458374,\n",
       " 0.19678081572055817,\n",
       " -0.6175144910812378,\n",
       " -0.40091052651405334,\n",
       " 0.28140756487846375,\n",
       " 0.38908618688583374,\n",
       " -0.5481705069541931,\n",
       " 0.8892621397972107,\n",
       " -1.2568817138671875,\n",
       " -0.5431017279624939,\n",
       " -0.026118241250514984,\n",
       " -0.10271655023097992,\n",
       " 0.6615520715713501,\n",
       " -0.4993603825569153,\n",
       " -0.6251615285873413,\n",
       " 0.43885350227355957,\n",
       " 1.2879183292388916,\n",
       " 0.03626968711614609,\n",
       " -0.39042574167251587,\n",
       " -0.17361068725585938,\n",
       " 0.16917717456817627,\n",
       " 0.4801422357559204,\n",
       " -0.42014774680137634,\n",
       " 0.09925314784049988,\n",
       " 0.4031534492969513,\n",
       " 0.41855138540267944,\n",
       " 0.026010507717728615,\n",
       " -0.6726486086845398,\n",
       " 0.3786383271217346,\n",
       " 0.35855841636657715,\n",
       " -0.09152480959892273,\n",
       " -0.19306525588035583,\n",
       " 0.3216475546360016,\n",
       " 0.09862637519836426,\n",
       " 0.8363602757453918,\n",
       " 0.17311371862888336,\n",
       " 0.15131357312202454,\n",
       " -0.30584484338760376,\n",
       " -0.007732462137937546,\n",
       " -0.3236081004142761,\n",
       " 0.17792600393295288,\n",
       " -0.36371132731437683,\n",
       " 0.15160579979419708,\n",
       " -0.4163753092288971,\n",
       " -0.20876654982566833,\n",
       " 0.4478924572467804,\n",
       " -0.27715229988098145,\n",
       " 0.28943270444869995,\n",
       " -0.42986106872558594,\n",
       " -0.6251782774925232,\n",
       " -0.08692393451929092,\n",
       " 0.39923688769340515,\n",
       " 0.7808569669723511,\n",
       " 0.1010601669549942,\n",
       " -0.03299973905086517,\n",
       " 0.4080323278903961,\n",
       " 0.22767965495586395,\n",
       " 0.965324878692627,\n",
       " 0.2424129843711853,\n",
       " 0.530028223991394,\n",
       " -0.41564643383026123,\n",
       " -0.0391886904835701,\n",
       " -0.5123184323310852,\n",
       " -0.42653533816337585,\n",
       " 0.10298271477222443,\n",
       " -0.6262794733047485,\n",
       " -1.0041167736053467,\n",
       " 0.8074737191200256,\n",
       " 0.13817982375621796,\n",
       " 0.40284401178359985,\n",
       " 0.8158924579620361,\n",
       " -0.2952513098716736,\n",
       " -0.3250993490219116,\n",
       " -0.37668168544769287,\n",
       " 0.32131582498550415,\n",
       " 0.4034964442253113,\n",
       " 0.8458303213119507,\n",
       " 0.73372483253479,\n",
       " -0.4708184599876404,\n",
       " -0.1383170336484909,\n",
       " 0.3335557281970978,\n",
       " -0.629274308681488,\n",
       " 0.631247878074646,\n",
       " 0.2368919402360916,\n",
       " 0.6389521956443787,\n",
       " 0.4984843134880066,\n",
       " 0.46396946907043457,\n",
       " 0.8206322193145752,\n",
       " 0.23344257473945618,\n",
       " 0.5509088635444641,\n",
       " 0.3802308738231659,\n",
       " 0.10664008557796478,\n",
       " -0.974139392375946,\n",
       " 1.0811712741851807,\n",
       " -0.5539907217025757,\n",
       " -0.15210659801959991,\n",
       " -0.33258408308029175,\n",
       " -0.18737134337425232,\n",
       " -0.7375648021697998,\n",
       " 0.9152279496192932,\n",
       " -0.040111929178237915,\n",
       " -0.843249499797821,\n",
       " -0.4079584777355194,\n",
       " 0.21550074219703674,\n",
       " -0.8295071721076965,\n",
       " 0.7415568828582764,\n",
       " 0.5439835786819458,\n",
       " 0.9277709126472473,\n",
       " 0.225800022482872,\n",
       " 0.006588412448763847,\n",
       " 0.05977022647857666,\n",
       " 0.11336526274681091,\n",
       " -0.020288769155740738,\n",
       " -0.9285645484924316,\n",
       " -0.6049491763114929,\n",
       " -0.9375056028366089,\n",
       " -0.17338375747203827,\n",
       " -0.36747556924819946,\n",
       " -0.26905593276023865,\n",
       " -0.5912953615188599,\n",
       " 1.3675647974014282,\n",
       " 0.10118870437145233,\n",
       " -1.1825218200683594,\n",
       " -0.21815282106399536,\n",
       " 0.5595471858978271,\n",
       " 0.1137399673461914,\n",
       " 0.1629265546798706,\n",
       " 0.2279718965291977,\n",
       " 1.2138880491256714,\n",
       " 0.3107753396034241,\n",
       " 0.2785989046096802,\n",
       " -0.8746329545974731,\n",
       " 0.5219542384147644,\n",
       " 0.17354953289031982,\n",
       " -0.11621834337711334,\n",
       " 0.43318480253219604,\n",
       " -0.9352765083312988,\n",
       " 0.4744790196418762,\n",
       " 0.7375209331512451,\n",
       " 0.04700005427002907,\n",
       " 0.46171748638153076,\n",
       " -0.060270100831985474,\n",
       " -0.61757892370224,\n",
       " -0.7431787848472595,\n",
       " -0.006359919905662537,\n",
       " 0.46343016624450684,\n",
       " 0.023903004825115204,\n",
       " -0.6960286498069763,\n",
       " -1.2771661281585693,\n",
       " 0.15615952014923096,\n",
       " -0.759737491607666,\n",
       " -0.08846250176429749,\n",
       " -0.3411308526992798,\n",
       " 0.4027828574180603,\n",
       " -0.36829686164855957,\n",
       " 0.4713101387023926,\n",
       " 0.2042238414287567,\n",
       " -1.2066740989685059,\n",
       " 3.7286620140075684,\n",
       " 1.518918514251709,\n",
       " 1.7966175079345703,\n",
       " 0.4332870841026306,\n",
       " -0.20300473272800446,\n",
       " 1.1696733236312866,\n",
       " -0.5021340250968933,\n",
       " -0.43327969312667847,\n",
       " -0.1646093726158142,\n",
       " -0.6467173099517822,\n",
       " 0.7936290502548218,\n",
       " 0.2464693784713745,\n",
       " -0.3041519522666931,\n",
       " 0.4514203667640686,\n",
       " -0.07076327502727509,\n",
       " 0.8874101042747498,\n",
       " -0.9272466897964478,\n",
       " 0.2124553918838501,\n",
       " 0.4343791604042053,\n",
       " -0.5205674171447754,\n",
       " -0.39965617656707764,\n",
       " 0.30981913208961487,\n",
       " -0.4198615849018097,\n",
       " 0.40835797786712646,\n",
       " -0.4510154128074646,\n",
       " 0.016434594988822937,\n",
       " 1.4787755012512207,\n",
       " -1.130057692527771,\n",
       " -0.017921175807714462,\n",
       " -0.01744719222187996,\n",
       " -0.16790375113487244,\n",
       " -0.13323503732681274,\n",
       " 0.10151784867048264,\n",
       " 0.07899472117424011,\n",
       " 0.8257882595062256,\n",
       " -0.0780366063117981,\n",
       " -0.12786850333213806,\n",
       " -1.375522494316101,\n",
       " -0.6360052227973938,\n",
       " 0.3998054265975952,\n",
       " -0.4154958128929138,\n",
       " -0.8338119983673096,\n",
       " -0.0936669409275055,\n",
       " -0.7836196422576904,\n",
       " 0.12021775543689728,\n",
       " 0.03200683370232582,\n",
       " -0.49239328503608704,\n",
       " 0.205050989985466,\n",
       " -0.4412184953689575,\n",
       " -0.5548238754272461,\n",
       " 0.2266276478767395,\n",
       " -0.0978546068072319,\n",
       " -0.2144722044467926,\n",
       " -1.17531418800354,\n",
       " -0.30406829714775085,\n",
       " 0.380507230758667,\n",
       " 0.26780569553375244,\n",
       " 0.03776683658361435,\n",
       " -0.47077810764312744,\n",
       " 0.7461305260658264,\n",
       " -0.9177480340003967,\n",
       " 0.17413461208343506,\n",
       " -0.4845144748687744,\n",
       " -0.6645116806030273,\n",
       " -0.10838557779788971,\n",
       " 0.6510306000709534,\n",
       " -0.14075064659118652,\n",
       " 0.23639966547489166,\n",
       " -0.5465475916862488,\n",
       " 0.29037341475486755,\n",
       " -0.08516477793455124,\n",
       " ...]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.embed_query(\"What is second letter of greek alphabet?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HF_TOKEN']=os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.02219323255121708,\n",
       " -0.011655949987471104,\n",
       " 0.07762274146080017,\n",
       " 0.048201631754636765,\n",
       " 0.028246894478797913,\n",
       " 0.05335577204823494,\n",
       " 0.014203856699168682,\n",
       " -0.050392355769872665,\n",
       " 0.029828622937202454,\n",
       " -0.03013942576944828,\n",
       " 0.0846155658364296,\n",
       " -0.04450998827815056,\n",
       " 0.0440790131688118,\n",
       " 0.0433078408241272,\n",
       " -0.009363092482089996,\n",
       " 0.014246895909309387,\n",
       " 0.08916229009628296,\n",
       " 0.02025790326297283,\n",
       " -0.037817858159542084,\n",
       " 0.013670781627297401,\n",
       " 0.007137923967093229,\n",
       " 0.04653988406062126,\n",
       " 0.05418972671031952,\n",
       " -0.05408455803990364,\n",
       " 0.01716436631977558,\n",
       " -0.0006513539119623601,\n",
       " -0.09210391342639923,\n",
       " 0.016734562814235687,\n",
       " 0.08676841109991074,\n",
       " -0.01860661432147026,\n",
       " 0.063850536942482,\n",
       " -0.014821152202785015,\n",
       " -0.0239939633756876,\n",
       " 0.09018656611442566,\n",
       " 0.04945998638868332,\n",
       " 0.04422907158732414,\n",
       " 0.05397539585828781,\n",
       " 0.0205898005515337,\n",
       " -0.016251536086201668,\n",
       " 0.011888865381479263,\n",
       " 0.025042062625288963,\n",
       " -0.025132490321993828,\n",
       " 0.007802823558449745,\n",
       " 0.0709867924451828,\n",
       " 0.0084243044257164,\n",
       " -0.042191024869680405,\n",
       " -0.05175028741359711,\n",
       " -0.017875077202916145,\n",
       " -0.06986701488494873,\n",
       " -0.006184477359056473,\n",
       " -0.049642208963632584,\n",
       " -0.05919220671057701,\n",
       " -0.0637204498052597,\n",
       " -0.0527263879776001,\n",
       " -0.02134568989276886,\n",
       " 0.024298690259456635,\n",
       " 0.0021891044452786446,\n",
       " -0.016154494136571884,\n",
       " 0.05178007483482361,\n",
       " 0.011473266407847404,\n",
       " 0.003315282054245472,\n",
       " -0.04183947667479515,\n",
       " 0.0031338694971054792,\n",
       " 0.07319903373718262,\n",
       " 0.07881342619657516,\n",
       " 0.007277114316821098,\n",
       " -0.032600827515125275,\n",
       " 0.03915121406316757,\n",
       " -0.06742630898952484,\n",
       " 0.053158167749643326,\n",
       " -0.02839607372879982,\n",
       " 0.06186094880104065,\n",
       " -0.03458603098988533,\n",
       " -0.0015246502589434385,\n",
       " -0.03586389124393463,\n",
       " 0.004250077996402979,\n",
       " -0.005297255702316761,\n",
       " -0.13117137551307678,\n",
       " 0.14055725932121277,\n",
       " -0.06529554724693298,\n",
       " -0.03934706002473831,\n",
       " -0.0884585976600647,\n",
       " -0.028979666531085968,\n",
       " 0.0008167779888026416,\n",
       " 0.06749657541513443,\n",
       " 0.03132482245564461,\n",
       " 0.08536015450954437,\n",
       " -0.14307339489459991,\n",
       " -0.1011083796620369,\n",
       " 0.02114187180995941,\n",
       " -0.010728557594120502,\n",
       " -0.07533922791481018,\n",
       " 0.014784213155508041,\n",
       " 0.07414121925830841,\n",
       " -0.03250911086797714,\n",
       " -0.02049407735466957,\n",
       " -0.03570185601711273,\n",
       " 0.017824308946728706,\n",
       " 0.02497095800936222,\n",
       " 0.06880676746368408,\n",
       " -0.005914777982980013,\n",
       " 0.008028513751924038,\n",
       " 0.09242694824934006,\n",
       " 0.01194795873016119,\n",
       " -0.06181274726986885,\n",
       " -0.09141258895397186,\n",
       " -0.023501645773649216,\n",
       " -0.04361076280474663,\n",
       " -0.010416426695883274,\n",
       " -0.06312782317399979,\n",
       " -0.04963744431734085,\n",
       " -0.05442190542817116,\n",
       " 0.0008557509281672537,\n",
       " 0.026427213102579117,\n",
       " -0.03963029384613037,\n",
       " -0.04293486475944519,\n",
       " -0.03445855528116226,\n",
       " -0.001227649045176804,\n",
       " 0.01439402624964714,\n",
       " 0.03900535777211189,\n",
       " 0.04029456898570061,\n",
       " 0.09487804770469666,\n",
       " -0.04361213371157646,\n",
       " 0.0067923408932983875,\n",
       " 0.0024615644942969084,\n",
       " -0.09216750413179398,\n",
       " 0.03737141937017441,\n",
       " -4.543385582947961e-33,\n",
       " 0.013090179301798344,\n",
       " -0.051504187285900116,\n",
       " -0.013136602006852627,\n",
       " 0.072356678545475,\n",
       " 0.034929729998111725,\n",
       " 0.011745985597372055,\n",
       " -0.054829731583595276,\n",
       " 0.14125105738639832,\n",
       " -0.09884824603796005,\n",
       " 0.011562763713300228,\n",
       " -0.0389699749648571,\n",
       " -0.019155902788043022,\n",
       " -0.026914194226264954,\n",
       " 0.10883469134569168,\n",
       " 0.025945499539375305,\n",
       " 0.09433626383543015,\n",
       " -0.0011222062166780233,\n",
       " 0.028348756954073906,\n",
       " -0.03350977972149849,\n",
       " 0.03226734697818756,\n",
       " -0.052610915154218674,\n",
       " 0.031031738966703415,\n",
       " -0.060647595673799515,\n",
       " -0.13262295722961426,\n",
       " -0.10989179462194443,\n",
       " -0.09145370870828629,\n",
       " 0.060662902891635895,\n",
       " -0.07135073095560074,\n",
       " -0.0883774533867836,\n",
       " 0.017104439437389374,\n",
       " -0.09812018275260925,\n",
       " -0.03149900585412979,\n",
       " -0.04009919986128807,\n",
       " 0.027446070685982704,\n",
       " 0.03741271793842316,\n",
       " 0.04737046733498573,\n",
       " 0.0564095564186573,\n",
       " -0.03353444114327431,\n",
       " -0.06256862729787827,\n",
       " 0.018479961901903152,\n",
       " -0.024564307183027267,\n",
       " -0.015609421767294407,\n",
       " -0.014316651970148087,\n",
       " 0.003160914173349738,\n",
       " 0.036262623965740204,\n",
       " 0.009966359473764896,\n",
       " 0.01232389360666275,\n",
       " 0.019805120304226875,\n",
       " -0.02496364526450634,\n",
       " -0.010106217116117477,\n",
       " 0.03497409448027611,\n",
       " 0.052556995302438736,\n",
       " 0.03664461523294449,\n",
       " -0.0866544246673584,\n",
       " 0.08340340107679367,\n",
       " 0.005661425646394491,\n",
       " -0.04565435275435448,\n",
       " 0.02299206331372261,\n",
       " 0.00789257325232029,\n",
       " 0.006110121496021748,\n",
       " -0.06178737059235573,\n",
       " -0.017390020191669464,\n",
       " 0.01954122819006443,\n",
       " 0.02674340456724167,\n",
       " -0.027492588385939598,\n",
       " 0.020543867722153664,\n",
       " -0.021493075415492058,\n",
       " -0.06867489963769913,\n",
       " 0.10131417959928513,\n",
       " 0.07836443185806274,\n",
       " -0.039514314383268356,\n",
       " 0.018982814624905586,\n",
       " -0.05519555136561394,\n",
       " 0.07838264107704163,\n",
       " -0.059621114283800125,\n",
       " -0.0010954105528071523,\n",
       " -0.044857777655124664,\n",
       " -0.019069017842411995,\n",
       " -0.0028910022228956223,\n",
       " 0.06780200451612473,\n",
       " 0.01638941653072834,\n",
       " -0.11991631239652634,\n",
       " 0.006598177365958691,\n",
       " -0.022088341414928436,\n",
       " -0.04793209955096245,\n",
       " -0.10615186393260956,\n",
       " 0.022992797195911407,\n",
       " -0.1329217255115509,\n",
       " 0.027439475059509277,\n",
       " 0.01899174228310585,\n",
       " 0.030177300795912743,\n",
       " 0.01177841518074274,\n",
       " -0.02791682817041874,\n",
       " -0.05339520797133446,\n",
       " 0.043010223656892776,\n",
       " 1.523297874469159e-33,\n",
       " -0.01187810581177473,\n",
       " 0.07049014419317245,\n",
       " -0.07197878509759903,\n",
       " 0.1232655942440033,\n",
       " 0.042394526302814484,\n",
       " -0.011806512251496315,\n",
       " 0.03173902630805969,\n",
       " 0.017055554315447807,\n",
       " -0.03162281587719917,\n",
       " 0.11074113100767136,\n",
       " -0.07468881458044052,\n",
       " -0.008166525512933731,\n",
       " 0.00694529851898551,\n",
       " -0.036778319627046585,\n",
       " -0.020071256905794144,\n",
       " 0.03954903781414032,\n",
       " -0.017154954373836517,\n",
       " -0.03324742242693901,\n",
       " 0.018471181392669678,\n",
       " 0.047440305352211,\n",
       " -0.02406669594347477,\n",
       " 0.10502691566944122,\n",
       " 0.012043002061545849,\n",
       " 0.11783886700868607,\n",
       " -0.005147026386111975,\n",
       " 0.06943674385547638,\n",
       " 0.012595957145094872,\n",
       " -0.018635403364896774,\n",
       " -0.06420997530221939,\n",
       " 0.002693797927349806,\n",
       " 0.027691984549164772,\n",
       " -0.05575023964047432,\n",
       " -0.10805672407150269,\n",
       " 0.024268869310617447,\n",
       " 0.007650340907275677,\n",
       " 0.018429357558488846,\n",
       " 0.12927469611167908,\n",
       " -0.04214354231953621,\n",
       " -0.02425961196422577,\n",
       " -0.01067239698022604,\n",
       " 0.06416842341423035,\n",
       " 0.03564293310046196,\n",
       " -0.03959798067808151,\n",
       " 0.09513315558433533,\n",
       " 0.033031199127435684,\n",
       " -0.04496878385543823,\n",
       " -0.036540236324071884,\n",
       " -0.08023426681756973,\n",
       " 0.03863181546330452,\n",
       " 0.004022196400910616,\n",
       " -0.10660471767187119,\n",
       " 0.010792112909257412,\n",
       " -0.05560751631855965,\n",
       " -0.005389732774347067,\n",
       " -0.054800987243652344,\n",
       " -0.013567428104579449,\n",
       " -0.03878258541226387,\n",
       " -0.04846629500389099,\n",
       " 0.014360127039253712,\n",
       " -0.014811903238296509,\n",
       " -0.05175051465630531,\n",
       " 0.005305078811943531,\n",
       " 0.01928478665649891,\n",
       " -0.04021068289875984,\n",
       " 0.05808505415916443,\n",
       " -0.10552408546209335,\n",
       " -0.027893805876374245,\n",
       " 0.08827756345272064,\n",
       " 0.00833933800458908,\n",
       " -0.0550873838365078,\n",
       " 0.02095993608236313,\n",
       " -0.01765201799571514,\n",
       " -0.06533800810575485,\n",
       " 0.047243401408195496,\n",
       " 0.028233813121914864,\n",
       " -0.05258927494287491,\n",
       " 0.025246012955904007,\n",
       " -0.008760708384215832,\n",
       " 0.029060741886496544,\n",
       " -0.07786893099546432,\n",
       " -0.011751692742109299,\n",
       " -0.10265549272298813,\n",
       " 0.037365879863500595,\n",
       " 0.020722072571516037,\n",
       " 0.01170741394162178,\n",
       " 0.05031943321228027,\n",
       " 0.01708444021642208,\n",
       " 0.011225073598325253,\n",
       " -0.016601255163550377,\n",
       " 0.027546077966690063,\n",
       " 0.02952340804040432,\n",
       " -0.035511311143636703,\n",
       " 0.013026482425630093,\n",
       " 0.055916622281074524,\n",
       " 0.01668626070022583,\n",
       " -2.1828435947668368e-08,\n",
       " -0.04839290305972099,\n",
       " -0.0024595351424068213,\n",
       " -0.0025462363846600056,\n",
       " 0.000254986371146515,\n",
       " -0.07908333092927933,\n",
       " -0.0044549377635121346,\n",
       " 0.016300398856401443,\n",
       " -0.014476343989372253,\n",
       " -0.0553770549595356,\n",
       " -0.019514700397849083,\n",
       " 0.04350553825497627,\n",
       " 0.049790333956480026,\n",
       " -0.07225240021944046,\n",
       " 0.019686637446284294,\n",
       " 0.05115152895450592,\n",
       " 0.00031234807102009654,\n",
       " -0.03341405466198921,\n",
       " -0.008627936244010925,\n",
       " 0.020924309268593788,\n",
       " 0.11419139802455902,\n",
       " -0.0003522622282616794,\n",
       " 0.10184769332408905,\n",
       " 0.04237174987792969,\n",
       " 0.037036068737506866,\n",
       " -0.08298323303461075,\n",
       " 0.02236236073076725,\n",
       " 0.01760699786245823,\n",
       " 0.006268023047596216,\n",
       " 0.0382651649415493,\n",
       " 0.04557753726840019,\n",
       " 0.08762113749980927,\n",
       " 0.094862200319767,\n",
       " -0.061641890555620193,\n",
       " -0.04177464544773102,\n",
       " -0.05438351631164551,\n",
       " 0.07018166035413742,\n",
       " 0.009961836971342564,\n",
       " -0.09811876714229584,\n",
       " -0.008993099443614483,\n",
       " -0.03541748225688934,\n",
       " -0.0069232904352247715,\n",
       " 0.01866443082690239,\n",
       " -0.018380898982286453,\n",
       " 0.001496989862062037,\n",
       " 0.0645337775349617,\n",
       " -0.04278608784079552,\n",
       " 0.04435054585337639,\n",
       " -0.014118717052042484,\n",
       " 0.0026061509270220995,\n",
       " -0.022767476737499237,\n",
       " 0.031193403527140617,\n",
       " -0.041731756180524826,\n",
       " 0.015941256657242775,\n",
       " -0.00016194644558709115,\n",
       " 0.02313058450818062,\n",
       " -0.036774106323719025,\n",
       " 0.011270345188677311,\n",
       " -0.0010690854396671057,\n",
       " -0.06297364830970764,\n",
       " 0.02188805863261223,\n",
       " 0.02669239044189453,\n",
       " 0.06420010328292847,\n",
       " 0.06740768253803253,\n",
       " -0.05152812972664833]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=\"This is a test sentence for embeddings.\"\n",
    "query=embeddings.embed_query(text)\n",
    "print(len(query))\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.043399371206760406,\n",
       "  0.03153632581233978,\n",
       "  0.0426400750875473,\n",
       "  -0.0070740156807005405,\n",
       "  0.0590025968849659,\n",
       "  0.07748805731534958,\n",
       "  0.05717156454920769,\n",
       "  -0.015846719965338707,\n",
       "  0.03532953932881355,\n",
       "  -0.04691490903496742,\n",
       "  0.07170525938272476,\n",
       "  0.01592620648443699,\n",
       "  0.011252649128437042,\n",
       "  -0.024096734821796417,\n",
       "  -0.08868508785963058,\n",
       "  0.04808421432971954,\n",
       "  0.06417981535196304,\n",
       "  0.017124459147453308,\n",
       "  -0.02819094993174076,\n",
       "  -0.009318923577666283,\n",
       "  -0.011185038834810257,\n",
       "  0.060136061161756516,\n",
       "  0.08445288985967636,\n",
       "  -0.050475675612688065,\n",
       "  0.0016540219075977802,\n",
       "  0.005656891502439976,\n",
       "  -0.07919064909219742,\n",
       "  0.11868414282798767,\n",
       "  0.07436972111463547,\n",
       "  -0.0014468568842858076,\n",
       "  0.003951891791075468,\n",
       "  0.01218367274850607,\n",
       "  0.0077368891797959805,\n",
       "  0.06085770204663277,\n",
       "  0.01718178763985634,\n",
       "  0.044974539428949356,\n",
       "  0.017898235470056534,\n",
       "  0.0623304508626461,\n",
       "  -0.028899140655994415,\n",
       "  0.03728455677628517,\n",
       "  0.027611952275037766,\n",
       "  -0.04769134894013405,\n",
       "  -0.0001303778262808919,\n",
       "  0.07647006958723068,\n",
       "  0.012758942320942879,\n",
       "  -0.03060515597462654,\n",
       "  -0.08288423717021942,\n",
       "  -0.08130398392677307,\n",
       "  -0.042009297758340836,\n",
       "  0.039365384727716446,\n",
       "  -0.03765494376420975,\n",
       "  -0.05252733826637268,\n",
       "  -0.09115327894687653,\n",
       "  -0.0302001740783453,\n",
       "  0.04706784337759018,\n",
       "  0.03472871705889702,\n",
       "  -0.015239623375236988,\n",
       "  -0.08378472179174423,\n",
       "  0.03384293615818024,\n",
       "  -0.057749904692173004,\n",
       "  0.07003431022167206,\n",
       "  0.0075866603292524815,\n",
       "  0.053051143884658813,\n",
       "  0.06251059472560883,\n",
       "  0.053467296063899994,\n",
       "  -0.03026372753083706,\n",
       "  -0.012028389610350132,\n",
       "  0.0983169749379158,\n",
       "  -0.09166093915700912,\n",
       "  0.02911468967795372,\n",
       "  -0.017323536798357964,\n",
       "  0.02700844593346119,\n",
       "  -0.08463308215141296,\n",
       "  -0.016932044178247452,\n",
       "  -0.05007629469037056,\n",
       "  -0.00837676040828228,\n",
       "  -0.0512487068772316,\n",
       "  -0.10503420233726501,\n",
       "  0.05104777589440346,\n",
       "  -0.09749662131071091,\n",
       "  0.008955058641731739,\n",
       "  -0.027219336479902267,\n",
       "  0.00645548477768898,\n",
       "  0.004769298247992992,\n",
       "  0.027718402445316315,\n",
       "  0.03652296960353851,\n",
       "  -0.014881462790071964,\n",
       "  -0.1450728476047516,\n",
       "  -0.020329952239990234,\n",
       "  -0.005259358324110508,\n",
       "  0.0012494022957980633,\n",
       "  -0.05565109848976135,\n",
       "  0.0467391163110733,\n",
       "  0.06848485767841339,\n",
       "  -0.06767336279153824,\n",
       "  -0.015282722190022469,\n",
       "  -0.07195545732975006,\n",
       "  0.019829196855425835,\n",
       "  -0.016775043681263924,\n",
       "  0.0967075303196907,\n",
       "  -0.024777298793196678,\n",
       "  -0.019931545481085777,\n",
       "  0.09229086339473724,\n",
       "  -0.023095732554793358,\n",
       "  -0.02494106814265251,\n",
       "  -0.1058363988995552,\n",
       "  -0.004165770020335913,\n",
       "  0.011638346128165722,\n",
       "  -0.04279093071818352,\n",
       "  -0.07790087163448334,\n",
       "  -0.037002984434366226,\n",
       "  -0.048636544495821,\n",
       "  -0.08358509838581085,\n",
       "  -0.00038053374737501144,\n",
       "  0.041701264679431915,\n",
       "  -0.03575693815946579,\n",
       "  0.08779965341091156,\n",
       "  -0.019319437444210052,\n",
       "  0.08410398662090302,\n",
       "  0.05040751025080681,\n",
       "  0.006062999367713928,\n",
       "  0.01826847344636917,\n",
       "  -0.06620422005653381,\n",
       "  -0.0008671525865793228,\n",
       "  0.008688266389071941,\n",
       "  -0.09692620486021042,\n",
       "  0.011578384786844254,\n",
       "  -4.015969185724833e-33,\n",
       "  0.04034748673439026,\n",
       "  0.010351179167628288,\n",
       "  -0.021302219480276108,\n",
       "  0.05544116720557213,\n",
       "  0.0807618498802185,\n",
       "  0.031078917905688286,\n",
       "  -0.0756852775812149,\n",
       "  0.029354212805628777,\n",
       "  -0.08587965369224548,\n",
       "  -0.04518925026059151,\n",
       "  -0.08422230184078217,\n",
       "  0.035841990262269974,\n",
       "  -0.021124660968780518,\n",
       "  0.04438476637005806,\n",
       "  -0.06329019367694855,\n",
       "  -0.059339482337236404,\n",
       "  0.017678674310445786,\n",
       "  0.005248411558568478,\n",
       "  0.04750078171491623,\n",
       "  -0.005350177176296711,\n",
       "  -0.06832380592823029,\n",
       "  0.08988437801599503,\n",
       "  -0.042303986847400665,\n",
       "  -0.09520266205072403,\n",
       "  -0.041681814938783646,\n",
       "  0.002992615569382906,\n",
       "  0.0812111422419548,\n",
       "  -0.07611636817455292,\n",
       "  -0.057823289185762405,\n",
       "  0.026302507147192955,\n",
       "  -0.03227917104959488,\n",
       "  0.0067352172918617725,\n",
       "  0.017020773142576218,\n",
       "  -0.05656582862138748,\n",
       "  0.052441395819187164,\n",
       "  0.062284134328365326,\n",
       "  0.008319197222590446,\n",
       "  -0.010559945367276669,\n",
       "  -0.02449595369398594,\n",
       "  -0.015842583030462265,\n",
       "  0.03207159414887428,\n",
       "  -0.02577754110097885,\n",
       "  0.00843777135014534,\n",
       "  -0.09655987471342087,\n",
       "  0.0076491036452353,\n",
       "  0.06797197461128235,\n",
       "  0.044237781316041946,\n",
       "  0.010101293213665485,\n",
       "  0.0028761657886207104,\n",
       "  -0.026480644941329956,\n",
       "  0.005758702754974365,\n",
       "  0.029908806085586548,\n",
       "  0.01658148318529129,\n",
       "  -0.06094761937856674,\n",
       "  0.06984879821538925,\n",
       "  -0.05337279289960861,\n",
       "  -0.0724259614944458,\n",
       "  0.06731463223695755,\n",
       "  -0.0018966810312122107,\n",
       "  -0.04177480936050415,\n",
       "  -0.06767906993627548,\n",
       "  -0.04830541834235191,\n",
       "  0.03520231321454048,\n",
       "  -0.03241504356265068,\n",
       "  -0.021079396829009056,\n",
       "  -0.008978024125099182,\n",
       "  -0.04364542290568352,\n",
       "  -0.07060021907091141,\n",
       "  0.04395483061671257,\n",
       "  0.014734016731381416,\n",
       "  -0.08728537708520889,\n",
       "  0.03634822368621826,\n",
       "  0.029597826302051544,\n",
       "  0.053268253803253174,\n",
       "  -0.09273979067802429,\n",
       "  0.018613433465361595,\n",
       "  -0.08312707394361496,\n",
       "  -0.048656217753887177,\n",
       "  0.0020694646518677473,\n",
       "  0.05182113125920296,\n",
       "  -0.07897281646728516,\n",
       "  -0.12389053404331207,\n",
       "  -0.03722250089049339,\n",
       "  -0.015653425827622414,\n",
       "  -0.026154829189181328,\n",
       "  -0.05959213525056839,\n",
       "  0.06748134642839432,\n",
       "  -0.1111777201294899,\n",
       "  0.0453028604388237,\n",
       "  0.10439929366111755,\n",
       "  -0.0778777226805687,\n",
       "  -0.01848759688436985,\n",
       "  -0.05540429428219795,\n",
       "  -0.034946877509355545,\n",
       "  0.038828544318675995,\n",
       "  1.2861584195800709e-33,\n",
       "  -0.011009315960109234,\n",
       "  0.01737474463880062,\n",
       "  -0.09458902478218079,\n",
       "  0.04689953476190567,\n",
       "  0.06381964683532715,\n",
       "  0.07166795432567596,\n",
       "  0.026684032753109932,\n",
       "  0.10836104303598404,\n",
       "  -0.003256942378357053,\n",
       "  0.05801742523908615,\n",
       "  -0.08241119980812073,\n",
       "  0.032374802976846695,\n",
       "  0.07731392234563828,\n",
       "  -0.06955933570861816,\n",
       "  0.016793662682175636,\n",
       "  -0.014923661015927792,\n",
       "  0.017691398039460182,\n",
       "  0.006122843362390995,\n",
       "  0.0021204426884651184,\n",
       "  0.02270703949034214,\n",
       "  -0.0015827238094061613,\n",
       "  0.029315484687685966,\n",
       "  -0.03203762322664261,\n",
       "  0.04289480298757553,\n",
       "  0.07412777096033096,\n",
       "  0.1006939634680748,\n",
       "  0.029562097042798996,\n",
       "  0.0350765585899353,\n",
       "  -0.04869695007801056,\n",
       "  -0.04876665025949478,\n",
       "  0.017128609120845795,\n",
       "  -0.0774708092212677,\n",
       "  -0.05514641851186752,\n",
       "  0.015738653019070625,\n",
       "  -0.056019820272922516,\n",
       "  -0.0025982230436056852,\n",
       "  0.13218805193901062,\n",
       "  -0.001032086438499391,\n",
       "  -0.07221276313066483,\n",
       "  -0.037547580897808075,\n",
       "  0.11257509887218475,\n",
       "  0.021921394392848015,\n",
       "  -0.043963365256786346,\n",
       "  0.005160165950655937,\n",
       "  -0.0013149901060387492,\n",
       "  -0.02432781085371971,\n",
       "  -0.03806502744555473,\n",
       "  -0.01813647337257862,\n",
       "  0.05834426358342171,\n",
       "  -0.007958034053444862,\n",
       "  -0.02639622986316681,\n",
       "  -0.05887467786669731,\n",
       "  -0.041059840470552444,\n",
       "  -0.011488757096230984,\n",
       "  -0.027420518919825554,\n",
       "  -0.010828611440956593,\n",
       "  -0.007274487521499395,\n",
       "  -0.03014584630727768,\n",
       "  0.05374725162982941,\n",
       "  -0.03304430469870567,\n",
       "  -0.023479172959923744,\n",
       "  -0.016888298094272614,\n",
       "  -0.021343709900975227,\n",
       "  -0.002175350207835436,\n",
       "  0.08250289410352707,\n",
       "  -0.09120535850524902,\n",
       "  -0.026683950796723366,\n",
       "  0.0631084218621254,\n",
       "  -0.025742249563336372,\n",
       "  0.0020837290212512016,\n",
       "  -0.024579785764217377,\n",
       "  -0.05910620093345642,\n",
       "  -0.11410914361476898,\n",
       "  0.006294608116149902,\n",
       "  0.02874491550028324,\n",
       "  -0.0376092828810215,\n",
       "  0.08742275089025497,\n",
       "  0.02244722470641136,\n",
       "  -0.009631390683352947,\n",
       "  -0.03144023194909096,\n",
       "  0.05871421843767166,\n",
       "  -0.07077332586050034,\n",
       "  0.01766083762049675,\n",
       "  0.07914876192808151,\n",
       "  0.06279271841049194,\n",
       "  0.017237870022654533,\n",
       "  0.01942097581923008,\n",
       "  0.04358876496553421,\n",
       "  -0.00010218323586741462,\n",
       "  -0.014676016755402088,\n",
       "  -0.03605049103498459,\n",
       "  0.040629785507917404,\n",
       "  -0.035592835396528244,\n",
       "  0.11099133640527725,\n",
       "  0.027584591880440712,\n",
       "  -1.954508910273489e-08,\n",
       "  -0.025730082765221596,\n",
       "  -0.036937419325113297,\n",
       "  -0.04657138139009476,\n",
       "  -0.0410720594227314,\n",
       "  -0.0219219159334898,\n",
       "  0.00017606583423912525,\n",
       "  -0.008960525505244732,\n",
       "  -0.06333167850971222,\n",
       "  -0.038888007402420044,\n",
       "  0.020405123010277748,\n",
       "  0.1387324035167694,\n",
       "  0.048995714634656906,\n",
       "  -0.00047602018457837403,\n",
       "  0.004645192064344883,\n",
       "  0.04004629701375961,\n",
       "  0.03827839717268944,\n",
       "  -0.026540692895650864,\n",
       "  -0.020634222775697708,\n",
       "  0.01478493120521307,\n",
       "  0.03528263792395592,\n",
       "  0.06297009438276291,\n",
       "  0.08397839218378067,\n",
       "  0.03850167989730835,\n",
       "  -0.02574840746819973,\n",
       "  -0.0846586525440216,\n",
       "  0.02980457805097103,\n",
       "  -0.04937054216861725,\n",
       "  -0.041005365550518036,\n",
       "  0.0038183804135769606,\n",
       "  -0.019704680889844894,\n",
       "  0.05812406539916992,\n",
       "  0.09508489817380905,\n",
       "  -0.0035704660695046186,\n",
       "  -0.0496981218457222,\n",
       "  -0.04372100532054901,\n",
       "  0.07002248615026474,\n",
       "  0.01822565123438835,\n",
       "  -0.06970657408237457,\n",
       "  -0.025974659249186516,\n",
       "  0.003554105758666992,\n",
       "  0.04935234412550926,\n",
       "  -0.026691032573580742,\n",
       "  0.006571997422724962,\n",
       "  0.025028759613633156,\n",
       "  0.0941791757941246,\n",
       "  -0.009427761659026146,\n",
       "  0.07070991396903992,\n",
       "  0.00345239439047873,\n",
       "  0.00615558261051774,\n",
       "  0.024282725527882576,\n",
       "  0.020846746861934662,\n",
       "  -0.04209167882800102,\n",
       "  0.025002066045999527,\n",
       "  0.05302300304174423,\n",
       "  -0.019750790670514107,\n",
       "  0.010694380849599838,\n",
       "  0.045716140419244766,\n",
       "  0.036765024065971375,\n",
       "  -0.05793290212750435,\n",
       "  0.022404257208108902,\n",
       "  -0.006270430516451597,\n",
       "  0.07816110551357269,\n",
       "  0.08175160735845566,\n",
       "  0.013548257760703564]]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_res_query=embeddings.embed_documents([\"This is another text for the embeddings\"])\n",
    "doc_res_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector StoreDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x23d0a683b00>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FAISS\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "docs=TextLoader(\"speech.txt\",encoding=\"UTF-8\").load()\n",
    "splitter=CharacterTextSplitter(chunk_size=200,chunk_overlap=0)\n",
    "doc=splitter.split_documents(docs)\n",
    "\n",
    "embeddings=OllamaEmbeddings(model=\"mxbai-embed-large\")\n",
    "db=FAISS.from_documents(doc,embeddings)\n",
    "db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'speech.txt'}, page_content='Scuderia Ferrari (Italian: [skudeˈriːa ferˈraːri]) currently racing under Scuderia Ferrari HP is the racing division of luxury Italian auto manufacturer Ferrari and the racing team that competes in Formula One racing. The team is also known by the nickname \"The Prancing Horse\" (Italian: il Cavallino Rampante or simply il Cavallino), in reference to their logo. It is the oldest surviving and most successful Formula One team, having competed in every world championship since 1950.')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query the db\n",
    "query=\"What is Scuderia Ferrari succesful in?\"\n",
    "docs=db.similarity_search(query)\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'source': 'speech.txt'}, page_content='Scuderia Ferrari (Italian: [skudeˈriːa ferˈraːri]) currently racing under Scuderia Ferrari HP is the racing division of luxury Italian auto manufacturer Ferrari and the racing team that competes in Formula One racing. The team is also known by the nickname \"The Prancing Horse\" (Italian: il Cavallino Rampante or simply il Cavallino), in reference to their logo. It is the oldest surviving and most successful Formula One team, having competed in every world championship since 1950.'),\n",
       "  148.14124)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Smililarity search with score\n",
    "docs_score=db.similarity_search_with_score(query)\n",
    "docs_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'speech.txt'}, page_content='Scuderia Ferrari (Italian: [skudeˈriːa ferˈraːri]) currently racing under Scuderia Ferrari HP is the racing division of luxury Italian auto manufacturer Ferrari and the racing team that competes in Formula One racing. The team is also known by the nickname \"The Prancing Horse\" (Italian: il Cavallino Rampante or simply il Cavallino), in reference to their logo. It is the oldest surviving and most successful Formula One team, having competed in every world championship since 1950.')]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As a retriever\n",
    "ret=db.as_retriever()\n",
    "ret.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save db in Local system\n",
    "db.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'speech.txt'}, page_content='Scuderia Ferrari (Italian: [skudeˈriːa ferˈraːri]) currently racing under Scuderia Ferrari HP is the racing division of luxury Italian auto manufacturer Ferrari and the racing team that competes in Formula One racing. The team is also known by the nickname \"The Prancing Horse\" (Italian: il Cavallino Rampante or simply il Cavallino), in reference to their logo. It is the oldest surviving and most successful Formula One team, having competed in every world championship since 1950.')]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the db\n",
    "new_db=FAISS.load_local(\"faiss_index\",embeddings,allow_dangerous_deserialization=True)\n",
    "New_docs=new_db.similarity_search(\"Sucerdia ferrari championship in which year?\")\n",
    "New_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_chroma.vectorstores.Chroma at 0x23d61f38140>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ChromaDB from langchain\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "docs=TextLoader(\"speech.txt\",encoding=\"UTF-8\").load()\n",
    "splitter=CharacterTextSplitter(chunk_size=200,chunk_overlap=0)\n",
    "doc=splitter.split_documents(docs)\n",
    "\n",
    "embeddings=OllamaEmbeddings(model=\"mxbai-embed-large\")\n",
    "db=Chroma.from_documents(doc,embeddings)\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'speech.txt'}, page_content='Scuderia Ferrari (Italian: [skudeˈriːa ferˈraːri]) currently racing under Scuderia Ferrari HP is the racing division of luxury Italian auto manufacturer Ferrari and the racing team that competes in Formula One racing. The team is also known by the nickname \"The Prancing Horse\" (Italian: il Cavallino Rampante or simply il Cavallino), in reference to their logo. It is the oldest surviving and most successful Formula One team, having competed in every world championship since 1950.'),\n",
       " Document(metadata={'source': 'speech.txt'}, page_content='Scuderia Ferrari (Italian: [skudeˈriːa ferˈraːri]) currently racing under Scuderia Ferrari HP is the racing division of luxury Italian auto manufacturer Ferrari and the racing team that competes in Formula One racing. The team is also known by the nickname \"The Prancing Horse\" (Italian: il Cavallino Rampante or simply il Cavallino), in reference to their logo. It is the oldest surviving and most successful Formula One team, having competed in every world championship since 1950.'),\n",
       " Document(metadata={'source': 'speech.txt'}, page_content='Scuderia Ferrari (Italian: [skudeˈriːa ferˈraːri]) currently racing under Scuderia Ferrari HP is the racing division of luxury Italian auto manufacturer Ferrari and the racing team that competes in Formula One racing. The team is also known by the nickname \"The Prancing Horse\" (Italian: il Cavallino Rampante or simply il Cavallino), in reference to their logo. It is the oldest surviving and most successful Formula One team, having competed in every world championship since 1950.'),\n",
       " Document(metadata={'source': 'speech.txt'}, page_content='Scuderia Ferrari (Italian: [skudeˈriːa ferˈraːri]) currently racing under Scuderia Ferrari HP is the racing division of luxury Italian auto manufacturer Ferrari and the racing team that competes in Formula One racing. The team is also known by the nickname \"The Prancing Horse\" (Italian: il Cavallino Rampante or simply il Cavallino), in reference to their logo. It is the oldest surviving and most successful Formula One team, having competed in every world championship since 1950.')]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"What is Scuderia Ferrari known for?\"\n",
    "docs=db.similarity_search(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Chromadb\n",
    "db=Chroma.from_documents(doc,embeddings,persist_directory=\"./chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'speech.txt'}, page_content='Scuderia Ferrari (Italian: [skudeˈriːa ferˈraːri]) currently racing under Scuderia Ferrari HP is the racing division of luxury Italian auto manufacturer Ferrari and the racing team that competes in Formula One racing. The team is also known by the nickname \"The Prancing Horse\" (Italian: il Cavallino Rampante or simply il Cavallino), in reference to their logo. It is the oldest surviving and most successful Formula One team, having competed in every world championship since 1950.'),\n",
       " Document(metadata={'source': 'speech.txt'}, page_content='Scuderia Ferrari (Italian: [skudeˈriːa ferˈraːri]) currently racing under Scuderia Ferrari HP is the racing division of luxury Italian auto manufacturer Ferrari and the racing team that competes in Formula One racing. The team is also known by the nickname \"The Prancing Horse\" (Italian: il Cavallino Rampante or simply il Cavallino), in reference to their logo. It is the oldest surviving and most successful Formula One team, having competed in every world championship since 1950.'),\n",
       " Document(metadata={'source': 'speech.txt'}, page_content='Scuderia Ferrari (Italian: [skudeˈriːa ferˈraːri]) currently racing under Scuderia Ferrari HP is the racing division of luxury Italian auto manufacturer Ferrari and the racing team that competes in Formula One racing. The team is also known by the nickname \"The Prancing Horse\" (Italian: il Cavallino Rampante or simply il Cavallino), in reference to their logo. It is the oldest surviving and most successful Formula One team, having competed in every world championship since 1950.')]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading Chroma\n",
    "db2=Chroma(persist_directory=\"./chroma_db\",embedding_function=embeddings)\n",
    "docs=db2.similarity_search(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'speech.txt'}, page_content='Scuderia Ferrari (Italian: [skudeˈriːa ferˈraːri]) currently racing under Scuderia Ferrari HP is the racing division of luxury Italian auto manufacturer Ferrari and the racing team that competes in Formula One racing. The team is also known by the nickname \"The Prancing Horse\" (Italian: il Cavallino Rampante or simply il Cavallino), in reference to their logo. It is the oldest surviving and most successful Formula One team, having competed in every world championship since 1950.'),\n",
       " Document(metadata={'source': 'speech.txt'}, page_content='Scuderia Ferrari (Italian: [skudeˈriːa ferˈraːri]) currently racing under Scuderia Ferrari HP is the racing division of luxury Italian auto manufacturer Ferrari and the racing team that competes in Formula One racing. The team is also known by the nickname \"The Prancing Horse\" (Italian: il Cavallino Rampante or simply il Cavallino), in reference to their logo. It is the oldest surviving and most successful Formula One team, having competed in every world championship since 1950.'),\n",
       " Document(metadata={'source': 'speech.txt'}, page_content='Scuderia Ferrari (Italian: [skudeˈriːa ferˈraːri]) currently racing under Scuderia Ferrari HP is the racing division of luxury Italian auto manufacturer Ferrari and the racing team that competes in Formula One racing. The team is also known by the nickname \"The Prancing Horse\" (Italian: il Cavallino Rampante or simply il Cavallino), in reference to their logo. It is the oldest surviving and most successful Formula One team, having competed in every world championship since 1950.')]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retriever \n",
    "ret=db2.as_retriever()\n",
    "ret.invoke(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
